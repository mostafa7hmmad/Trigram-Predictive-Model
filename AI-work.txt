Artificial intelligence techniques in financial trading: A systematic 
Artificial intelligence 
Financial technology 
Artificial Intelligence (AI) approaches have been increasingly used in financial markets as technology advances. 
through AI techniques. It reviews 143 research articles that implemented AI techniques in financial trading 
perspectives: the financial trading market and the asset type, the trading analysis type considered along with the 
AI technique, and the AI techniques utilized in the trading market, the estimation and performance metrics of the 
proposed models. The selected research articles were published between 2015 and 2023, and this review ad-
predictive models. Moreover, we found that technical analysis is more adopted compared to fundamental 
analysis. Furthermore, 16% of the selected research articles entirely automate the trading process. In addition, 
we identified 40 different AI techniques that are used as standalone and hybrid models. Among these techniques, 
deep learning techniques are the most frequently used in financial trading markets. Building prediction models 
for financial markets using AI is a promising field of research, and academics have already deployed several 
machine learning models. As a result of this evaluation, we provide recommendations and guidance to 
technology breakthroughs and improvements, Artificial Intelligence 
(AI) approaches have become widely used in financial markets, altering 
represented by financial technology, or FinTech, which uses technology 
automated trading, investments, insurance, and risk management (Gai 
AI has proven beneficial in the financial sector in areas such as 
process automation, risk management, and customer service develop-
advanced analytics and natural language processing, automated repet-
itive tasks, and risk assessment and reduction by analyzing large data-
sets with AI algorithms. AI is also used in the banking industry, where it 
areas. AI is revolutionizing the investment and insurance industries by 
facilitating automated risk management, tailored investment programs, 
and market forecasting (Ferreira et al., 2021). 
integrating AI in the financial markets. Significant challenges include 
data quality, ultra-high frequency data processing, and economic 
AI-enhanced algorithmic trading significantly impacts financial 
trading by mining critical data and providing inexpensive and easily 
accessible tools that benefit everyone, not just companies. AI investing 
AI, allowing them to learn from the trading records of thousands of 
learning algorithms that discover patterns in data and generate pre-
dictions. As a result, AI algorithmic trading offers several benefits and 
Li et al., 2020). For example, AI’s ability to respond to market condi-
patterns that humans cannot capture due to the massive amount of data, 
achievable with incredibly powerful computers and AI technology. 
or fear. On the other hand, AI algorithmic trading is based on statistical, 
confident conclusions created by examining past data and a wide range 
Even though AI is frequently used in financial markets, researchers 
encounter several challenges. One of the primary difficulties is data, 
which includes data quality, ultra-high frequency data processing, and 
rapidly adding new data sources such as social mainstream media and 
In the financial trading industry, AI techniques have become vital 
technology’s quick development and application in the financial mar-
kets, there is still a substantial gap in systematic reviews of AI techniques 
investigation to comprehend the state of AI approaches and trading 
analysis tools for financial market trading. To the best of our knowledge, 
no previous study has systematically focused on AI techniques and ap-
on using AI in financial trading markets. This study is an overview of 
which AI approaches are commonly employed and which models exploit 
scholars with a better grasp of the present level of AI progress and use in 
the asset type, (ii) the trading analysis type considered along with the AI 
technique, and (iii) the AI techniques utilized in the trading market, (iv) 
the estimation and performance metrics of the proposed models. 
2.2. Trading analysis types 
evaluate patterns. Traders typically use one or a mix of these analysis 
a) Fundamental analysis 
The fundamental analysis approach consists of analyzing the impact 
the significant events and economic data that affect the market. It de-
b) Technical analysis 
Technical analysis is based on statistical methods and charts that 
trends that they might exploit. This analysis aims to extract (non-linear) 
patterns that will be used to build trading strategies from the analysis of 
Table 1 compares the major types of analysis. The table indicates that 
technical analysis predicts price movement by employing price charts, 
other hand, fundamental analysis is focused on economic analysis, 
automate the trading process. Algorithm trading is often characterized 
historical data. Backtesting allows traders to fine-tune and enhance their 
models and tactics. 
Algorithmic trading employs models that adhere to predetermined 
strategies. These models can include basic yet successful tactics such as 
complicated models has been possible with AI approaches. These models 
testing a machine learning model to minimize overfitting and fine-tune 
frequently continued by simulated trading using real-time data. If this 
continues to be effective, the algorithm will most likely be deployed to 
Fig. 2. Trading Analysis.  
Comparison between Fundamental and Technical Analysis.   
Fundamental Analysis 
Technical Analysis 
historical and current data is 
historical data from the past. 
AI in financial trading were reviewed. Only survey articles that study AI 
in financial markets are Several surveys for AI in financial trading have 
pilot survey on using machine learning for quantitative trading. The 
including price trends, forecasting, and portfolio selections. In addition, 
analysis, and text mining for learning portfolio selection. 
bibliographic analysis highlighting machine-learning approaches for 
forecasting financial market values. The authors analyzed 57 articles, 
and their findings revealed that the most commonly employed models in 
price forecasting are support vector machines and neural networks. 
data from developing markets provides a research opportunity. 
The forecasting methodologies are classified, characterized, and 
compared from 2014 to 2018. Their study and analysis show that 
ensemble models have highly predictive predictions. Surprisingly, they 
claim that deep learning models did not beat traditional methods, which 
2021) give another evaluation covering a wide range of works from 
1995 to 2019 investigating AI in stock market trading. The authors 
classified AI applications in the stock market into four categories: 
portfolio optimization, stock market prediction using AI, financial 
sentiment analysis, and combinations of two or more methodologies. 
learning techniques: Artificial Neural Networks (ANN) and Support 
and AI, such as the following (Le et al., 2020; Chopra and Sharma, Nov. 
Another part of the survey used deep learning and deep reinforce-
hand, did a thorough literature review on deep learning and technical 
analysis in the stock market. Their systematic study focuses on four 
areas: price forecasting approach, trading strategy, profit evaluation and 
measures, and risk management. According to their findings, the LSTM 
approach is the most often employed. Deep Learning has quickly 
emerged as a potent technique for modeling and forecasting unpre-
deep learning techniques in the European stock market. 
FinTech, or the intersection of finance and technology, transforms 
accessibility, efficiency, and inclusion. FinTech’s fast growth continues 
discusses the opportunities and risks of using AI in the financial sector, 
view of how AI transforms the financial industry and what financial 
organizations must consider when integrating this technology. On the 
areas of AI in both FinTech and RegTech, which refers to regulatory 
technologies. The author discusses AI’s impact on Fintech and its ben-
associated with Fintech and how RegTech can help to regulate Fintech 
sights into the exciting world of AI in FinTech and RegTech and how it is 
AI and machine learning are affecting it from several factors. In (Milana 
of AI in finance and financial markets present insights into the industry’s 
approaches, including fuzzy set qualitative comparison analysis and 
abductive learning networks, to assess the influence of AI on market 
value added, risk management, and long-term growth. They also 
examine the frequency distribution of articles on AI in finance over time, 
et al. (Aziz et al., 2022). The authors of this study employ a data science 
edge of the structure of research in machine learning and finance. They 
quantitative analysis disciplines, including deep learning. Several 
niques in fields where data sets are intrinsically small, such as 
emphasize the novel and inventive uses of machine learning algorithms 
applications of AI in e-commerce and finance. Their study highlights 
how AI is being used to improve customer experience, supply chain 
study also discusses the differences between machine learning and deep 
learning, two of the most commonly used AI approaches. 
Two research focused on delivering a review of bibliometric analysis. 
evaluation of AI and Machine Learning research in finance. They sought 
to determine the conceptual formation of AI and ML in finance research 
scope of the evaluation, selecting the techniques for analysis, gathering 
data for analysis, conducting the analysis, and reporting the findings. 
The report thoroughly examines the research on AI and machine 
metric evaluation of the literature on applying AI and machine learning 
keyword co-occurrence, factorial analysis, trend analysis, co- 
Our Systematic Literature Review (SLR) on applying AI in financial 
cryptocurrencies, or foreign exchange) or AI methods (such as solely 
deep learning), our SLR covers a broad range of AI techniques, 
including machine learning, deep learning, and reinforcement 
overview of AI’s application in financial trading, emphasizing 
charting and different approaches to trade analysis. A condensed 
derstand the subsequent exploration of AI in trading markets.  
3) Thorough Analysis and Data Collection: We have carefully 
market, the kinds of assets traded, the AI models and approaches 
datasets and their sources, metrics for evaluating model perfor-
This precise data collection process enables us to create an in-depth 
overview of state-of-the-art AI applications in financial trading by 
investigation in underrepresented fields within the AI and financial 
The purpose of our article is to review AI techniques used in financial 
trading in a systematic approach. We conducted a thorough analysis of 
published research from 2015 to 2023 to determine the most popular AI 
state-of-the-art AI applications used in financial trading markets, we 
collected data aided in identifying study patterns in the usage of AI in 
trading during the last decade. The data collected during our study shed 
establishing quality evaluation guidelines, laying out the data extraction 
technique, and synthesizing the collected data. The stages are illustrated 
Machine learning 
Machine learning 
Machine learning 
Deep learning 
Deep learning 
Machine learning and deep learning 
Deep reinforcement learning 
AI 
Machine learning 
Fintech, banking, 
AI 
Machine learning 
AI 
Machine learning 
FinTech, RegTech 
AI 
analysis 
AI 
Machine learning 
Machine learning 
Deep learning 
AI 
AI  
We aim to investigate how AI is utilized in financial trading, which 
primary machine learning algorithms are employed, how accurate they 
are, what makes a training model acceptable for the data presented, and 
which models provide the most return for traders. In addition, we want 
to look at the automation side of financial trading.  
2. RQ2: Are fundamental or technical trading analysis approaches 
being used? What sources for fundamental analysis are being 
used? Does the proposed solution support automation?  
3. RQ3: What type of AI approach is deployed? What are the 
4. RQ4: What are the testing and evaluation metrics for the model 
• “AI” OR “Artificial intelligence” AND “trading” OR “AI-based 
• “Machine learning” AND “trading”  
• “Deep learning” AND “trading”  
• “High-frequency trading” AND “artificial intelligence” OR “AI”  
• “High-frequency trading” AND “machine learning”  
• “Reinforcement learning” OR “transfer learning” AND “trading”  
quality evaluation guidelines.  
An initial machine learning survey for quantitative 
mining, neural networks, SVM, and wavelet analysis. 
A review of the literature on machine learning for 
network methods were highlighted in the analysis of 
57 articles. It finds research opportunities in data 
trends. Their emphasis is on ensemble models and 
A Review of the literature on technical analysis and 
deep learning in the stock market. They emphasize 
risk management, trading strategy, profit assessment, 
and price forecasting. Additionally, LSTM was found 
This review systematically analyzes deep learning in 
Examines AI’s use in stock market trading between 
Covers the potential and hazards of AI in banking, 
AI’s revolutionary impact on financial services. 
A review of the literature on AI in the financial 
markets. It examines studies on the effects of AI on 
growth, risk management, and market value. 
AI finance. 
Highlights small data set applications, predicting 
Discusses AI’s impact, benefits for regulatory 
authorities, and risks in Fintech. 
Utilize data science topic modeling to comprehend 
finance research and machine learning. It also 
financial engineering and quantitative analysis, 
including deep learning. The study emphasizes 
valuable machine learning applications in finance and 
forecasting. The study draws attention to these two 
An overview of the use of AI in finance and e- 
commerce. It discusses the impact of AI on quality 
QAR7: Are evaluation metrics and testing results reported? 
QAR8: Are the evaluation metrics of the proposed methods suitable? 
QAR9: Is the evaluation metric compared to other methods? 
4.5. Data extraction strategy 
(Trading type, financial asset), RQ2(AI approach, Model, Automation), 
RQ3(analysis type, technical indicators, fundamental analysis source), 
RQ4(evaluation metric, testing, time frame, dataset), and RQ5(future 
work and challenges), were among the data retrieved from each paper. 
3) the AI approach is utilized (machine learning, deep learning, 
reinforcement learning, etc.), and the model is conducted.  
4) the type of trading analysis used (fundamental analysis, technical 
analysis, trading strategy).  
7) the evaluation metrics of profitability and the performance of the 
4.6. Synthesis of extracted data 
answer the RQs from the data retrieved from the selected publications. 
tabulated the data to create statistical comparisons between the various 
data were qualitative, such as the type of assessment metrics, while 
itative data synthesizing strategies. 
diving deeper into the analysis details, we provide Fig. 5, which presents 
• Machine learning articles that aren’t 
prediction, sentiment analysis, or 
portfolio optimization aren’t included. 
• Machine learning for price or trend 
optimization. 
learning and non-machine learning 
more robust and adaptable trading models. 
We have compiled the following findings in our analysis of the 
The analysis of technology companies was one of the study’s high-
lights. The analysis results indicated that tech business shares are more 
articles implemented the BTC-USDT pair in their application of AI 
behavior, and potential trading strategies. This detailed analysis enables 
the development of more targeted and effective AI-based trading models 
5.2. Trading analysis methods 
different trading analysis types in conjunction with AI techniques. Fig. 10 
provides insights into the frequency of trading analysis types utilized in 
implementing AI in trading markets. According to the figure, technical 
analysis, trading strategy, and fundamental analysis are the primary 
analysis methods implemented in conjunction with machine learning 
techniques. Among these, technical analysis is the most widely utilized, 
analysis is employed in 12 % of the research papers, indicating a lesser 
prevalence than technical analysis. Additionally, 5 % of the research 
papers combine technical and fundamental analysis. Furthermore, a 
fundamental analysis. Incorporating news sentiment and its impact on 
on trading strategy with technical analysis implementation. 
When obtaining news data for fundamental analysis, the most widely 
financial markets. Using different trading analysis types with AI tech-
strategies. While technical analysis dominates the implementation 
landscape, fundamental analysis, trading strategies, and combining 
these methods showcase the integration of AI techniques in exploring 
minimum price observed during the asset’s market activity. The data’s 
The choice of data granularity relies on the intended prediction 
goals. For long-term investments, opting for lower granularity data, such 
strategies benefit from higher granularity data. However, it’s important 
to note that higher granularity data introduces more noise, although it 
Fig. 10. Trading Analysis Methods Implemented in Selected Research Articles.  
Fig. 11. Technical Analysis Indicators Types Frequency.  
It’s worth highlighting that selecting the appropriate data granu-
In addition to market price data, researchers commonly incorporate 
various trading analysis types into their prediction models. Technical 
analysis involves the inclusion of specific indicators that align with their 
training the models. On the other hand, some researchers employ 
fundamental analysis, which entails web scraping news articles to 
identify factors that influence prices. They combine this news data with 
market information for their models. Another approach is to leverage 
technical and fundamental analysis with market data. 
The outputs of these models vary among researchers, but the ulti-
data. Others focus on predicting the overall trend, whether upward or 
models focus on predicting the price or emphasize success and profit 
Some of these models incorporate automation by directly executing 
implemented automation and developed a fully functional trading sys-
not employ automation in their solution. Only 16 % of the research 
papers automated the actions predicted by their models. However, 22 % 
5.3. AI approach and algorithm techniques 
commonly employed AI techniques in the financial trading sector. 
extraction, preprocessing, and analysis, we thoroughly examined the 
Fig. 14 categorizes the AI approaches used in trading financial 
markets, which can be classified into five primary types: classification, 
regression, deep learning, reinforcement learning, and deep reinforce-
• Classification: Ten percent of the articles we reviewed used classi-
fication techniques, which included categorizing data into pre-
• Regression: Regression methods are used in 2 % of the chosen ar-
Regression analysis can offer essential insights into price patterns 
• Deep Learning: The most widely used strategy, used in 30 % of the 
articles, deep learning algorithms can process enormous amounts of 
unstructured data, which makes them especially helpful for identi-
• Reinforcement Learning: 29 % of the articles use this technique, in 
• Deep Reinforcement Learning: This strategy, also used in 29 % of 
the studies, combines reinforcement learning’s ability to make de-
cisions with deep learning’s capacity for pattern recognition. As a 
These results indicate that, in this domain, deep learning, rein-
considered more appropriate than classification and regression tech-
financial markets are and how sophisticated AI methods that can 
reinforcement learning started gaining attention in 2019 and reached its 
reinforcement learning was the most commonly used approach in 2018 
and 2021, but it was surpassed by deep learning in 2022. 
Fig. 16 provides an overview of the AI techniques and algorithms for 
analysis, classical machine learning, deep learning, and reinforcement 
applied in risk analysis and financial modeling. It is mainly used to 
between the variables. Copula is a statistical time-series analysis tool 
that can be used in the context of AI. However, it is a statistical analysis 
tool rather than a specialized AI technique. It can be combined with AI 
approaches like machine learning, deep learning, or reinforcement 
Fig. 12. Utilizing Trading Analysis in AI.  
Fig. 14. AI Type Implementation by Selected Research Articles.  
Fig. 15. Distribution of AI Implementation Types per Year.  
We divided the algorithms into classifies, ensemble, regression, and 
clustering in classical machine learning. Deep learning techniques have 
rithms such as convolutional neural networks, recurrent neural net-
ability to capture temporal dependencies. Reinforcement learning ap-
Reinforcement learning algorithms can be based on policies, either on- 
algorithms. These Reinforcement learning techniques have been 
2020), a hybrid implementation of Proximal Policy Optimization (PPO) 
incorporate fundamental analysis by studying the sentiments of news 
Fig. 16. AI Techniques utilized in Financial Trading Markets.  
Fig. 17. Frequency of AI Evaluation Metrics.  
evolving nature of AI applications in financial trading, encompassing 
statistical, machine learning, deep learning, and reinforcement learning 
5.4. Performance metrics and evaluation 
Evaluation of model performance is a crucial step in any AI pipeline 
mance metrics commonly adopted to measure and evaluate the effi-
ciency of the proposed methods and techniques. Several well-known AI 
evaluation metrics are specifically designed to assess the quality of 
uation metrics used to test the performance of AI models. According to 
the figure, the most commonly adopted metrics among classification 
employ a combination of two or more of these evaluation methods. 
using an AI approach over a traditional buy-and-hold strategy. The most 
widely used evaluation metric is Root Mean Square Error (RMSE), 
categorized as a regression metric. 
which showcases the most commonly used performance metrics for 
assessing financial performance. The metrics include the Sharpe Ratio, 
metrics provide insights into the proposed models’ risk-adjusted returns, 
overall profitability, and financial viability. Adopting evaluation metrics 
from both AI and financial perspectives ensures a comprehensive 
model’s performance on additional historical data. It allows traders to 
real-time replication of trading strategies as new data becomes avail-
from the historical data used in backtesting. 
searchers utilize to obtain their data. Table 8 presents a list of these 
commonly used source for obtaining market data. Its comprehensive 
techniques to gather historical financial data, was utilized by 4 research 
articles. This highlights its significance as a valuable data source for 
Finance are reputable sources for obtaining historical financial data. 
reliable by researchers in the field. The utilization of various data 
the necessary datasets for their studies. The selection of a particular data 
source depends on factors such as data coverage, reliability, accessi-
market and financial data. 
adopted either a 4-year or 1-year range of market data. This indicates 
that researchers often focus on relatively recent data to analyze market 
Frequency of Investment Performance Metrics.  
Wharton Research Data 
proaches through AI techniques. It reviews 143 scientific research arti-
cles implementing AI techniques in financial trading markets. 
trading market and the asset type, the trading analysis type considered 
along with the AI technique, and the AI techniques utilized in the trading 
market, the estimation and performance metrics of the proposed models. 
utilized for the application of AI. The most widely studied markets are 
RQ’s findings were that technical analysis indicators are preferable to 
fundamental analysis. In addition, fundamental analysis is adopted even 
these analysis methods in AI are market information that is given for the 
analysis, or both types. As well as an interesting finding is that only 16 % 
the third RQ, the AI approach widely implemented for building pre-
dictive models is deep learning, which is utilized by 30 % of the papers, 
followed by reinforcement learning and deep reinforcement learning, 
distribution of these approaches per year, and we identified 40 main AI 
techniques in this domain, which are used mostly as hybrid models that 
performance evaluation and an investment evaluation. RMSE, Accuracy, 
recall, and F-measure are the most common model evaluation metrics 
searchers have obtained market information. The time-series data 
studied used a 4-year and 1-year data range the most. We present the 
the models’ risk-controlling behavior and build additional crisis de-
both fundamental and technical analysis into the prediction model and 
Fatima Dakalbab: Methodology, Software, Formal analysis, Data 
Writing – review & editing. Tracy Saroufil: Formal analysis, Data 
tion, summarization, and analysis of the research papers for this SLR 
reinforcement learning model for automated multi-stock trading. Prog. Artif. Intell. 
trading system with capital risk analysis using machine learning”, 2021 3rd int. 
intelligence and machine learning in finance: a bibliometric review. Res. Int. Bus. 
trading using exploratory data analysis and artificial intelligence”, 2021 1st int. 
Conf. Artif. Intell. Data Anal. CAIDA 2021, 54–61. https://doi.org/10.1109/ 
portfolio optimization using recurrent reinforcement learning with expected 
reinforcement Learning and directional change. IEEE Access 9, 114659–114671. 
Ashta, A., Herrmann, H., May 2021. Artificial intelligence and fintech: an overview of 
Exploring the use of machine learning techniques,” Proc. 5th Int. Work. Data Sci. 
M. Ayitey Junior, P. Appiahene, and O. Appiah, “Forex market forecasting with two-layer 
stacked Long Short-Term Memory neural network (LSTM) and correlation analysis,” 
reinforcement Learning. Lect. Notes Networks Syst. 32, 41–49. https://doi.org/ 
Aziz, S., Dowling, M., Hammami, H., Piepenbrink, A., Jun. 2022. Machine learning in 
Baasher, A.A., Fakhr, M.W., 2016. Forex trend classification by machine Learning. Noor 
Reinforcement Learning Method,” Proc. 2020 5th Int. Conf. Cloud Comput. Artif. Intell. 
Baek, S., Glambosky, M., Oh, S.H., Lee, J., 2020. Machine Learning and algorithmic pairs 
Bayramo˘glu, G., 2021. “An overview of the artificial intelligence applications in fintech 
C. Betancourt and W. H. Chen, “Reinforcement learning with self-attention networks for 
K. Bisht and A. Kumar, “Deep Reinforcement Learning based Multi-Objective Systems for 
L. Bisi et al., “Foreign Exchange Trading: A Risk-Averse Batch Reinforcement Learning 
Borrageiro, G., Firoozye, N., Barucca, P., 2022. Reinforcement Learning for systematic FX 
Brim, A., Jan. 2020. “Deep reinforcement Learning pairs trading with a double deep Q- 
Carapuço, J., Neves, R., Horta, N., Dec. 2018. Reinforcement Learning applied to forex 
machine Learning on EUR to USD with moving average methods and financial 
L. Chen and Q. Gao, “Application of deep reinforcement learning on automated stock 
agent-based reinforcement learning algorithm,” Proc. - 2018 IEEE Int. Conf. Agents, 
M. Y. Chen, A. K. Sangaiah, T. H. Chen, E. D. Lughofer, and E. Egrioglu, “Deep Learning 
multimodal deep reinforcement learning. Appl. Soft Comput. 112, 107788 https:// 
machine Learning. Math. Probl. Eng. 2020 https://doi.org/10.1155/2020/3589198. 
based on deep learning network. Expert Syst. Appl. 183, 115390 https://doi.org/ 
Chopra, R., Sharma, G.D., Nov. 2021. Application of artificial intelligence in stock 
Market forecasting: a critique, review, and Research agenda. J. Risk Financ. Manag. 
reinforcement Learning day trading system. Proc. Int. Jt. Conf. Neural Networks. 
returns of deep learning based trading strategies,” Int. Conf. Electr. Comput. Commun. 
Q. V. Dang, “Reinforcement Learning in Stock Trading,” Adv. Intell. Syst. Comput., vol. 
analysis with machine learning techniques. J. Financ. Data Sci. 2 (1), 42–57. https:// 
Reinforcement Learning with Candlestick Decomposing Features,” IEEE Access, vol. 
optimization using the reinforcement learning method: a cointegration approach,” 
Felizardo, L.K., et al., 2022. Outperforming algorithmic trading reinforcement learning 
F. G. D. C. Ferreira, A. H. Gandomi, and R. T. N. Cardoso, “Artificial Intelligence Applied 
Fior, J., Cagliero, L., Nov. 2020. Exploring the use of data at multiple Granularity levels 
in machine Learning-based stock trading. IEEE Int. Conf. Data Min. Work. ICDMW 
P. M. Fiorini and P. G. Fiorini, “A Simple Reinforcement Learning Algorithm for Stock 
Trading,” Proc. 11th IEEE Int. Conf. Intell. Data Acquis. Adv. Comput. Syst. Technol. 
S. Firouzi, X. Wang, and A. Totonchyfardmotlagh, “Machine Learning Forecasting of 
Proceedings - 2022 IEEE International Conference on Big Data, Big Data 2022, 2022. doi: 
recurrent reinforcement learning with candlesticks,” Proc. - 2015 IEEE Symp. Ser. 
Gai, K., Qiu, M., Sun, X., Feb. 2018. A survey on FinTech. J. Netw. Comput. Appl. 103, 
reinforcement learning: a comparative study. ACM International Conference 
P. Gogas and T. Papadimitriou, “Machine Learning in Economics and Finance,” 
J. W. Goodell, S. Kumar, W. M. Lim, and D. Pattnaik, “Artificial intelligence and machine 
bibliometric analysis,” Journal of Behavioral and Experimental Finance, vol. 32. 
series data. Expert Syst. Appl. 209 https://doi.org/10.1016/j.eswa.2022.118260. 
using GRU, LSTM and bi-LSTM machine Learning algorithms. AI 2 (4), 477–496. 
Hirchoua, B., Ouhbi, B., Frikh, B., May 2021. Deep reinforcement learning based trading 
Hushani, P., 2019. Using autoregressive modelling and machine Learning for stock 
Jaquart, P., K¨opke, S., Weinhardt, C., Nov. 2022. Machine learning for cryptocurrency 
market prediction and trading. J. Financ. Data Sci. 8, 331–352. https://doi.org/ 
Strategy Using Machine Learning,” in 2020 IEEE 7th International Conference on 
Convolutional Neural Network and Stacked Gated Recurrent Unit,” Data, vol. 7, no. 
A. P. Ketsetsis et al., “Deep Learning Techniques for Stock Market Prediction in the 
Market? an approach based on machine Learning in stock trading. Comput. Intell. 
Kim, M., Aug. 2021. Adaptive trading system integrating machine learning and back- 
reinforcement Learning with trading and stop-loss Boundaries. Complexity 2019. 
T. E. Koker and D. Koutmos, “Cryptocurrency Trading Using Machine Learning,” J. Risk 
prediction using machine learning and statistical techniques. Mater. Today Proc. 49, 
reinforcement learning-based trading by using a generative adversarial market 
Forecasting,” Annals of Data Science, vol. 10, no. 1. Springer Science and Business 
reinforcement learning with hybrid loss for trading signal generation. Inf. Sci. (ny) 
Lahmiri, S., Bekiros, S., Apr. 2020. Intelligent forecasting with machine learning trading 
Lahmiri, S., Bekiros, S., Mar. 2021. Deep Learning forecasting in cryptocurrency high- 
prediction using machine deep learning models: a comprehensive review”, CITISIA 
analysis of stock trading strategies. Neural Comput. Appl. 34 (16), 13267–13279. 
Y. Lei, Q. Peng, and Y. Shen, “Deep Learning for Algorithmic Trading: Enhancing MACD 
Switching Setup Based on Reinforcement Learning Applied to a Multiagent System 
Technology and Mechatronics Automation, ICMTMA 2019, Institute of Electrical and 
Li, A.W., Bastos, G.S., 2020. Stock market forecasting using deep learning and technical 
analysis: a systematic review. IEEE Access 8, 185232–185242. https://doi.org/ 
Li, Y., Wu, J., Bu, H., Aug. 2016. “When quantitative trading meets machine learning: a 
Li, Y., Ni, P., Chang, V., Dec. 2020. Application of deep reinforcement Learning in stock 
trading strategies and stock forecasting. Computing 102 (6), 1305–1322. https://doi. 
Liu, C., et al., Jan. 2022. Forecasting the Market with machine Learning algorithms: an 
application of NMC-BERT-LSTM-DQN-X algorithm in quantitative trading. ACM 
Trans. Knowl. Discov. from Data 16 (4), 1–22. https://doi.org/10.1145/3488378. 
architecture incorporating machine Learning models and genetic algorithm 
optimization for forex trading. FinTech 1 (2), pp. https://doi.org/10.3390/ 
Lucarelli, G., Borrotti, M., May 2019. A deep reinforcement Learning approach for 
International Conference on Control, Automation and Systems, 2018, pp. 92–96. 
reinforcement learning algorithm for stock trading. Neurocomputing 449, 290–302. 
A. Maalla, C. Zhuang, and Q. Feng, “Research on Financial Data Analysis Based on 
Applied Deep Learning in Quantitative Trading,” in IMCEC 2021 - IEEE 4th Advanced 
Information Management, Communicates, Electronic and Automation Control Conference, 
Networks and the DQN Learning Algorithm,” in 2021 International Conference 
Forecasting using Deep Learning with an Optimized Trading Strategy,” 2019 IEEE 
C. Milana and A. Ashta, “Artificial intelligence techniques in finance and financial 
A. Millea, “Deep reinforcement learning for trading—a critical survey,” Data, vol. 6, no. 
indices modelling and trading utilizing deep Learning techniques: the ATHENS SE 
Investment Optimization Using Instantaneous Stochastic Gradient 
Ascent—Formulation of an Adaptive Machine Learning Approach,” Sustain., vol. 14, 
trading with deep reinforcement Learning. Lecture Notes in Computer Science 
(including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in 
Nasirtafreshi, I., 2022. Forecasting cryptocurrency prices using recurrent neural network 
and long short-term memory. Data Knowl. Eng. 139 https://doi.org/10.1016/j. 
trading and social media indicators for cryptocurrency price classification through 
deep learning. Expert Syst. Appl. 198 https://doi.org/10.1016/j.eswa.2022.116804. 
for financial trading: a fusion approach of machine learning and portfolio selection. 
M., Naved, M., Jan. 2023. Applications of artificial intelligence in business 
Learning and imitative reinforcement Learning. IEEE Access 9, 152310–152321. 
trading strategies for bitcoin leveraging deep Learning-based financial news analysis. 
Peng, Y.L., Lee, W.P., 2021. Data selection to avoid overfitting for foreign exchange 
intraday trading with machine learning. Appl. Soft Comput. 108, 107461 https:// 
E. S. Ponomarev, I. V. Oseledets, and A. S. Cichocki, “Using Reinforcement Learning in 
Rundo, F., Oct. 2019. Deep LSTM with reinforcement learning layer for financial trend 
C. Sadewa and Harlili, “Exploration and analysis of some online machine learning on 
Sarangi, P.K., Chawla, M., Ghosh, P., Singh, S., Singh, P.K., 2020. FOREX trend analysis 
using machine Learning techniques: INR vs USD currency exchange rate using ANN- 
application of machine Learning. Expert Syst. Appl. 158, 113490 https://doi.org/ 
reinforcement learning approach,” Appl. Sci., vol. 10, no. 4, 2020, doi: 10.3390/ 
trading system based on Evolutionary optimized technical analysis Parameters. 
based on deep learning architectures. Multimed. Tools Appl. 81 (10), 14153–14171. 
Sharma, M., Shekhawat, H.S., 2022. Portfolio optimization and return prediction by 
H. G. Shin, I. Ra, and Y. H. Choi, “A Deep Multimodal Reinforcement Learning System 
W. Si, J. Li, R. Rao, and P. Ding, “A multi-objective deep reinforcement learning 
S. W. Sidehabi, Indrabayu, and S. Tandungan, “Statistical and Machine Learning 
approach in forex prediction based on empirical data,” in Proceedings - 
H. Song and H. Choi, “Forecasting Stock Market Indices Using the Recurrent Neural 
Network Based Hybrid Models: CNN-LSTM, GRU-CNN, and Ensemble Models,” Appl. 
Model Based on PRE and Deep Neural Network,” Data, vol. 7, no. 5, p. 51, May 2022, 
Machine Learning Approach: A Pilot Study,” 2021 4th Int. Conf. Inf. Commun. 
J. Sun, Y. Zhou, and J. Lin, “Using machine learning for cryptocurrency trading,” Proc. - 
Sun, T., Wang, J., Ni, J., Cao, Y., Liu, B., May 2019. End-to-end deep learning based 
trading platform and its evaluation. ACM Int. Conf. Proceeding Ser. 5 https://doi. 
Sun, S., Wang, S., Wei, Y., Oct. 2020. A new ensemble deep learning approach for 
exchange rates forecasting and trading. Adv. Eng. Informatics 46, 101160. https:// 
Ta, V.D., Liu, C.M., Addis, D., Dec. 2018. Prediction and portfolio optimization in 
quantitative trading using machine learning techniques. ACM Int. Conf. Proceeding 
Ta, V.D., Liu, C.M., Addis, D., 2018. Prediction and portfolio optimization in quantitative 
trading using machine learning techniques. In: In ACM International Conference 
rules via deep reinforcement learning. Expert Syst. Appl. 195 https://doi.org/ 
“Employing Deep Learning in Intraday Stock Trading,” Proc. - 2020 5th Int. Conf. Res. 
Th´eate, T., Ernst, D., 2020. An application of deep reinforcement learning to algorithmic 
Th´eate, T., Ernst, D., Jul. 2021. An application of deep reinforcement learning to 
Tsai, Y.C., Wang, C.C., Szu, F.M., Wang, K.J., 2020. Deep reinforcement Learning for 
Tsaih, R.H., Kuo, B.S., Lin, T.H., Hsu, C.C., 2018. The use of big data analytics to predict 
A. Tsantekidis and A. Tefas, “Transferring trading strategy knowledge to deep learning 
models,” Knowl. Inf. Syst. 2020 631, vol. 63, no. 1, pp. 87–104, Sep. 2020, doi: 
reinforcement learning for financial trading using neural network distillation. IEEE 
Jul. 2021. Price trailing for financial trading using deep reinforcement Learning. 
IEEE Trans. Neural Networks Learn. Syst. 32 (7), 2737–2846. https://doi.org/ 
M. Ugur Gudelek, S. Arda Boluk, and A. Murat Ozbayoglu, “A deep learning based stock 
Vogl, M., R¨otzel, P.G., Homes, S., 2022. Forecasting performance of wavelet neural 
financial market data sets. Mach. Learn. Appl. 8 https://doi.org/10.1016/j. 
reinforcement Learning”, 2021 int. Conf. Appl. Artif. Intell. ICAPAI 2021. https:// 
currencies: a deep reinforcement learning with multidimensional attention gating 
trading strategies with deep reinforcement learning methods. Inf. Sci. (ny) 538, 
Deep Reinforcement Learning,” Proc. Int. Jt. Conf. Neural Networks, vol. 2019-July, 
classification of price-limit-hitting stocks. Inf. Sci. (ny) 607. https://doi.org/ 
deep reinforcement Learning”, in ACM international conference proceeding series. 
neural networks. Decis. Anal. J. 7, 100235 https://doi.org/10.1016/J. 
Yang, H., Liu, X.Y., Zhong, S., Walid, A., 2020. “Deep reinforcement learning for 
automated stock trading: an ensemble strategy”, ICAIF 2020–1st ACM int. Conf. AI 
system using gaussian inverse reinforcement learning algorithm. Expert Syst. Appl. 
Y. Yuan, W. Wen, and J. Yang, “Using Data Augmentation Based Reinforcement Learning 
K. S. Zarkias, N. Passalis, A. Tsantekidis, and A. Tefas, “Deep Reinforcement Learning for 
K. ˙Zbikowski, “Application of Machine Learning Algorithms for Bitcoin Automated 
Zhang, L., May 2021. “Pair trading with machine Learning strategy in China stock 
Zhang, H., Jul. 2021. “A Comparative evaluation of predominant deep Learning 
quantified stock trading strategies”, 2021 IEEE 4th int. Conf. Big Data Artif. Intell. 
J. Zhang and D. Maringer, “Using a Genetic Algorithm to Improve Recurrent 
Reinforcement Learning for Equity Trading,” Comput. Econ. 2015 474, vol. 47, no. 4, 
Zhang, S., Luo, J., Wang, S., Liu, F., 2023. Oil price forecasting: a hybrid GRU neural 
Zhang, W., Yin, T., Zhao, Y., Han, B., Liu, H., 2023. Reinforcement Learning for stock 
index trading strategy based on reinforcement Learning. Lect. Notes Comput. Sci. 
Panel for the Future of Science and Technology
intelligence (AI) technologies. It also reviews the guidelines and
certain implications of AI, such as those regarding human
STOA | Panel for the Future of Science and Technology
the Panel for the Future of Science and Technology (STOA), and managed by the Scientific Foresight Unit, within
of Autonomous and Intelligent Systems (A/IS)) and Jack Stilgoe (Department of Science & Technology Studies,
The ethics of artificial intelligence: Issues and initiatives
and implementation of artificial intelligence (AI) technologies. It also reviews the guidelines and
certain implications of AI, such as those regarding human relationships.
European Commission's definition of AI as 'systems that display intelligent behaviour'. Other key
terms defined in this chapter include intelligence and how this is used in the context of AI and
intelligent robots (i.e. robots with an embedded AI), as well as defining machine learning, artificial
neural networks and deep learning, before moving on to consider definitions of morality and ethics
and how these relate to AI.
the deployment of AI. The report begins by outlining a number of potential benefits that could
arise from AI as a context in which to situate ethical, social and legal considerations. Within the
context of issues for society, the report considers the potential impacts of AI on the labour market,
consequences of deployment of AI on the workplace. The report considers the potential impact of
AI on inequality and how the benefits of AI could be shared within society, as well as issues
concerning the concentration of AI technology within large internet companies and political
STOA | Panel for the Future of Science and Technology
Chapter 2 moves on to consider the impact of AI on human psychology, raising questions about the
impact of AI on relationships, as in the case of intelligent robots taking on human social roles, such
unanticipated ways. This section also considers the question of personhood, and whether AI
Impacts on the financial system are already being felt, with AI responsible for high trading volumes
of equities. The report argues that, although markets are suited to automation, there are risks
including the use of AI for intentional market manipulation and collusion.
AI technology also poses questions for both civil and criminal law, particularly whether existing legal
criminal and contractual misconduct involving AI. While it may seem unlikely that AIs will be
claiming they did not know the AI could or would do such a thing). In addition to challenging
questions around liability, AI could abet criminal activities, such as smuggling (e.g. by using
Large-scale deployment of AI could also have both positive and negative impacts on the
pollution and waste, as well as energy consumption. However, AI could help with waste
The potential impacts of AI are far-reaching, but they also require trust from society. AI will need to
Chapter 3 explores ethical initiatives in the field of AI. The chapter first outlines the ethical
and justice; control and the ethical use (or misuse) of AI; environmental harm and sustainability;
All initiatives focus on human rights and well-being, arguing that AI must not affect basic and
standards and regulatory bodies to oversee use of AI and ensure that human well-being is prioritised
throughout the design phase. The Montreal Protocol argues that AI should encourage and support
Another prominent issue identified in these initiatives is concern about the impact of AI on the
humans might form an intimate relationship. Emotional harm may also arise should AI be designed
The ethics of artificial intelligence: Issues and initiatives
AI to be auditable as a means of ensuring that manufacturers, designers and owners/operators of AI
means in the context of AI.
compliance. Particularly in situations where AI replaces human decision-making initiatives, we argue
that AI must be safe, trustworthy, reliable and act with integrity. The IEEE focus on the need for
in design, while the Japanese Society for AI, suggests that AI should be designed with social
and the risk that AI could widen gaps between developed and developing economies. There is
concern that AI-related degree programmes fail to equip designers with appropriate knowledge of
Legal issues are also addressed in the initiatives, with the IEEE arguing that AI should not be granted
practically give AI legal autonomy.
resource use but also acknowledgement that AI could play a role in conservation and sustainable
stewardship. The UNI Global Union states that AI should put people and plants first, striving to
education with regard to the potential harms of AI. The initiatives suggest a range of ways in which
services. The first case study highlights particular risks associated with embodied AI, which have
moving parts that can cause injury. Healthcare AI applications also have implications for training of
healthcare professionals and present data protection, legal and equality challenges. The case study
in particular. The use of AI in healthcare also raises questions about trust, for example, how trust in
professionals might change if they are seen as 'users' of technology.
vehicles (AVs). In the context of driving, six levels of automation are recognised by SAE International:
no automation, hands on (e.g. Cruise Control), hands off (driver still monitors driving), eyes off (driver
STOA | Panel for the Future of Science and Technology
technology and the lack of standards, processes and regulatory frameworks for accident
Manufacturers of autonomous vehicles also collect significant amounts of data from AVs, which
raises questions about the privacy and data protection rights of drivers and passengers. AVs could
A final case study explores the use of AI in warfare and the potential for AI applications to be used
as weapons. AI is already used in military contexts. However, there are particular aspects of
developing AI technologies that warrant consideration. These include: lethal autonomous weapons;
Key ethical issues arising from greater military use of AI include questions about the involvement of
Law). Would increasing use of AI reduce the threshold for going to war (affecting global stability)?
Chapter 4 discusses emerging AI ethics standards and regulations. There are a number of
emerging standards that address emerging ethical, legal and social impacts of robotics and AI.
Strategies on AI. Canada launched the first national strategy on AI in March 2017, followed soon
international initiative on AI and supports the strategies of individual Member States. Strategies vary
feature prominently in AI initiatives. Other international AI initiatives that cover ethical principles
include: G7 Common Vision for the Future of AI, Nordic-Baltic Region Declaration on AI, OECD
Principles on AI and the World Economic Form's Global AI Council. The United Nations has several
initiatives relating to AI, including the AI for Good Global Summit; UNICRI Centre for AI and Robotics;
national and international strategies in relation to AI, highlighting gaps. It questions whether the
AI, 2019) for the governance of AI are sufficient to meet the challenges it poses. The analysis
The ethics of artificial intelligence: Issues and initiatives
2.5.4 Ways AI could help the planet............................................................................................................29
3. Ethical initiatives in the field of artificial intelligence.....................................................................................37
STOA | Panel for the Future of Science and Technology
4. AI standards and regulation .................................................................................................................................... 66
5. National and International Strategies on AI ...................................................................................................... 71
5.7. International AI Initiatives, in addition to the EU .................................................................................... 80
5.8. Government Readiness for AI ......................................................................................................................... 82
6.2. Addressing the governance challenges posed by AI ............................................................................. 85
The ethics of artificial intelligence: Issues and initiatives
of AI __________________________________________________________________________ 5
Figure 3: National and International Strategies on AI published as of May 2019. ____________ 72
Table 2: IEEE 'human standards' with implications for AI _______________________________ 68
Table 3: Top 10 rankings for Government AI Readiness 2018/19. Source: Oxford Insights, 2019. 83
The ethics of artificial intelligence: Issues and initiatives
Rapid developments in artificial intelligence (AI) and machine learning carry huge potential benefits.
However it is necessary to explore the full ethical, social and legal aspects of AI systems if we are to
avoid unintended, negative consequences and risks arising from the implementation of AI in
This chapter introduces AI broadly, including current uses and definitions of intelligence. It also
defines robots and their position within the broader AI field.
1.1. What is AI – and what is intelligence?
The European Commission's Communication on Artificial Intelligence (European Commission,
2018a) defines artificial intelligence as follows:
'Artificial Intelligence (AI) refers to systems that display intelligent behaviour by analysing their
AI-based systems can be purely software-based, acting in the virtual world (e.g. voice assistants,
image analysis software, search engines, speech and face recognition systems) or AI can be
Within this report, we consider both software-based AI and intelligent robots (i.e. robots with an
embedded AI) when exploring ethical issues. Intelligent robots are therefore a subset of AI (whether
or not they make use of machine learning).
workplace (for a workmate robot). The 'environment' of a software AI is its context, which might be
clinical (for a medical diagnosis AI), or a public space – for face recognition in airports, for instance,
All present-day AIs and robots are examples of what we refer to as 'narrow' AI: a term that reflects
A long-term goal of AI and robotics research is so-called artificial general intelligence (AGI) which
STOA | Panel for the Future of Science and Technology
AI is often better than most humans at one particular task; examples are chess- or Go-playing AIs,
Machine learning is the term used for AIs which are capable of learning or, in the case of robots,
adapting to their environment. There are a broad range of approaches to machine learning, but
systems generally make use of Artificial Neural Networks (ANNs), which are trained by presenting
output (i.e. giraffe, lion, gorilla). This set of inputs and matched outputs is called a training data set.
a lion), even though that particular image with a lion wasn't present in the training data set. In
contrast, unsupervised learning has no training data; instead, the AI (or robot) must figure out on its
training data set must be truly representative of the task required; if not, the AI will exhibit bias.
Another limitation is that ANNs learn by picking out features of the images in the training data
snowy background as a wolf, because all examples of wolves in the images of the training data set
The term deep learning simply refers to (typically) supervised machine learning systems with large
(i.e. many-layered) ANNs and large training data sets.
It is important to note the terms AI and machine learning are not synonymous. Many highly capable
AIs and robots do not make use of machine learning.
1.2. Definition of morality and ethics, and how that relates to AI
AI ethics is concerned with the important question of how human developers, manufacturers and
operators should behave in order to minimise the ethical harms that can arise from AI in society,
either arising from poor (unethical) design, inappropriate application or misuse. The scope of AI
ethics spans immediate, here-and-now concerns about, for instance, data privacy and bias in current
AI systems; near- and medium-term concerns about, for instance, the impact of AI and robotics on
The ethics of artificial intelligence: Issues and initiatives
jobs and the workplace; and longer-term concerns about the possibility of AI systems reaching or
Within the last 5 years AI ethics has shifted from an academic concern to a matter for political as well
as public debate. The increasing ubiquity of smart phones and the AI-driven applications that many
of us now rely on every day, the fact that AI is increasingly impacting all sectors (including industry,
of an AI 'arms race', has prompted an extraordinary number of national and international initiatives,
AI (at least 22 different sets of ethical principles have been published since January 2017), new
Association), and a growing number of countries (and groups of countries) have announced AI
In this report we survey these initiatives in order to draw out the main ethical issues in AI and
Robots and artificial intelligence (AI) come in various forms, as outlined above, each of which raises
dilemmas and moral questions associated with the deployment of AI. This chapter explores in
Social impacts: this section considers the potential impact of AI on the labour market and economy
the risk that AI will further concentrate power and wealth in the hands of the few. Issues related to
privacy, human rights and dignity are addressed as are risks that AI will perpetuate the biases,
about the impact of AI technologies on democracy, suggesting that these technologies may operate
Financial system impacts: potential impacts of AI on financial systems are considered, including
Legal system impacts: there are a number of ways in which AI could affect the legal system,
including: questions relating to crime, such as liability if an AI is used for criminal activities, and the
extent to which AI might support criminal activities such as drug trafficking. In situations where an
AI is involved in personal injury, such as in a collision involving an autonomous vehicle, then
Impacts on trust: society relies on trust. For AI to take on tasks, such as surgery, the public will need
to trust the technology. Trust includes aspects such as fairness (that AI will be impartial),
transparency (that we will be able to understand how an AI arrived at a particular decision),
STOA | Panel for the Future of Science and Technology
accountability (someone can be held accountable for mistakes made by AI) and control (how we
might 'shut down' an AI that becomes too powerful).
In Chapter 3, Ethical initiatives in the field of artificial intelligence, the report reviews a wide
emerging in relation to AI. Section 3.1 discusses the issues each initiative is exploring and identifies
misuse) of AI; environmental harm and sustainability; informed use and existential risks. The chapter
Chapter 4 presents the current status of AI Ethical standards and regulation. At present only one
specifically addresses AI. However, the IEEE is developing a number of standards that affect AI in a
Finally, Chapter 5 explores National and international strategies on AI. The chapter considers
what is required for a trustworthy AI and visions for the future of AI as they are articulated in national
The ethics of artificial intelligence: Issues and initiatives
associated with the deployment of AI
According to the Future of Life Institute (n.d.), AI 'holds great economic, social, medical, security, and
Figure 1: Main ethical and moral issues associated with the development and implementation of AI
In the long term, AI may lead to 'breakthroughs' in numerous fields, says the Institute, from basic
STOA | Panel for the Future of Science and Technology
of AI, drawing insights from relevant academic literature. The issues discussed deal with impacts on:
People have been concerned about the displacement of workers by technology for centuries.
Automation, and then mechanisation, computing, and more recently AI and robotics have been
internal combustion engines. In the past, however, automation has often substituted for human
Nevertheless, there is widespread concern that artificial intelligence and associated technologies
AI is already widespread in finance, space exploration, advanced manufacturing, transportation,
impact of automation on 'blue-collar' jobs; however, as computers become more sophisticated,
creative, and versatile, more jobs will be affected by technology and more positions made obsolete.
Economists are generally enthusiastic about the prospects of AI on economic growth. Robotics
It is hard to quantify the effect that robots, AI and sensors will have on the workforce because we
are in the early stages of the technology revolution. Economists also disagree on the relative impact
of AI and robotics. One study asked 1,896 experts about the impact of emerging technologies; 48
(52%) expected that technology would not displace more jobs than it created by 2025. Those
Some argue that technology is already producing major changes in the workforce:
people can use technology to create and capture value. However, there's never been a worse time to be a worker
The ethics of artificial intelligence: Issues and initiatives
'as technology accelerates, machine automation may ultimately penetrate the economy to the extent
humans. But jobs analysing big data, mining information, and managing data sharing networks will be created'
If AI led to economic growth, it could create demand for jobs throughout the economy, including in
ways that are not directly linked to technology. For example, the share of workers in leisure and
the next 20 years. According to their analysis, telemarketers, title examiners, hand sewers,
photographic process workers, new accounts clerks, library technicians, and data-entry specialists
In a further study, the team surveyed 156 academic and industry experts in machine learning,
advising' were less likely than others to be automatable, while 'administering', 'information and data
Overall the model predicted very high automation potential for office, administrative support, and
automation were physical processes such as production, farming, fishing and forestry, and
occupations that were robust to automation included education, legal, community service, arts, and
tend to be the least amenable to automation. However, even this does not guarantee that an
STOA | Panel for the Future of Science and Technology
to be amenable to automation.
they will be the first generation to work alongside AI (Biavaschi et al., 2013). Even though many
young people have time to acquire relevant expertise, few gain training in science, technology,
the increasing use of digital technology, considering it to improve society, the economy, and their
technology in various aspects of their life and work (European Commission, 2017). However,
central to the issue of how AI will affect different demographics and the potential issues arising
increasing development and implementation of AI if nobody is to be disadvantaged or left behind
'When we're talking about 'AI for good', we need to define what 'good' means. Currently, the key
It is possible that AI and robotic technologies could exacerbate existing social and economic
'The biggest question around AI is inequality, which isn't normally included in the debate about AI ethics.
It is an ethical issue, but it's mostly an issue of politics – who benefits from AI?' (Jack Stilgoe)
The ethics of artificial intelligence: Issues and initiatives
AI and roboticstechnology are expected to allow companiesto streamline their businesses, making
increasing social inequalities. Consequently, individuals who hold ownership in AI-driven
Changes in employment related to automation and digitisation will not be expressed solely via job
losses, as AI is expected to create many numerous and new forms of employment (Hawksworth and
workers performing tasks such as tagging and moderating content – in this way, AI could bring an
additional human cost that must be considered when characterising the benefits of AI to society.
Building AI most often requires people to manage and clean up data to instruct the training
algorithms. Better (and safer) AI needs huge training data sets and a whole new outsourced industry
objects in images in order to create training data sets for machine learning systems (for example, to
generate training data sets for driverless car AIs) and (iii) interpreting queries (text or speech) that
an AI chatbot cannot understand. Collectively these jobs are sometimes known by the term
which AI is based (Gray, 2019).
The average consumer of AI technology may never know that a person was part of the process – the
functioning of the AI technologies. This may be especially the case where the labour force reside in
countries outside the EU or US – there are growing 'data-labelling' industries in both China and
STOA | Panel for the Future of Science and Technology
AI has the potential to bring significant and diverse benefits to society (Conn, 2018; UK Government
Institute (n.d.) states that AI may be capable of tackling a number of the most difficult global issues
A US report on AI, automation, and the economy (2016) highlights the importance of ensuring that
potential benefits of AI do not accumulate unequally, and are made accessible to as many people
as possible. Rather than framing the development of AI and automation as leading to an inevitable
outcome determined by the technology itself, the report states that innovation and technological
change 'does not happen in a vacuum': the future of AI may be shaped not by technological
the inventor or developer of an AI has great potential to determine its use and reach (Conn, 2018),
Automation is more applicable to certain roles than others (Duckworth et al., 2018), placing certain
considered analogous to AI. While electricity can make many areas more productive, remove
To ensure that AI's benefits are distributed fairly – and to avoid a whoever designs it first, wins
dynamic – one option may be to pre-emptively declare that AI is not a private good but instead for
the beneficial powers of AI for citizens, help navigate the AI-driven economic transition, and retain
and strengthen public trust in AI (Min, 2018). Brundage and Bryson (2016) agree with this call for
tensions that may accompany AI. AI-driven job losses will require new retraining programmes and
populations and the vulnerable – and on those building AI systems, to target any 'skewed product
According to Brundage and Bryson (2016), taking a proactive approach to AI policies is not
'premature, misguided [or] dangerous', given that AI 'is already sufficiently mature technologically
The ethics of artificial intelligence: Issues and initiatives
uncertainty'; and that AI is widely applied and proactively made accessible (especially in areas of
Considering the energy industry as an example, AI may be able to modernise the energy grid,
real-time, accessible data would also help them to select the most cost-efficient tariff for them, say
 'Does AI have to increase inequality? Could you design systems that target, for example, the needs of
the poorest people? If AI was being used to further benefit rich people more than it benefits poor people,
people, then what might we do about that? Is that an appropriate use of AI?' (Jack Stilgoe)
Nemitz (2018) writes that it would be 'naive' to ignore that AI will concentrate power in the hands
Internet delivers to them is shaped by a few mega corporations…the development of AI is
In particular, Nemitz is concerned that investigations into the impact of new technologies like AI on
who are not only shaping the development and deployment of AI, but also the debate on its
influence, they can also afford to buy new ideas and start-ups in the area of AI, or indeed any
STOA | Panel for the Future of Science and Technology
3. Collecting personal data. These corporations collect personal data for profit, and profile
dominance in AI innovation…must be seen together, and…must inform the present debate about
ethics and law for AI'.
of the falling costs of robotic technology. High costs can maintain diversity in economic systems.
Bryson (2019) also notes that the rise of AI could lead to wealth inequality and political upheaval.
AI will have profound impacts on privacy in the next decade. The privacy and dignity of AI users
dressing). However, other aspects of AI will also affect privacy. Smith (2018), President of Microsoft,
'[Intelligent 3] technology raises issues that go to the heart of fundamental human rights
Privacy and data rights
'Humans will not have agency and control [over their data] in any way if they are not given the tools to
One way in which AI is already affecting privacy is via Intelligent Personal Assistants (IPA) such as
The ethics of artificial intelligence: Issues and initiatives
storing their data (6%) and the 'creepy' nature of the device (4%) (Manikonda et al, 2018). However
Another aspect of AI that affects privacy is Big Data. Technology is now at the stage where longterm records can be kept on anyone who produces storable data — anyone with bills, contracts,
Any one of us can be identified by facial recognition software or data mining of our shopping or
Machine learning allows us to extract information from data and discover new patterns, and is able
to turn seemingly innocuous data into sensitive, personal data. For example, patterns of social
AI applications based on machine learning need access to large amounts of data, but data subjects
have limited rights over how their data are used (Veale et al., 2018). Recently, the EU adopted new
General Data Protection Regulations (GDPR) to protect citizen privacy. However, the regulations
only apply to personal data, and not the aggregated 'anonymous' data that are usually used to train
models.
In addition, personal data, or information about who was in the training set, can in certain cases be
systems. For instance, while people have rights about how their personal data are used and stored,
they have limited rights over trained models. Instead, models have been typically thought to be
stands, there are no data protection rights nor obligations concerning models in the period after
This brings up a number of ethical issues. What level of control will subjects have over the data that
it is used for, given their stake in training it? Could machine learning systems seeking patterns in
data inadvertently violate people's privacy if, for example, sequencing the genome of one family
Veale et al. (2018) argue that extra protections should be given to people whose data have been
used to train models, such as the right to access models; to know where they have originated from,
STOA | Panel for the Future of Science and Technology
AI has important repercussions for democracy, and people's right to a private life and dignity. For
instance, if AI can be used to determine people's political beliefs, then individuals in our society
Alternatively, if AI can judge people's emotional states and gauge when they are lying, these people
This might sound like a nightmare dystopian vision, but the use of AI to spy is increasing. For
example, an Ohio judge recently ruled that data collected by a man's pacemaker could be used as
evidence that he committed arson (Moon, 2017). Data collected by an Amazon Alexa device was
televisions, now regularly collect data that may be used as evidence or accessed by hackers. Video
AI may also be used to monitor and predict potential troublemakers. Face recognition capacities are
technology could be used to penalise students for not paying attention or penalise prisoners who
There is a risk that governments fearing dissent will use AI to suppress, imprison and harm
Law enforcement agencies in India already use 'proprietary, advance hybrid AI technology' to
does the AI discussed operate in the absence of safeguards to prevent misuse, making them ripe for
The ethics of artificial intelligence: Issues and initiatives
profoundly affected by AI. AI has been widely touted by technology companies as a solution to
In India, sentiment analysis tools are increasingly deployed to gauge the tone and nature of speech
Government has also expressed interest in using AI to identify fake news and boost India's image on
AI is created by humans, which means it can be susceptible to bias. Systematic bias may arise as a
result of the data used to train systems, or as a result of values held by system developers and users.
It most frequently occurs when machine learning applications are trained on data that only reflect
reinforced by AI systems.
Examples of AI bias
The investigative journalism organisation ProPublica showed that COMPAS, a machine learning
distribute adverts for well-paid jobs to men than women (Datta et al., 2015). AI-informed
STOA | Panel for the Future of Science and Technology
There have been a few activities that have demonstrated the bias contained in data training sets.
but the creators say that it is an interface that shows users how a machine learning model is
interpreting the data and how results can be quite disturbing.
As many machine-learning models are built from human-generated data, human biases can easily
result in a skewed distribution in training data. Unless developers work to recognise and counteract
these biases, AI applications and products may perpetuate unfairness and discrimination. AI that is
imprisoned or detained. Using AI to perform credit checks could result in some individuals being
unfairly refused loans, making it difficult for them to escape a cycle of poverty (O'Neil 2016). If AI is
This problem is exacerbated by the fact that AI applications are usually 'black boxes', where it is
impossible for the consumer to judge whether the data used to train them are fair or representative.
on making machine learning fair, accountable and transparent, and more public-facing activities
and implementation of AI could threaten democracy in other ways too.
Big Data, politicians have access to huge amounts of information that allow them to target specific
This may be a good thing for politicians, but there is a great deal of evidence that AI-powered
5 https://www.vice.com/en_uk/article/xweagk/ai-face-app-imagenet-roulette
The ethics of artificial intelligence: Issues and initiatives
In addition to shaping online debate, AI can be used to target and manipulate individual voters.
During the U.S. 2016 presidential election, the data science firm Cambridge Analytica gained access
to the personal data of more than 50 million Facebook users, which they used to psychologically
which citizens can vote without manipulation — and AI threatens to undermine this process.
Some commentators have questioned whether democracies are particularly suited to the age of AI
and machine learning, and whether its deployment will enable countries with other political
STOA | Panel for the Future of Science and Technology
A centrally planned, state-controlled economy may well be better suited to a new AI age, as it is less
population means that Chinese businesses have access to huge amounts of data, with relatively few
restraints on how those data can be used. In China, there are no privacy or data protection laws,
such as the new GDPR rules in Europe. As China could soon become the world leader in AI, this
means it could shape the future of the technology and the limits on how it is used.
'The last few years suggest digital technology thrives perfectly well under monopolistic conditions:
the bigger a company is, the more data and computing power it gets, and the more efficient it
becomes; the more efficient it becomes, the more data and computing power it gets, in a selfperpetuating loop' (Bartlett, 2018). According to Bartlett, people's love affair with 'convenience'
AI is getting better and better at modelling human thought, experience, action, conversation and
'The biggest risk [of AI] that anyone faces is the loss of ability to think for yourself. We're already seeing
It is also possible that people could become psychologically dependent on robots. Technology is
6 The word’s first chatbot ELIZA, developed by AI pioneer Joseph Weizenbaum showed that many early users were
The ethics of artificial intelligence: Issues and initiatives
have to 'systematically delude themselves regarding the real nature of their relation with the [AI]'
(Christakis, 2019). In other words, AI could change how loving and kind we are—not just in our direct
STOA | Panel for the Future of Science and Technology
Both of these studies demonstrate that AI can improve the way humans relate to one another.
However, AI can also make us behave less productively and less ethically. In another experiment,
The fact that AI might reduce our ability to work together is concerning, as cooperation is a key
feature of our species. 'As AI permeates our lives, we must confront the possibility that it will stunt
consider giving AI systems 'personhood' and moral or legal agency? One way of programming AI
systems is 'reinforcement learning', where improved performance is reinforced with a virtual reward.
Scholars have increasingly discussed the legal status(es) of robots and AI systems over the past three
'Artificial Intelligence and Robotics Experts' in April 2018 which stated that 'the creation of a Legal
The majority of ethics research regarding AI seems to agree that AI machines should not be given
The ethics of artificial intelligence: Issues and initiatives
Markets are well suited to automation, as they now operate almost entirely electronically,
generating huge volumes of data at high velocity, which require algorithms to digest. The
invested in this technology to the extent that they have. In other words, algorithmic trading can
the increasing use of sophisticated machine learning techniques makes it difficult to understand
learning, an AI can learn the technique of order-book spoofing, which involves placing orders with
STOA | Panel for the Future of Science and Technology
the first place (Ezrachi and Stucke, 2016). Crucially, for collusion to take place, an algorithm does not
manipulation, however could an autonomous algorithm even meet the legal definition of market
The creation of AI machines and their use in society could have a huge impact on criminal and civil
Arguably, the most important near-term legal question associated with AI is who or what should be
liable for tortious, criminal, and contractual misconduct involving AI and under what conditions.
The ethics of artificial intelligence: Issues and initiatives
The increasing delegation of decision making to AI will also impact many areas of law for which mens
What would happen, for example if an AI program chosen to predict successful investments and
pick up on market trends made a wrong evaluation that led to a lack of capital increase and hence,
evaluation (Pagallo, 2017).
Existing liability models may be inadequate to address the future role of AI in criminal activities (King
comprise an intention to commit the actus reus using an AI-based application, or knowledge that
AI's criminal act or omission. This provides a great incentive for human agents to avoid finding out
what precisely the machine learning system is doing, since the less the human agents know, the
in liability being assigned to the person who deployed the AI regardless of whether they knew about
Kingston (2018) references a definition provided by Hallevy (2010) on how AI actions may be viewed
under criminal law. According to Hallevy, these legal models can be split into three scenarios:
commit the crime, then the instructor is held criminally liable. Under this model, an AI may
accomplice. This scenario may hold when an AI that was designed for a 'good' purpose is
STOA | Panel for the Future of Science and Technology
hold for an AI that was programmed to do a 'bad' thing, but to those that are
misappropriated. Anyone capable and likely of foreseeing an AI being used in a specific
consequences of misuse are spelt out in the AI instructions – which is unlikely).
3. Direct liability. This model attributes both actus and mens rea to an AI. However, while actus
rea (the action or inaction) is relatively simple to attribute to an AI, says Kingston (2018),
attributing mens rea (a guilty mind) is more complex. For example, the AI program 'driving'
possible issues that arise when considering AI to be directly liable. For example, could an AI
infected by a virus claim a defence similar to coercion or intoxication, or an AI that is
Identifying who exactly would be held liable for an AI's actions is important, but also potentially
There is a risk that AI robots could manipulate a user's mental state in order to commit a crime. This
In the future AI could be used by organised criminal gangs to support the trafficking and sale of
banned substances. Criminals could use AI equipped unmanned vehicles and autonomous
The ethics of artificial intelligence: Issues and initiatives
Social bots could also be used to harass people. Now that AI can generate more sophisticated fake
AI robots could also be used to torture and interrogate people, using psychological (e.g., mimicking
imprisonment for AI-caused offences against a person is difficult. It is clear that an AA cannot be
There is a danger that AI embodied robots could be used to promote sexual objectification, sexual
STOA | Panel for the Future of Science and Technology
When considering the possible consequences and misuse of an AI, the key question is: who
is responsible for the actions of an AI? Is it the programmers, manufacturers, end users, the
AI itself, or another? Is the answer to this question the same for all AI or might it differ, for
According to the European Parliament Resolution (2017) on AI, legal responsibility for an
AI’s action (or inaction) is traditionally attributed to a human actor: the owner, developer,
manufacturer or operator of an AI, for instance. For example, self-driving cars in Germany
networks: if an action cannot be predicted by the developer because an AI has sufficiently
mechanisms pose a challenge in regulating AI and assigning blame, say Atabekov and
Yastrebov (2018), with autonomous AI in particular raising the question of whether a new
Taddeo and Floridi (2018) highlight the concept of ‘distributed agency’. As an AI’s actions
each with different motivations, backgrounds, and knowledge – then an AI outcome may
responsibility. One way to ensure that AI works towards 'preventing evil and fostering
holds all agents accountable for their role in the outcomes and actions of an AI (Taddeo
Different applications of AI may require different frameworks. For example, when it comes
Learning machines and autonomous AI are other crucial examples. Their use may create a
may, in principle, be unable to predict a given AI’s future behaviour – and thus cannot be
AI deviates from the initial programming to become a product of its interactions with its
echoed by Scherer (2016), who states that AI has so far been developed in 'a regulatory
of AI and responsibility.
The ethics of artificial intelligence: Issues and initiatives
AI could be used to gather personal data, and forge people's identities. For example, social media
number, or relationship history (Bilge et al., 2009). AI could manipulate people by building rapport
AI could also be used to commit banking fraud by forging a victim's identity, including mimicking a
person's voice. Using the capabilities of machine learning, Adobe's software is able to learn and
STOA | Panel for the Future of Science and Technology
nature of the evidence, such as complex algorithms and sensor data is also likely to make litigation
liability). A plaintiff would need multiple experts to recover and find the defect in the algorithm,
AI and robotics technologies require considerable computing power, which comes with an energy
cost. Can we sustain massive growth in AI from an energetic point of view when we are faced with
electrical cars and smartphones - has already damaged the environment, and AI will likely increase
environments that are dangerous to human operators – leading to further automation of mining
As well as the toll that increased mining and waste will have on the environment, adoption of AI
technology, particularly machine learning, will require more and more data to be processed. And
that requires huge amounts of energy. In the United States, data centres already account for about
The ethics of artificial intelligence: Issues and initiatives
AI will also require large amounts of energy for manufacturing and training – for example, it would
take many hours to train a large-scale AI model to understand and recognise human language such
language processing AI is over seven times that of an average human in one year, and roughly 1.5
2.5.4 Ways AI could help the planet
Alternatively AI could actually help us take better care of the planet, by helping us manage waste
There are also applications for AI in conservation settings. For example, deep-learning technology
AI is set to change our daily lives in domains such as transportation; the service industry; health-care;
The overwhelming consensus amongst the research community is that trust in AI can only be
are how much control we want to exert over AI machines, and if, for example we want to always
While robots and AI are largely viewed positively by citizens across Europe, they also evoke mixed
attitudes towards robots and AI (survey 382), and towards increasing digitisation and automation
widespread use of robots and advanced technology in society. For example, while respondents
STOA | Panel for the Future of Science and Technology
'In order for AI to reach its full potential, we must allow machines to sometimes work autonomously,
'We trust machine learning algorithms to indicate the best decision to make when hiring a
properly. Constantly supervising a machine learning algorithm used to make a decision would
flagging that the outcome of an algorithm may not be objective. However in the long term, an
In order to trust AI it must be fair and impartial. As discussed in section 3.4, as more and more
decisions are delegated to AI, we must ensure that those decisions are free from bias and
it's vital that decisions made by AI are fair, and do not deepen already entrenched social inequalities.
impossible to know what algorithms based on neural networks are actually learning when you train
them with data. For example, the COMPAS algorithm, which assessed how likely someone was to
The ethics of artificial intelligence: Issues and initiatives
algorithms were not actually given people's race as an input. Instead the algorithm inferred this
sensitive data from other information, e.g. address.
For instance, one study found that two AI programs that had independently learnt to recognise
one AI focused rightly on the animal's features, the other based its decision wholly on a bunch of
copyright tag for the horse pictures. The AI worked perfectly for entirely the wrong reasons.
To devise a fair algorithm, first you must decide what a fair outcome looks like. Corbett-Davies et al.
(2017) describe four different definitions of algorithmic fairness for an algorithm that assesses
3. Predictive equality - where the accuracy of decisions is equal across race groups, as
notions of fairness conflict with one another, and it is impossible to have an algorithm that meets all
requires transparency. However as we will find out, it is not always easy to find out why an algorithm
came to a particular decision – many AIs employ complex 'neural networks' so that even their
its algorithm a trade secret and would not disclose its workings. The teachers took their case to court,
This case study highlights the importance of transparency for building trust in AI - it should always
STOA | Panel for the Future of Science and Technology
reflect concerns over trust, data access, and data use — all of which relate strongly to the idea of
transparency and of understanding what AI gathers, why, and how one may access the data being
Transparency can be very difficult with modern AI systems, especially those based on deep learning
systems. Deep learning systems are based on artificial neural networks (ANNs), a group of
never change its behaviour, however systems based on machine learning—by definition—change
The AI Now Institute at New York University, which researches the social impact of AI, recently
and other faults are swiftly corrected (AI Now Report, 2018).
In many cases, it may be possible to find out how an algorithm came to a particular decision without
'opening the AI black box'. Rather than exposing the full inner workings of an AI, researchers recently
developed a way of working out what it would take to change their AI's decision (Wachter et al.,
2018). Their method could explain why an AI turned down a person's mortgage application, for
algorithms are fundamentally understandable pieces of technology. He makes the point that
technology itself, which is always built for a specific purpose, and can also always be understood in
systems – systems must be designed so that they support analysis.
The ethics of artificial intelligence: Issues and initiatives
Other issues and problems with transparency include the fact that software and data are proprietary
Transparency also conflicts with privacy, as people involved in training machine learning models
may not want their data, or inferences about their data to be revealed. In addition, the lay public, or
transparency is often taken to mean the disclosure of source code or data, we don't have to see the
receive explanations that may seem plausible. Automation bias, the phenomenon in which humans
The simplest way to understand a piece of technology is to understand what it was designed to do,
evaluation of the program during development. In other words, measuring the performance of a
it is supposed to – a concept known as construct validity; and whether the data accurately reflects
For example a machine learning model tasked with conducting credit checks could inadvertently
Algorithm auditors
Larsson et al. (2019) suggest a role for professional algorithm auditors, whose job would be to
be an autonomous vehicle algorithm auditor, who could provide simulated traffic scenarios to
STOA | Panel for the Future of Science and Technology
function is to 'monitor, audit, and hold operational AI programs accountable' (Etzioni and Etzioni
2016). For example, one idea would be to have an algorithm that conducts real-time assessments of
the amount of bias caused by a news filtering algorithm, raising an alarm if bias increases beyond a
'How do decision-makers make sense of what decisions get made by AI technologies and how these
decisions are different to those made by humans?... the point is that AI makes decisions differently from
Another method of ensuring trust of AI is through accountability. As discussed, accountability
ensures that if an AI makes a mistake or harms someone, there is someone that can be held
responsible, whether that be the designer, the developer or the corporation selling the AI. In the
responsible AI. Algorithmic accountability, according to Caplan et al. (2018), deals with the
technology is, in general, trusted if it brings benefits and is safe and well regulated. Their paper
argues that one key element in building trust in AI is ethical governance – a set of processes,
When it comes to public perception of robots and advanced technology, regulation and
The ethics of artificial intelligence: Issues and initiatives
between 88% and 91% of those surveyed declared that robots and advanced technology must be
Another issue which affects public trust of AI is control. Much of this relates to fears around the idea
of 'Superintelligence' - that as artificial intelligence increases to the point that it surpasses human
human extinction. A related fear is that, even if an AI agent was carefully designed to have goals
However, while most researchers agree this threat is unlikely to occur, to maintain trust in AI, it is
important that humans have ultimate oversight over this technology.
label data for training machine learning algorithms. For example when you mark an email as 'spam',
you are one of many humans in the loop of a complex machine learning algorithm, helping it in its
continuous quest to improve email classification as spam or non-spam.
However HITL can also be a powerful tool for regulating the behaviour of AI systems. For instance,
fulfils two major functions in a HITL AI system (Rahwan, 2018):
However, although HITL is useful for building AI systems that are subject to oversight, it may not be
enough. AI machines that make decisions with wider societal implications, such as algorithms that
As a way to address some of the threats of artificial intelligence, researchers have proposed ways to
stop an AI system before it has a chance to escape outside control and cause harm. A so-called 'big
STOA | Panel for the Future of Science and Technology
commentators fear that a sufficiently advanced AI machine could anticipate this move and defend
The red button raises wider practical questions about shutting down AI systems in order to keep
them safe. What is the best way to accomplish that, and for what specific kinds of AI systems?
Orseau and Armstrong (2016) recently published a paper about how to prevent AI programmed
through reinforcement learning (RL) from seeing interruptions as a threat. For example, an
algorithm trying to optimise its chess performance may learn to disable its off switch so that it can
off, etc. What the researchers propose is to steer certain variants of reinforcement learning away
reinforcement learning will not undermine the means of responsible oversight and intervention.
Riedl and Harrison (2017) suggests making a 'big red button' that, once pressed, diverted the AI into
would prevent AI from attaching value to disabling an off-switch (Hadfield-Menell et al., 2016).
better approach, according to Arnold and Scheutz, would be to make ongoing self-evaluation and
The ethics of artificial intelligence: Issues and initiatives
3. Ethical initiatives in the field of artificial intelligence
development, use and effects of artificial intelligence (AI). These range from the potential effects AI
utilisation of gathered data; from the bias and discrimination unintentionally embedded into an AI
consequences of their choices and usage of any given AI, leading to ill-informed decisions and
AI builds upon previous revolutions in ICT and computing and, as such, will face a number of similar
ethical problems. While technology may be used for good, potentially it may be misused. We may
excessively anthropomorphise and humanise AI, blurring the lines between human and machine.
The ongoing development of AI will bring about a new 'digital divide', with technology benefiting
some socioeconomic and geographic groups more than others. Further, AI will have an impact on
STOA | Panel for the Future of Science and Technology
anchoring of rapid advances in AI, covering disciplines including
Ethical AI &
develop AI, based on eight principles for responsible machine
appropriate redress for AI impact, evaluation of bias, explicability,
transparency, reproducibility, mitigation of the effect of AI
automation on workers, accuracy, cost, privacy, trust, and security.
growth of new AI technology, and ensuring the ethical development
of AI-led EdTech.
Ensuring that the development of AI is beneficial to humankind, with
human control of AI, and the potential dangers of advanced
'general/strong' or super-intelligent AI.
'Asilomar AI Principles'
The ethics of artificial intelligence: Issues and initiatives
Japan To ensure that AI R&D remains beneficial to human society, and that
AI4All United States Diversity and inclusion in AI, to expose underrepresented groups to
AI for social good and humanity's benefit. Google
The impact and governance of artificial intelligence to broadly benefit
Governance of AI' Published
The AI Now
The social implications of AI, especially in the areas of:
Rights and liberties, labour and automation, bias and inclusion, and
& Governance of AI Initiative.
Societal and policy guidelines to keep AI and intelligent systems
on AI United States
Best practices on AI technologies: Safety, fairness, accountability,
a group of AI researchers
STOA | Panel for the Future of Science and Technology
AI4People Belgium The social impacts of AI, and the founding principles, policies, and
practices upon which to build a 'good AI society'.
AI Society'
Seeks to ensure that technologies of automation and machine
responsible AI
deploy responsible AI ecosystems, to deliver transparent,
accountable, trustworthy AI services. Enabling organisations to
develop human-centric AI, with a focus on increasing the levels of
trust and accountability in AI ecosystems. The platform offers
– AI industrialisation and economic impact. European Commission
The ethics of artificial intelligence: Issues and initiatives
Data Ethics and
UK Identifying and plugging gaps in our regulatory landscape, AI use of
data, and maximising the benefits of AI to society. UK Government
Promoting and supporting the growth and application of AI principles
and techniques throughout computing, and promoting AI education
The socially responsible development of AI, bringing together 400
Worker disruption and transparency in the application of AI, robotics,
and data and machine learning in the workplace. Safeguarding
'Top 10 Principles for Ethical AI' unknown
Europe Bringing European robotics and AI community together. Industrydriven, focus on competitiveness and innovation. European Commission
STOA | Panel for the Future of Science and Technology
All of the initiatives listed above agree that AI should be researched, developed, designed, deployed,
include analysis and grouping of the initiatives above, by type of issues they aim to address, and
Is AI in the best interests of humanity and human well-being?
Will AI degrade the integrity of the human emotional experience, or facilitate emotional or
Who is responsible for AI, and who will be held accountable for its actions?
comes to data and personalisation?
What if AI is deemed untrustworthy by the public, or acts in ways that threaten the safety of
How do we ensure that AI is inclusive, free of bias and discrimination, and aligned with public
How will we control for AI that negatively affects economic opportunity and employment, and
How do we go about ensuring that AI - and the data it collects - is used, processed, and
and regulation? What would such regulation look like? Should AI be granted 'personhood'?
9. Control and the ethical use – or misuse – of AI
How might AI be used unethically - and how can we protect against this? How do we ensure
that AI remains under complete human control, even as it develops and 'learns'?
development and use of AI? How do we produce it in a sustainable way?
The ethics of artificial intelligence: Issues and initiatives
and interaction with AI?
How do we avoid an AI arms race, pre-emptively mitigate and regulate potential harm, and
ensure that advanced machine learning is both progressive and manageable?
impacts associated with AI — with a focus on ensuring that AI is accountable and transparent (IEEE,
the ethical issues that AI may raise — and the various proposed means of mitigating these.
STOA | Panel for the Future of Science and Technology
Areas of key impact comprise sustainable development; personal data rights and agency over
human values; political self-determination and data agency; and technical dependability.
The ethics of artificial intelligence: Issues and initiatives
All initiatives adhere to the view that AI must not impinge on basic and fundamental human rights,
personal data, equality, solidarity and justice (European Parliament, Council and Commission, 2012).
How do we ensure that AI upholds such fundamental human rights and prioritises human wellbeing? Or that AI does not disproportionately affect vulnerable areas of society, such as children,
frameworks, standards, and regulatory bodies which oversee the use of AI; translating existing legal
maintaining complete human control over AI, without granting them rights or privileges equal to
best and most widely-accepted available metrics to clearly measure the societal success of an AI.
Personal data are also a key issue here; AI collect all manner of personal data, and users must retain
the access to, and control of, their data, to ensure that their fundamental rights are being lawfully
According to the Foundation for Responsible Robotics, AI must be ethically developed with human
policymaking – made before AI is released and put into use.
the development of AI, including the need to design and operate AI in a way that is compatible with
Society for AI Ethical Guidelines, which places the utmost importance on AI being realised in a way
researchers and society as a whole. AI must contribute to the peace, safety, welfare, and public
extent should we delegate to machines decisions that affect people? For example, could AI 'judges'
7 https://futureoflife.org/ai-principles/ 8 http://thefuturesociety.org/law-and-society-initiative
STOA | Panel for the Future of Science and Technology
and even if they were, would this be an appropriate way to deploy AI? The Montréal Declaration9
internationally recognised human rights in fields affected by the rollout of AI: 'The principles of the
exercising their emotional, moral and intellectual capacities.' In other words, AI must not only not
Some approach AI from a more specific viewpoint – such as the UNI Global Union, which strives to
that AI may cause in the realm of human employment. The Union states that we must ensure that
AI serves people and the planet, and both protects and increases fundamental human rights, human
What is it to be human? AI will interact with and have an impact on the human emotional
ways of interacting, affective and influential AI could begin to influence how people view society
update AI norms and values according to who they are engaging with, and the sensitivities of the
There are various ways in which AI could inflict emotional harm, including false intimacy, overattachment, objectification and commodification of the body, and social or sexual isolation. These
Responsible Robotics, Partnership on AI, the AI Now institute (especially regarding affect
relationship with an AI, for example in the sex industry. Intimate systems, as the IEEE call them, must
Affective AI is also open to the possibility of deceiving and coercing its users – researchers have
defined the act of AI subtly modifying behaviour as 'nudging', when an AI emotionally manipulates
The ethics of artificial intelligence: Issues and initiatives
question of whether or not the nudging design pathway for AI, which lends itself well to selfish or
Other issues include technology addiction and emotional harm due to societal or gender bias.
The vast majority of initiatives mandate that AI
operators of AI are held accountable for the
technology or system's actions, and are thus
not exist, given that AI-oriented technology is
a particular AI.
of 23 guiding principles for AI to follow in order to be ethical in the short and long term. Designers
and builders of advanced AI systems are 'stakeholders in the moral implications of their use, misuse,
and actions, with a responsibility and opportunity to shape those implications' (FLI, 2017); if an AI
should make a mistake, it should also be possible to ascertain why. The Partnership on AI also
assumptions and biases exist within data and thus within systems built from these data, and strive
not to replicate them – i.e. to be actively accountable for building fair, bias-free AI.
and AI engineers, and by regulation, law and society on a larger scale.
intimate association with technology. Many
STOA | Panel for the Future of Science and Technology
A main concern over AI is its transparency,
AI require data to continually learn and develop their automatic decision-making. These data are
into how these data are used? Individuals may lack the appropriate tools to control and cultivate
their unique identity and manage the associated ethical implications of the use of their data.
Without clarity and education, many users of AI will remain unaware of the digital footprint they are
users to control, interact with and access their data, and give them agency over their digital
example), and systems must ask for explicit consent at the time data are collected and used, in order
personalised 'privacy AI or algorithmic agent or guardian' to help individuals curate and control their
personal data and foresee and mitigate potential ethical implications of machine learning data
transparency and privacy across various aspects: failure transparency (if an AI fails, it must be
possible to figure out why), judicial transparency (any AI involved in judicial decision-making must
access, manage, and control the data AI gather and create), and liberty and privacy (AI must not
strongly emphasises the importance of AI that are transparent, accountable, and trustworthy, where
The current approach to AI is undeniably
natural, between self-organising and not. AI
AI? Machine autonomy designates how machines
attempts to implant emotion and morality into AI
embodied AI begins to look increasingly similar to
terms of artificial intelligence and systems.
The ethics of artificial intelligence: Issues and initiatives
All of the initiatives surveyed identify transparency and accountability of AI as an important issue.
compensation and rights, security of data and systems, public trust, and social harm.
Where AI is used to supplement or replace human
Asilomar principles indicate that all involved in developing and deploying AI should be missionled, adopting the norm that AI 'should only be developed in the service of widely shared ethical
Institute, 2017). This approach would build public trust in AI, something that is key to its successful
The Japanese Society for AI proposes that AI should act with integrity at all times, and that AI and
to the overall peace and happiness of mankind' (JSAI, 2017). The Partnership on AI agrees, and
strives to ensure AI is trustworthy and to create a culture of cooperation, trust, and openness among
AI scientists and engineers. The Institute for Ethical AI & Machine Learning also emphasises the
mandating that AI technologists communicate with stakeholders about the processes and data
AI development requires a diversity of viewpoints. There are several organisations establishing that
preferences, that biases and assumptions must not be built into data or systems, and that AI should
argue that all should have access to the benefits of AI, and it should work for the common good. In
other words, developers and implementers of AI have a social responsibility to embed the right
values into AI and ensure that they do not cause or exacerbate any existing or future harm to any
The IEEE suggest first identifying social and moral norms of the specific community in which an AI
will be deployed, and those around the specific task or service it will offer; designing AI with the idea
of 'norm updating' in mind, given that norms are not static and AI must change dynamically and
and equipping AI with a system in which to do so in a similar and transparent way. This should be
and IEEE suggest equipping AI systems with
includes clear data on the ethical
STOA | Panel for the Future of Science and Technology
Several initiatives – such as AI4All and the AI Now Institute – explicitly advocate for fair, diverse,
equitable, and non-discriminatory inclusion in AI at all stages, with a focus on support for underrepresented groups. Currently, AI-related degree programmes do not equip aspiring developers
While AI may have considerable usefulness in a humanitarian sense, they must not widen this gap
transparent power structures; facilitating and sharing robotics and AI knowledge and research; and
generally keeping AI in line with the US Sustainable Development Goals11. AI technology should be
interdisciplinary discussion should be held on effective AI education and training (IEEE, 2019).
A set of ethical guidelines published by the Japanese Society for AI emphasises, among other
considerations, the importance of a) contribution to humanity, and b) social responsibility. AI must
responsible AI; the Partnership on AI cautions about the 'serious blind spots' of ignoring the
presence of biases and assumptions hidden within data; Saidot aims to ensure that, although our
social values are now 'increasingly mediated by algorithms', AI remains human-centric (Saidot,
2019); the Future of Life Institute highlights a need for AI imbued with human values of cultural
diversity and human rights; and the Institute for Ethical AI & Machine Learning includes 'bias
evaluation' for monitoring bias in AI development and production. The dangers of human bias and
assumption are a frequently identified risk that will accompany the ongoing development of AI.
AI may disrupt the economy and lead to loss of jobs or work disruption for many humans, and will
structures will need to be changed to mitigate the effects of automation and take into account the
employment. The UNI Global Union call for multi-stakeholder ethical AI governance bodies on
trade unions, lawyers, CSOs, owners, and employers. AI must benefit and empower people broadly
The AI Now Institute works with diverse stakeholder groups to better understand the implications
that AI will have for labour and work, including automation and early-stage integration of AI
specifically asks how AI will affect the legal profession: 'If AI systems are demonstrably superior to
The ethics of artificial intelligence: Issues and initiatives
AI in the workplace will affect far more than workers' finances, and may offer various positive
opportunities. As laid out by the IEEE (2019), AI may offer potential solutions to workplace bias – if
Several initiatives address the need for AI to be
surrounding AI translate directly and indirectly
into discrete legal challenges. How should AI be labelled: as a product? An animal? A person?
The IEEE conclude that AI should not be granted any level of 'personhood', and that, while
development, design and distribution of AI should fully comply with all applicable international and
suggest that AI should remain subject to the applicable regimes of property law; that stakeholders
should identify the types of decisions that should never be delegated to AI, and ensure effective
and reviewed for mechanisms that could practically give AI legal autonomy; and that manufacturers
AI could operate. They also recommend that governments reassess the legal status for AI as they
Control and the ethical use – or misuse – of AI
With more sophisticated and complex new AI come more sophisticated and complex possibilities
for misuse. Personal data may be used maliciously or for profit, systems are at risk of hacking, and
technology may be used exploitatively. This ties into informed use and public awareness: as we
enter a new age of AI, with new systems and technology emerging that have never before been
STOA | Panel for the Future of Science and Technology
example a 'data privacy' warning on smart
devices that collect personal data; delivering
behaviour and data. Humans must retain
control over AI and oppose subversion. Most
issue facing AI as it develops, and flag that AI
reliable, with appropriate means for redress, and be subject to validation and testing. AI must also
The production, management, and implementation of AI must be sustainable and avoid
so on (IEEE, 2019). The IEEE (EAD, 2019) state that AI must do no harm to Earth's natural systems or
and/or the restoration of Earth's natural systems. The UNI Global Union state that AI must put
of potential uses for AI in coming years, from agricultural and farming roles to monitoring of climate
govern AI and robotics, say the Foundation, to mitigate risk and support ongoing innovation and
Members of the public must be educated on the use, misuse, and potential harms of AI, via civic
instances in which consent is less clear-cut than might be ethical: what if one's personal data are
imbalance; many employees do not have clear consent on how their personal data – including those
on health – is used by their employer. To remedy this, the IEEE (2017) suggest employee data impact
assessments to deal with these corporate nuances and ensure that no data is collected without
employee consent. Data must also be only gathered and used for specific, explicitly stated,
necessary. In cases where subjects do not have a direct relationship with the system gathering data,
consent must be dynamic, and the system designed to interpret data preferences and limitations
Personhood and AI
The issue of whether or not an AI deserves
AI itself that is responsible for its actions and
The ethics of artificial intelligence: Issues and initiatives
To increase awareness and understanding of AI, undergraduate and postgraduate students must be
educated on AI and its relationship to sustainable human development, say the IEEE. Specifically,
potential of AI applications; and awareness should be increased of the opportunities and risks faced
by Lower Middle Income Countries in the implementation of AI in humanitarian efforts across the
AI, Japanese Society for AI Ethical Guidelines, Future Society and AI Now Institute; these and
others maintain that clear, open and transparent dialogue between AI and society is key to the
According to the Future of Life Institute, the main existential issue surrounding AI 'is not
malevolence, but competence' – AI will continually learn as they interact with others and gather
data, leading them to gain intelligence over time and potentially develop aims that are at odds with
ants. A key goal of AI safety research is to never place humanity in the position of those ants' (The Future
AI also poses a threat in the form of autonomous weapons systems (AWS). As these are designed
for possible longer-term risks. We must avoid strong assumptions on the upper limits of future AI
capabilities, assert the FLI's Asilomar Principles, and recognise that advanced AI represents a
Artificial Intelligence and robotics are rapidly moving into the field of healthcare and will
STOA | Panel for the Future of Science and Technology
medical image diagnostics, machine learning has been proven to match or even surpass our ability
Embodied AI, or robots, are already involved in a number of functions that affect people's physical
for human safety and well-being. The stakes are much higher with embodied AI than with mere
Again, perhaps the most important ethical issue arising from the growth of AI and robotics in
but to thoroughly establish a technology's long-term safety and performance investment in clinical
clinical trials will be essential to safely implement the healthcare innovations that AI systems offer.
The correct application of AI by a healthcare professional is important to ensure patient safety. For
2009). With genomics and machine learning becoming embedded in diagnoses and medical
technological tool and use it appropriately. It is important for users to trust the AI presented but to
instance, a generally accurate machine learning study to predict the risk of complications in patients
higher-level care circumvented complications. The inaccurate recommendation from the algorithm
However, it's questionable to what extent individuals need to understand how an AI system arrived
machine learning algorithms often prevent the ability to understand how a conclusion has been
The ethics of artificial intelligence: Issues and initiatives
to ensure safety would be to license AI for specific medical procedures, and to 'disbar' the AI if a
Data protection
Personal medical data needed for healthcare algorithms may be at risk. For instance, there are
worries that data gathered by fitness trackers might be sold to third parties, such as insurance
companies, who could use those data to refuse healthcare coverage (National Public Radio, 2018).
Pooling personal medical data is critical for machine learning algorithms to advance healthcare
data sharing. Clear frameworks for how healthcare staff and researchers use data, such as genomics,
Although AI promises to reduce the number of medical mishaps, when issues occur, legal liability
it is tricky to establish negligence on the part of the algorithm's producer (Hart, 2018).
For now, AI is used as an aide for expert decisions, and so experts remain the liable party in most
the AI and sent asthmatic pneumonia patients home without applying their specialist knowledge,
of Law and Information Technology, 2019).
Soon, the omission of AI could be considered negligence. For instance, in less developed countries
with a shortage of medical professionals, withholding AI that detects diabetic eye disease and so
Technology, 2019).
Fundamental Rights), but machine learning algorithms are trained on datasets that often have
proportionally less data available about minorities, and as such can be biased (Medium, 2014). This
difficult task because of the aforementioned 'black box' nature of machine learning. However,
STOA | Panel for the Future of Science and Technology
The Partnership on AI, an ethics-focused industry group was launched by Google, Facebook,
ensuring equality of access to healthcare, but also in increasing the data from minority groups
The ethics of artificial intelligence: Issues and initiatives
technology'. Wallach and Allen (2009) agree that robots designed to detect human social gestures
companion AI. Robots could empower disabled and older people and increase their independence;
As with many areas of AI technology, the privacy and dignity of users' needs to be carefully
the hippocampus and people pressing 'consent', like we do now, for data access'. (John Havens)
STOA | Panel for the Future of Science and Technology
Larosa and Danks (2018) write that AI may affect human-human interactions and relationships
— for instance, of an image-identifying algorithm mistaking a turtle for a gun (The Verge, 2017) —
uptake of AI (Global News Canada, 2016).
seen as 'mere users' of the AI, we would expect their role to be downgraded in the public's eye,
patient's wishes, then these actions will have a negative impact on trust. Introducing AI into this
dynamic could increase trust — if the AI reduced the likelihood of misdiagnosis, for example, or
improved patient care. However, AI could also decrease trust if the doctor delegated too much
diagnostic or decision-making authority to the AI, undercutting the position of the doctor as an
The ethics of artificial intelligence: Issues and initiatives
around since at least the 1920s, it is only in recent years that technology has developed to a point
driving automation:
0 No automation An automated system may issue warnings and/or momentarily intervene in
Some of the lower levels of automation are already well-established and on the market, while higher
models have an Autopilot function, which provides level 2 automation (Tesla, nd). Drivers are legally
STOA | Panel for the Future of Science and Technology
AVs are complex systems that often rely on advanced machine learning technologies. Several
crash is ongoing, with a third-party appraiser reviewing data from the vehicle (Curtis, 2016).
The ethics of artificial intelligence: Issues and initiatives
developed or adopted. In addition, the proprietary data logging systems currently installed in AVs
data on the events leading up to an accident (Stilgoe and Winfield, 2018).
One solution is to fit all future AVs with industry standard event data recorders — a so-called 'ethical
is possible that manufacturers are collecting this data already, they are not under any obligation to
do so — or to share the data. The only exception at the moment is the US state of California, which
Apple AVs (Hawkins, 2019).Data on these disengagements reinforces the importance of ensuring
that human safety drivers remain engaged. However, the Californian data collection process has
Without access to this type of data, policymakers cannot account for the frequency and significance
Data privacy
It is becoming clear that manufacturers collect significant amounts of data from AVs. As these
data compromising the privacy and data protection rights of drivers and passengers?
Already, data management and privacy issues have appeared, with some raising concerns about the
potential misuse of AV data for advertising purposes (Lin, 2014). Tesla have also come under fire for
the unethical use of AV data logs. In an investigation by The Guardian, the newspaper found multiple
instances where the company shared drivers' private data with the media following crashes, without
STOA | Panel for the Future of Science and Technology
their permission, to prove that its technology was not responsible (Thielman, 2017). At the same
time, Tesla does not allow customers to see their own data logs.
that all AV drivers be given full data sovereignty (Ethics Commission, 2017). This would allow them
to control how their data is used.
of AV technology (Viscelli, 2018). In 2016, the first commercial delivery of beer was made using a
Fully autonomous taxis will likely only become realistic in the long term, once AV technology has
also be more far-reaching effects for urban planning, with automation shaping the planning of
distances (Worland, 2016). The impact of automation on driving behaviours should therefore not be
The ethics of artificial intelligence: Issues and initiatives
controlled by an algorithm causes
However, Millar (2016) suggests that the user of the technology, in this case the passenger in the
Although partially autonomous and intelligent systems have been used in military technology since
at least the Second World War, advances in machine learning and AI signify a turning point in the
use of automation in warfare.
AI is already sufficiently advanced and sophisticated to be used in areas such as satellite imagery
analysis and cyber defence, but the true scope of applications has yet to be fully realised. A recent
report concludes that AI technology has the potential to transform warfare to the same, or perhaps
(Allen and Chan, 2017). Some key ways in which AI will impact militaries are outlined below.
STOA | Panel for the Future of Science and Technology
willing to delegate authority to them. This is likely to continue with the widespread adoption of AI,
leading to an AI inspired arms-race. The Russian Military Industrial Committee has already approved
Hallaq et al. (2017) also highlight key areas in which machine learning is likely to affect warfare. They
and compare situational data to a stored database of hundreds of previous wargame exercises and
Employing AI in warfare raises several legal and ethical questions. One concern is that automated
threaten our fundamental right to life and the principle of human dignity. AI could also lower the
should unnecessarily aggravate the suffering of combatants. AI may be unable to fulfil these
The ethics of artificial intelligence: Issues and initiatives
AI, and the commander or supervisor (assuming that they knew, or should have known, the
STOA | Panel for the Future of Science and Technology
4. AI standards and regulation
of artificial intelligence and robotics are further understood. Whether a standard clearly articulates
risk assessment of their robot or AI, and mitigate any ethical risks identified. It is based on a set of 20
The ethics of artificial intelligence: Issues and initiatives
initiative explicitly seeks to reposition robotics and AI as technologies for improving the human
train and empower AI/robot stakeholders to 'prioritise ethical considerations so that these
standards that have implications for artificial intelligence (Table 4.1).
STOA | Panel for the Future of Science and Technology
Table 2: IEEE 'human standards' with implications for AI
• Disruptive technology (e.g. driverless cars): enabling the public to assess technology (and, if
P7002 Data Privacy Process
To establish standards for the ethical use of personal data in software engineering processes. It will
The ethics of artificial intelligence: Issues and initiatives
To help algorithm developers make explicit the ways in which they have sought to eliminate or
• Benchmarking processes for the selection of data sets;
• Guidelines on communicating the boundaries for which the algorithm has been designed and
P7004 Standard for Child and Student Data Governance Specifically aimed at educational institutions, this will provide guidance on accessing, collecting,
storing, using, sharing and destroying child/student data.
P7005 Standard for Transparent Employer Data Governance Similar to P7004, but aimed at employers.
P7006 Standard for Personal Data Artificial Intelligence (AI)
Describes the technical elements required to create and grant access to personalised AI. It will enable
enable personalised AI to act as a proxy for machine-to-machine decisions.
and Automation Systems
STOA | Panel for the Future of Science and Technology
manipulative, and seeks to elaborate methodologies for ethical design of AI using nudge.
P7010 Well-being Metrics Standard for Ethical Artificial
To establish a baseline for metrics used to assess well-being factors that could be affected by
Facial Analysis Technology
To provide guidelines on the data used in facial recognition, the requirements for diversity, and
The ethics of artificial intelligence: Issues and initiatives
5. National and International Strategies on AI
As the technology behind AI continues to progress beyond expectations, policy initiatives are
The first national strategy on AI was launched by Canada in March 2017, followed soon after by
technology leaders Japan and China. In Europe, the European Commission put forward a
communication on AI, initiating the development of independent strategies by Member States. An
American AI initiative is expected soon, alongside intense efforts in Russia to formalise their 10-point
plan for AI.
STOA | Panel for the Future of Science and Technology
Figure 3: National and International Strategies on AI published as of May 2019.
The ethics of artificial intelligence: Issues and initiatives
The European Commission's Communication on Artificial Intelligence (European Commission,
2018a), released in April 2018, paved the way to the first international strategy on AI. The document
about by AI.
The Communication on AI was formalised nine months later with the presentation of a coordinated
plan on AI (European Commission, 2018b). The plan details seven objectives, which include
and PhDs in AI and creating common European data spaces.
High-Level Expert Group on Artificial Intelligence, 2019). The Guidelines list key requirements that
AI systems must meet in order to be trustworthy.
The EU's High-Level Expert Group on AI shortly after released a further set of policy and investment
guidelines for trustworthy AI (European Commission High-Level Expert Group on AI, 2019b), which
AI in the private sector, expanding European research capacity in AI and developing ethical data
The Council of Europe also has various ongoing projects regarding the application of AI and in
September 2019 established an Ad Hoc Committee on Artificial Intelligence (CAHAI). The committee
will assess the potential elements of a legal framework for the development and application of AI,
Looking ahead, the next European Commission President, Ursula von der Leyen, has announced AI
'human and ethical implications' of AI (Kayali, 2019; von der Leyen, 2019).
The European Commission provides a unifying framework for AI development in the EU, but
The EU’s seven requirements for trustworthy AI:
3. Privacy and data governance
Source: European Commission High-Level Expert Group on Artificial Intelligence, 2019
STOA | Panel for the Future of Science and Technology
Finland was the first Member State to develop a national programme on AI (Ministry of Economic
of Artificial Intelligence and Work in the Age of Artificial Intelligence (Ministry of Economic Affairs and
into policy, Finland's AI steering group will run until the end of the present Government's term, with
AI. Denmark's National Strategy for Artificial Intelligence (The Danish Government, 2019) was
AI, providing high quality data and overall increasing investment in AI (particularly in the agriculture,
energy, healthcare and transport sectors). There is a strong focus on data ethics, including
Danish government outlines six principles for ethical AI – self-determination, dignity, responsibility,
development and use of AI in order to achieve societal progress) – and will establish a Data Ethics
In France, 'AI for Humanity' was launched in March 2018 and makes commitments to support French
talent, make better use of data and also establish an ethical framework on AI (AI For Humanity, 2018).
President Macron has committed to ensuring transparency and fair use in AI, which will be
French mathematician and politician, whose 2018 report on AI made recommendations across
Germany's AI Strategy was adopted soon after in November 2018 (Die Bundesregierung, 2018) and
makes three major pledges: to make Germany a global leader in the development and use of AI, to
safeguard the responsible development and use of AI, and to integrate AI in society in ethical, legal,
research, the creation of 100 extra professorships for AI, establishing a German AI observatory,
funding 50 flagship applications of AI to benefit the environment, developing guidelines for AI that
are compatible with data protection laws, and establishing a 'Digital Work and Society Future Fund'
Sweden's approach to AI (Government Offices of Sweden, 2018) has less specific terms, but provides
general guidance on education, research, innovation and infrastructure for AI. Recommendations
of AI. A Swedish AI Council, made up of experts from industry and academia, has also been
established to develop a 'Swedish model' for AI, which they say will be sustainable, beneficial to
society and promote long-term economic growth (Swedish AI Council, 2019).
The UK government issued the comprehensive 'AI Sector Deal' in April 2018 (GOV.UK, 2018), part of
and infrastructure (GOV.UK, 2019). It pledges almost £1 billion to promote AI in the UK, along five
The ethics of artificial intelligence: Issues and initiatives
creation of a 'Centre for Data Ethics and Innovation' (CDEI) to ensure the safe and ethical use of AI.
First announced in the 2017 budget, the CDEI will assess the risks of AI, review regulatory and
governance frameworks and advise the government and technology creators on best practice (UK
established a 'Robot Council' to help the Government to develop a national AI Strategy (Austrian
Council on Robotics and Artificial Intelligence, 2019). A white paper prepared by the Council lays the
responsible use of AI, develop measures to recognise and mitigate hazards, create a legal framework
to protect data security, and engender a public dialogue around the use of AI (Austrian Council on
Robotics and Artificial Intelligence, 2018).
Estonia has traditionally been quick to take up new technologies, AI included. In 2017, Estonia's
Adviser for Digital Innovation Marten Kaevats described AI as the next step for 'e-governance' in
Estonia (Plantera, 2017). Indeed, AI is already widely used by the government, which is currently
devising a national AI strategy (Castellanos, 2018). The plan will reportedly consider the ethical
implications of AI, alongside offering practical economic incentives and pilot programmes.
An AI task force has been established by Italy (Agency for Digital Italy, 2019) to identify the
opportunities offered by AI and improve the quality of public services. Their white paper (Task Force
on Artificial Intelligence of the Agency for Digital Italy, 2018), published in March 2018, describes
ethics as the first challenge to the successful implementation of AI, stating a need to uphold the
principle that AI should be at the service of the citizen and to ensure equality by using technology
to address universal needs. The task force further outline challenges relating to technology
development, the skills gap, data accessibility and quality, and a legal framework. It makes a total of
Malta, a country that has previously focused heavily on blockchain technology, has now made
public its plans to develop a national AI strategy, putting Malta 'amongst the top 10 nations with a
national strategy for AI' (Malta AI, 2019). A task force has been established composed of industry
ethical, transparent and socially-responsible AI while developing measures that garner foreign
investment, which will include developing the skillset and infrastructure needed to support AI in
Poland too is working on its national AI strategy. A report recently released by the Digital Poland
Foundation (2019) focuses on the AI ecosystem in Poland, as a forerunner of the national AI strategy.
surrounding AI.
Despite media reports of military-focused AI developments in Russia (Apps, 2019; Bershidski, 2017;
Le Miere, 2017; O'Connor, 2017) the country currently has no national strategy on AI. Following the
released a list of policy recommendations, which include creating a state system for AI education
and a national centre for AI. The latest reports suggest President Putin has set a deadline of June 15th
2019 for his government to finalise the national strategy on AI.
STOA | Panel for the Future of Science and Technology
Overall, surveys of European perspectives to AI, robotics, and advanced technology (European
 Concerned that such technology requires effective and careful management;
 Worried that automation and digitisation would bring job losses, and unsure whether it
 Worried about accessing and protecting their data and online information, and likely to have
These concerns thus feature prominently in European AI initiatives, and are reflective of general
opinion on the implementation of robots, AI, automation and digitisation across the spheres of life,
Canada was the first country in the world to launch a national AI strategy, back in March 2017. The
Pan-Canadian Artificial Intelligence Strategy (Canadian Institute For Advanced Research, 2017) was
established with four key goals, to: increase the number of AI researchers and graduates in Canada;
thought leadership in the economic, ethical, policy and legal implications of AI; and support a
national research community in AI.
A separate programme for AI and society was dedicated to the social implications of AI, led by policyrelevant working groups that publish their findings for both government and public. In
Innovation (UKRI), the AI and society programme has recently announced a series of interdisciplinary
workshops to explore issues including trust in AI, the impact of AI in the healthcare sector and how
AI affects cultural diversity and expression (Canadian Institute For Advanced Research, 2019).
In the USA, President Trump issued an Executive Order launching the 'American AI Initiative' in
AI initiatives (The White House, 2019b), including AI for American Innovation, AI for American
Industry, AI for the American Worker and AI for American Values. The American AI Initiative has five
key areas: investing in R&D, unleashing AI resources (i.e. data and computing power), setting
The ethics of artificial intelligence: Issues and initiatives
governance standards, building the AI workforce and international engagement. The Department
of Defence has also published its own AI strategy (US Department of Defence, 2018), with a focus on
the military capabilities of AI.
In May, the US advanced this with the AI Initiative Act, which will invest $2.2 billion into developing
a national AI strategy, as well as funding federal R&D. The legislation, which seeks to 'establish a
coordinated Federal initiative to accelerate research and development on artificial intelligence for
the economic and national security of the United States' commits to establishing a National AI
Coordination Office, create AI evaluation standards and fund 5 national AI research centres. The
programme will also fund the National Science Foundation to research the effects of AI on society,
including the roles of data bias, privacy and accountability, and expand AI-based research efforts
In June 2019, the National Artificial Intelligence Research and Development Strategic Plan was
strategic priorities, including making long-term investments in AI research, developing effective
methods for human-AI collaboration, developing shared public datasets, evaluating AI technologies
societal implications of AI. The document provides a coordinated strategy for AI research and
development in the US (National Science & Technology Council, 2019).
Asia has in many respects led the way in AI strategy, with Japan being the second country to release
a national initiative on AI. Released in March 2017, Japan's AI Technology Strategy (Japanese
Strategic Council for AI Technology, 2017) provides an industrialisation roadmap, including priority
three-stage development plan for AI, culminating in a completely connected AI ecosystem, working
Singapore was not far behind. In May 2017, AI Singapore was launched, a five-year programme to
enhance the country's capabilities in AI, with four key themes: industry and commerce, AI
frameworks and testbeds, AI talent and practitioners and R&D (AI Singapore, 2017). The following
and ethics of AI, including establishing an Advisory Council on the Ethical Use of AI and Data,
formalised in January 2019's 'Model AI Governance Framework' (Personal Data Protection
incorporate human decision making into AI and how to minimise bias in datasets.
largest economy (World Economic Forum, 2018). To catapult China to world leader in AI, the Chinese
Government released the 'Next Generation AI Development Plan' in July 2017. The detailed plan
for Law and International Affairs, 2017). In line with Japan, it is a three-step strategy for AI
development, culminating in 2030 with becoming the world's leading centre for AI innovation.
AI and 'actively participate' in the global governance of this technology. Formalised under the
'Three-Year Action Plan for Promoting Development of a New Generation Artificial Intelligence
Industry', the strategy iterates four main goals, to: scale-up the development of key AI products (with
STOA | Panel for the Future of Science and Technology
systems); significantly enhance core competencies in AI; deepen the development of smart
manufacturing; and establish the foundation for an AI industry support system (New America, 2018).
In India, AI has the potential to add 1 trillion INR to the economy by 2035 (NITI Aayog, 2018). India's
AI strategy, named AI for All, aims to utilise the benefits of AI for economic growth but also social
up Centres of Research Excellence for AI (COREs, each with their own Ethics Council), promoting
Technological Sustainability'. It also establishes the concept of India as an 'AI Garage', whereby
Alongside them, Taiwan released an 'AI Action Plan' in January 2018 (AI Taiwan, 2018), focused
heavily on industrial innovation, and South Korea announced their 'AI Information Industry
government, across data management, research methods, AI in government and public services,
Malaysia's Prime Minister announced plans to introduce a national AI framework back in 2017
(Abas, 2017), an extension of the existing 'Big Data Analytics Framework' and to be led by the
national AI strategy in the country, at an event held in collaboration with the Computer Society of
In the Middle East, the United Arab Emirates was the first country to develop a strategy for AI,
technology and space. The ethics underlying the framework is fairly comprehensive; the Dubai AI
Ethics Guidelines dictate the key principles that make AI systems fair, accountable, transparent and
of AI technology to evaluate the ethics of their system (Smart Dubai, 2019b).
World leader in technology Israel is yet to announce a national AI strategy. Acknowledging the
global race for AI leadership, a recent report by the Israel Innovation Authority (Israel Innovation
Authority, 2019) recommended that Israel develop a national AI strategy 'shared by government,
Africa has taken great interest in AI; a recent white paper suggests this technology could solve some
financial services (Access Partnership, 2018). The document provides essential elements for a panAfrican strategy on AI, suggesting that lack of government engagement to date has been a
hindrance and encouraging African governments to take a proactive approach to AI policy. It lists
laws on data privacy and security, initiatives to foster widespread adoption of the cloud, regulations
to enable the use of AI for provision of public services, and adoption of international data standards
The ethics of artificial intelligence: Issues and initiatives
Kenya however has announced a task force on AI (and blockchain) chaired by a former Secretary in
created a task force to put together a national strategy on AI and held a workshop in 2018 entitled
'National AI Strategy: Unlocking Tunisia's capabilities potential' (ANPR, 2018).
Mexico is so far the only South American nation to release an AI strategy. It includes five key actions,
needs of industry; promote Mexico's international leadership in AI; publish recommendations for
The strategy emphasises the role of its citizens in Mexico's AI development and the potential of
social applications of AI, such as improving healthcare and education. It also addresses the fact that
18% of all jobs in Mexico (9.8 million in total) will be affected by automation in the coming 20 years
in Asia. Recent reports suggest AI could double the size of the economy in Argentina, Brazil, Chile,
Australia does not yet have a national strategy on AI. It does however have a' Digital Economy
skills and inclusion', listing AI as a key emerging technology. A report on 'Australia's Tech Future'
further details plans for AI, including using AI to improve public services, increase administrative
legislative reforms to streamline the sharing and release of public sector data. The draft ethics
framework (Dawson et al., 2019) is based on case studies from around the world of AI 'gone wrong'
Work is also ongoing to launch a national strategy in New Zealand, where AI has the potential to
increase GDP by up to $54 billion (AI Forum New Zealand, 2018). The AI Forum of New Zealand has
been set up to increase awareness and capabilities of AI in the country, bringing together public,
Their report 'Artificial Intelligence: Shaping The Future of New Zealand' (AI Forum New Zealand,
development (i.e. to coordinate research investment and the use of AI in government services);
increase awareness of AI (including conducting research into the impacts of AI on economy and
society); assist AI adoption (by developing best practice resources for industry); increase the
accessibility of trusted data; grow the AI talent pool (developing AI courses, including AI on the list
of valued skills for immigrants); and finally to adapt to AI's effects on law, ethics and society. This
STOA | Panel for the Future of Science and Technology
includes the recommendation to establish an AI ethics and society working group to investigate
moral issues and develop guidelines for best practice in AI, aligned with international bodies.
5.7. International AI Initiatives, in addition to the EU
In addition to the EU, there are a growing number of international strategies on AI, aiming to provide
technology.
G7 Common Vision for the Future of AI
Germany, Italy, Japan, the United Kingdom and the United States) committed to 12 principles for AI,
1. Promote human-centric AI and the commercial adoption of AI, and continue to advance
2. Promote investment in R&D in AI that generates public test in new technologies and
individuals, in the development and implementation of AI.
Challenges to government adoption of AI
roadblocks to government adoption of AI:
1. Effective use of data - Lack of understanding of data infrastructure, not implementing
data governance processes (e.g. employing data officers and tools to efficiently access
data).
2. Data and AI skills - It is difficult for governments, which have smaller hiring budgets
than many big companies, to attract candidates with the required skills to develop firstrate AI solutions.
3. The AI ecosystem - There are many different companies operating in the AI market and
it is rapidly changing. Many of the start-ups pioneering AI solutions have limited
4. Legacy culture - It can be difficult to adopt transformative technology in government,
The ethics of artificial intelligence: Issues and initiatives
5. Facilitate multi-stakeholder dialogue on how to advance AI innovation to increase trust
6. Support efforts to promote trust in AI, with particular attention to countering harmful
7. Promote the use of AI by small and medium-sized enterprises.
9. Encourage investment in AI.
11. Ensure the development of frameworks for privacy and data protection.
12. Support an open market environment for the free flow of data, while respecting privacy
and data protection.
Nordic-Baltic Region Declaration on AI
the use of AI in the region, including improving the opportunities for skills development, increasing
access to data and a specific policy objective to develop 'ethical and transparent guidelines,
standards, principles and values' for when and how AI should be used (Nordic Co-operation, 2018).
OECD Principles on AI
for AI, the first international standards agreed by governments for the responsible development of
AI. They include practical policy recommendations as well as value-based principles for the
'responsible stewardship of trustworthy AI', summarised below:
• AI should benefit people and the planet by driving inclusive growth, sustainable
• AI systems should respect the rule of law, human rights, democratic values and diversity,
• There should be transparency around AI to ensure that people understand outcomes
• AI systems must function in a robust, secure and safe way throughout their life cycles
• Organisations and individuals developing, deploying or operating AI systems should be
AI Principles were released in June 2019 and are drawn from the OECD Principles (G20, 2019).
The UN has several initiatives relating to AI, including:
• AI for Good Global Summit- Summits held since 2017 have focused on strategies to
ensure the safe and inclusive development of AI (International Telecommunication
STOA | Panel for the Future of Science and Technology
academia to build a common understanding of the capabilities of emerging AI
• UNICRI Centre for AI and Robotics - The UN Interregional Crime and Justice Research
Institute (UNICRI) launched a programme on AI and Robotics in 2015 and will be
Scientific Knowledge and Technology (COMEST) has authored a report on 'Robotics
principles and values, and a technology-based ethical framework (COMEST, 2017).
The World Economic Forum (WEF) formed a Global AI Council in May 2019, co-chaired by speech
of Microsoft Bradford Smith. One of six 'Fourth Industrial Revolution' councils, the Global AI Council
understanding among countries of best practice in AI policy (World Economic Forum, 2019a).
In October 2019, they released a framework for developing a national AI strategy to guide
governments that are yet to develop or are currently developing a national strategy for AI. The WEF
describe it as a way to create a 'minimum viable' AI strategy and includes four main stages:
The WEF has also announced plans to develop an 'AI toolkit' to help businesses to best implement
AI and to create their own ethics councils, which will be released at 2020's Davos conference (Vanian,
5.8. Government Readiness for AI
2019) evaluated the 'AI readiness' of governments around the globe in 2019, using a range of data
including not only the presence of a national AI strategy, but also data protection laws, statistics on
AI startups and technology skills.
The strong European representation in this analysis is reflective of the value of the unifying EU
framework, as well as Europe's economic power. The analysis also praises the policy strategies of
Examples of this collaborative approach include the EU Declaration of Cooperation on AI (European
AI, and individual partnerships between Member States, such as that of Finland, Estonia and
Sweden, working together to trial new applications of AI.
The ethics of artificial intelligence: Issues and initiatives
Table 3: Top 10 rankings for Government AI Readiness 2018/19. Source: Oxford Insights, 2019.
national strategy on AI, ranked 10th. China's position as 21st in the global rankings is expected to
improve next year as its investments in AI begin to pay off. Progress in Asia overall has been
workforces, private sector innovation and abundance of data, to a level at which regions missing
capitalise on AI's potential in the coming years. What this analysis does not consider however is how
robustly each nation is considering the moral and ethical issues surrounding the use of AI, which we
STOA | Panel for the Future of Science and Technology
Our review of the literature on the ethical issues surrounding AI and intelligent robots highlights a
some way to addressing these concerns. However, the focus of many existing strategies on AI is on
enabling technology development and, while ethical issues are addressed, notable gaps can be
There are several themes shared by the various national strategies on AI, among which
strategy for AI, and this is particularly prominent in the emerging economies of Southeast Asia. Most
of the strategies make reference to the importance of AI for business competitiveness and several,
specialised incubators for AI-focused start-ups.
to establish 'centres of excellence' entirely dedicated to AI research, including strategies from
100 professors working on AI – both under the umbrella of the EU commitment to train, attract and
train a total of 5,000 AI specialists, while Taiwan has committed to training double that number by
Most of the strategies also consider the impact the AI revolution will have on the non-technology
literate workforce, who may be the first to lose their jobs to automation. Although this crosses over
AI'), and therefore the plans of its Member States. The UK for example will initiate an > €70 million
differently by different countries. India's approach for example is one of sharing; the 'AI Garage'
concept named in their strategy means AI-based solutions developed in India will be rolled out to
developing economies facing similar issues. Conversely, the US Executive Order on AI sets out to
The ethics of artificial intelligence: Issues and initiatives
'promote an international environment that supports American AI' while also protecting the nation's
The democratisation of technology hasthe potential to reduce inequalities in society, and inclusion
and social development are important goals for many national AI initiatives, particularly those of
developing economies. India's strategy discusses AI for 'greater good', focusing on the possibilities
financial products, and using data to aid small-scale farmers. Mexico's strategy lists inclusion as one
equality. France too aims for an AI that 'supports inclusivity', striving for policies that reduce both
Determining who is responsible for the actions and behaviour of AI is highly important, and
challenging in both moral and legal senses. Currently, AI is most likely considered to be the legal
on. However, this framework does not account for the unique challenges brought by AI, and many
limitations of an AI agent, then it may not be possible to hold them responsible. Without proving
that an AI agent intended to commit a crime (mens rea) and can act voluntarily, both of which are
controversial concepts, then it may not be possible to deem an AI agent responsible and liable for
6.2. Addressing the governance challenges posed by AI
There are currently two major international frameworks for the governance of AI: that of the EU (see
The OECD launched a set of principles for AI in May 2019 (OECD, 2019a) which were at that time
of AI (see section 5.1.1) as well as accompanying practical recommendations for governments to
achieve them. The G20 soon after adopted its own, human-centred AI principles, drawn from (and
strategy on AI since April 2018 (European Commission, 2018b). The EU framework includes
changes and is complemented by a separate set of ethics guidelines (European Commission HighLevel Expert Group on AI, 2019a).
Gaps in AI frameworks
makes reference to developing AI that brings positive outcomes for the planet, including protecting
The EU Communication on AI does not discuss the environment. However, its accompanying ethics
STOA | Panel for the Future of Science and Technology
and 'environmental friendliness') is one of the EU's requirements for trustworthy AI and its
Impacts on human psychology, including how people interact with AI and subsequent effects on
psychosocial impact of AI is not considered by the OECD Principles or the EU Communication.
that such effects must 'be carefully monitored and considered' and that AI interacting with humans
more nuanced factors, including the potential for AI to drive inequalities (2.1.2) and bias (2.1.4), is
more limited. The OECD's first principle of inclusive growth, sustainable development and wellbeing states that AI should be developed in a way that reduces 'economic, social, gender and other
inequalities'. This is also covered to a degree by the second OECD principle, which states that AI
fundamental basis for trustworthy AI and state that AI should be trained on data which is
the EU ethics guidelines, which elaborates on the importance of data governance and data access
rules. Issues concerning privacy are also covered by existing OECD data protection guidelines
The implications of AI for democracy (Section 2.1.5) are only briefly mentioned by the OECD, with
associated ethics guidelines, which state that AI systems should serve to maintain democracy and
that may be necessary in the AI age, including important questions around liability for misconduct
involving AI. The issue of liability is explicitly addressed by the EU in both its Communication and
Communication on AI, which includes guidance on product liability and an exploration of safety and
changes to regulation are further addressed in the recent AI Policy and Investment
Recommendations (European Commission High-Level Expert Group on AI, 2019b), which explore
to create an 'enabling policy environment' for AI, including a recommendation to review and adapt
The ethics of artificial intelligence: Issues and initiatives
competition' and does not address the issue of liability for AI-assisted crime.
states that 'organisations and individuals developing, deploying or operating AI systems should be
for trustworthy AI.
Many of the aforementioned issues are ultimately important for building trust in AI (Section 2.6),
which also requires AI to be fair (2.6.2) and transparent (2.6.3). These issues are at the foundation of
the EU ethics guidelines where they are dealt with in great detail. The OECD also states that AI
AI systems. The OECD Principles offer less context on these issues and do not consider practical
Finally, although both acknowledge the beneficial use of AI in finance (Section 2.3), neither
accidental harm or malicious activity. The potential for AI-assisted financial crime is an important
STOA | Panel for the Future of Science and Technology
development of artificial intelligence; from large scale issues such job losses from automation,
such as how AI may affect our privacy, our ability to judge what is real, and our personal
essential in the future of this rapidly developing technology, but not all countries understand ethics
in the same way. There are a number of independent ethical initiatives for AI, such as Germany's
Institute for Ethics in AI, funded by Facebook, and the private donor-funded Future of Life Institute
in the US. An increasing number of governments are also developing national AI strategies, with
their own ethics components. A number of countries have committed to creating AI ethics councils,
national strategy, by developing an 'Ethical AI Toolkit' and self-assessment tool for developers, while
(supplemented by separate ethics guidelines) and the OECD Principles on AI.
including increased energy consumption associated with AI data processing and manufacture, and
footprints; and potentially policies that direct technology innovation towards urgent environmental
priorities. In the case of inequality, options include declaring AI as a public, rather than private, good.
AI-driven economy. Setting minimum standards for corporate social responsibility reporting would
AI. Economic policies may be required to support workers displaced by AI; such policies should focus
address these and other gapsin order to adequately prepare for the full implications of an AI future.
In addition, to clarify the issue of responsibility pertaining to AI behaviour, moral and legislative
frameworks will require updating alongside the development of the technology itself.
Governments also need to develop new, up-to-date forms of technology assessment – allowing
Accountability Office's Technology Assessment Unit in the USA or the European Foresight platform
(http://www.foresight-platform.eu/). New forms of technology assessment TA should include
evaluation currently being drafted in the IEEE Standards Association P7000 series of ethical
standards; P7001 for instance sets out a method for measuring the transparency of an AI.
face the multifaceted challenges associated with AI, including potential breaches of fundamental
actively shapes the development of AI and as data-driven and machine-learning approaches begin
The ethics of artificial intelligence: Issues and initiatives
disparity between regions. Successful AI development requires substantial investment, and as
automation and intelligent machines begin to drive government processes, there is a real risk that
upon policymakers therefore to try to ensure that AI does not widen global inequalities. This could
include data sharing and collaborative approaches, such as India's promise to share its AI solutions
on AI. It speaks volumes that the nation ranked highest in the 2019 Government AI Readiness Index
has prioritised ethics so strongly in their national AI Strategy. Singapore is one of a few governments
to create an AI Ethics Council and has incorporated a range of ethical considerations into its policy.
developing a national AI strategy. So, aside from any potential moral obligations, it seems unlikely
STOA | Panel for the Future of Science and Technology
into technological developments in AI? How can we program machines to make ethical decisions -
Devising a method for integrating ethics into the design of AI has become a main focus of research
instance by using machine learning. Santos-Lang (2002) points out that this is a better approach, as
The ethics of artificial intelligence: Issues and initiatives
STOA | Panel for the Future of Science and Technology
Access Partnership and the University of Pretoria (2018). Artificial Intelligence for Africa: An Opportunity
https://www.up.ac.za/media/shared/7/ZP_Files/ai-for-africa.zp165664.pdf
Acemoglu, D. and Restrepo, P. (2018) Low-skill and high-skill automation. Journal of Human Capital,
Agency for Digital Italy (2019). Artificial Intelligence task force. [online] IA-Gov. Available from:
AI4All (2019). What we do [online] Available from: http://ai-4-all.org [Accessed 11/03/2019].
AI For Humanity (2018). AI for humanity: French Strategy for Artificial Intelligence [online] Available from:
AI Forum New Zealand (2018). Artificial Intelligence: Shaping a Future New Zealand. Available from:
https://aiforum.org.nz/wp-content/uploads/2018/07/AI-Report-2018_web-version.pdf
AI Now Insitute, (2018). AI Now Report. AI Now Institute, New York University. Available from:
AI Singapore. (2018). AI Singapore. [online] Available from: https://www.aisingapore.org [Accessed 26
AI Taiwan. (2019). AI Taiwan. [online] Available from: https://ai.taiwan.gov.tw [Accessed 28 Apr. 2019].
approaches. Ethics and Information Technology. doi:10.1007/s10676-006-0004-4.
Allen, G,. and Chan, T,. (2017). Artificial Intelligence and National Security. Available from:
https://www.belfercenter.org/sites/default/files/files/publication/AI%20NatSec%20-%20final.pdf
ANPR (2018). National AI Strategy: Unlocking Tunisia's capabilities potential [online] Available from:
http://www.anpr.tn/national-ai-strategy-unlocking-tunisias-capabilities-potential/. [Accessed 6 May
Apps, P. (2019). Commentary: Are China, Russia winning the AI arms race? [online] U.S. Available from:
https://www.reuters.com/article/us-apps-ai-commentary/commentary-are-china-russia-winning-the-aiarms-race-idUSKCN1P91NM.
evaluation of AI systems. Ethics and Information Technology. 20 (1), 59–69.
The ethics of artificial intelligence: Issues and initiatives
Asaro, P. (2012). On Banning Autonomous Weapon Systems: Human Rights, Automation, and the
Atabekov, A. and Yastrebov, O. (2018) Legal status of Artificial Intelligence: Legislation on the move.
Austrian Council on Robotics and Artificial Intelligence (2018). Die Zukunft Österreichs mit Robotik und
Autor, D. H. (2015). Why Are There Still So Many Jobs? The History and Future of Workplace Automation.
temporal features of handwritten behavioural data. In A. Basu, S. Das, P. Horain, and S. Bhattacharya
Bartlett, J. (2018) How AI could kill off democracy. New Statesman. Available from:
https://www.newstatesman.com/science-tech/technology/2018/08/how-ai-could-kill-democracy-0
https://www.bbc.co.uk/news/technology-47668886
https://www.bbc.co.uk/news/technology-47468391
STOA | Panel for the Future of Science and Technology
Bershidsky, L (2017). Elon Musk warns battle for AI supremacy will spark Third World War. The Independent.
Ethics and Information Technology. 20 (41). https://doi.org/10.1007/s10676-018-9444-x
Available from: https://www.cc.gatech.edu/ai/robot-lab/online-publications/RobotsEthicsIntimacyIACAP.pdf
Brundage, M. And Bryson, J. (2016) Smart Policies for Artificial Intelligence.
and Information Technology, 20 (1). 15–26
Bryson, J. J. (2019). The Past Decade and Future of AI's Impact on Society. In Baddeley, M., Castells, M.,
The ethics of artificial intelligence: Issues and initiatives
Burgmann, T. (2016). There's a cure for that: Canadian doctor pushes for more wearable technology.
Global News Canada. Available from: https://globalnews.ca/news/2787549/theres-a-cure-for-thatcanadian-doctor-pushes-for-more-wearable-technology/
Cadwalladr, C. (2017b). Robert Mercer: The big data billionaire waging war on mainstream media. The
York, Data & Society.
Cassim, N. (2019). Dhammika makes strong case for national strategy for AI. [online] Financial Times.
Castellanos, S. (2018). Estonia's CIO Tackles AI Strategy For Government. [online] WSJ. Available from:
https://blogs.wsj.com/cio/2018/11/28/estonias-cio-tackles-ai-strategy-for-government/ [Accessed 10
Canadian Institute For Advanced Research (2017) Pan-Canadian Artificial Intelligence Strategy. [online]
Available from: https://www.cifar.ca/ai/pan-canadian-artificial-intelligence-strategy. [Accessed 4 April
Canadian Institute For Advanced Research (2019). AI & Society Workshops: Call Two. [online] Available
from: https://www.cifar.ca/ai/ai-society/workshops-call-two [Accessed 10 May 2019].
CDEI (2019). 'The Centre for Data Ethics and Innovation (CDEI) 2019/ 20 Work Programme' [online]
Available from: https://www.gov.uk/government/publications/the-centre-for-data-ethics-andinnovation-cdei-2019-20-work-programme/the-centre-for-data-ethics-and-innovation-cdei-2019-20-
report., Justice, Queensland University of Technology.
Christakis, N.A (2019) How AI Will Rewire Us. The Atlantic Magazine, April 2019 Issue. Available from:
STOA | Panel for the Future of Science and Technology
Conn, A. (2018) AI Should Provide a Shared Benefit for as Many People as Possible, Future of Life
Council of Europe (2019a). Ad Hoc Committee on Artificial Intelligence – CAHAI. [online] Available at:
Processing of Personal Data (2019) Guidelines on Artifical Intelligence and Data Protection. Available
from: https://rm.coe.int/guidelines-on-artificial-intelligence-and-data-protection/168091f9d8
Cummings M. (2004). Automation bias in intelligent time critical decision support systems. In AIAA: 1st
Dastin, J. (2018). Amazon scraps secret AI recruiting tool that showed bias against women. Reuters.
Available from: https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazonscrapssecret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G
Hajkowicz, S. (2019). Artificial Intelligence: Australia's Ethics Framework. Available from:
The ethics of artificial intelligence: Issues and initiatives
De.digital. (2018). The Federal Government's Artificial Intelligence Strategy. [online] Available from:
Dignum, V. (2018). Ethics in artificial intelligence: introduction to the special issue. Ethics and
Information Technology, 20: 1.
Digital Poland Foundation (2019). Map of the Polish AI. Digital Poland Foundation..
Duckworth, P., Graham, L., Osborne andM.AI (2019). Inferring Work Task Automatability from AI Expert
Evidence. AAAI / ACM Conference on Artificial Intelligence, Ethics and Society. University of Oxford.
Dutton, T. (2018). An Overview of National AI Strategies. [online] Medium. Available at:
https://medium.com/politics-ai/an-overview-of-national-ai-strategies-2a70ec6edfd [Accessed 4 April
Etzioni, A. and Etzioni, O. (2016). AI assisted ethics. Ethics and Information Technology, 18(2), 149–156
and automation on daily life [online] Available at:
Regions on Artificial Intelligence for Europe. Available from: https://ec.europa.eu/digital-singlemarket/en/news/communication-artificial-intelligence-europe
Regions - Coordinated Plan on Artificial Intelligence (COM(2018) 795 final). Available from:
European Commission (2018c). High-level expert group on artificial intelligence: Draft ethics guidelines
for trustworthy AI. Brussels. [online] Available from:
STOA | Panel for the Future of Science and Technology
European Commission (2018d). EU Member States sign up to cooperate on Artificial Intelligence.
European Commission High-Level Expert Group on Artificial Intelligence (2019) Ethics Guidelines for
Trustworthy AI. Available from: https://ec.europa.eu/newsroom/dae/document.cfm?doc_id=58477
European Commission High-Level Expert Group on AI (2019b) Policy and Investment
Recommendations for Trustworthy AI. Available from: https://ec.europa.eu/digital-singlemarket/en/news/policy-and-investment-recommendations-trustworthy-artificial-intelligence
Ezrachi, A., & Stucke, M. E. (2016). Two artificial neural networks meet in an online hub and change the
Floridi, L., & Taddeo, M. (2016). What is data ethics? Philosophical Transactions of the Royal Society A:
Ford, M. (2009) The Lights in the Tunnel: Automation, Accelerating Technology, and the Economy of the
The ethics of artificial intelligence: Issues and initiatives
Foundation for Law & International Affairs (2017) China's New Generation of Artificial Intelligence
Computerisation? Oxford Martin Programme on the Impacts of Future Technology.
Furman, J & Seamans, R. (2018). AI and the Economy. NBER working paper no.24689
Future of Life Institute (2019). National and International AI Strategies.Future of Life Institute. [online]
Available from: https://futureoflife.org/national-international-ai-strategies/ [Accessed 28 Apr. 2019].
Gagan, O. (2018) Here's how AI fits into the future of energy, World Economic Forum, 25 May 2018
[Online] Available at: https://www.weforum.org/agenda/2018/05/how-ai-can-help-meet-globalenergy-demand [Accessed on 13 Aug. 2019].
Garfinkel, S. (2017). Hackers are the real obstacle for self-driving vehicles. MIT Technology Review.
Available from: https://www.theguardian.com/technology/2017/jan/20/tesla-model-s-cleared-autosafety-regulator-after-fatal-autopilot-crash
UK Government Office for Science (2015) Artificial intelligence: opportunities and implications for the
66075/gs-16-19-artificial-intelligence-ai-report.pdf [Accessed 13 Aug. 2019].
GOV.UK. (2018a). AI Sector Deal. [online] Available from
https://www.gov.uk/government/publications/artificial-intelligence-sector-deal/ai-sector-deal
GOV.UK. (2018b). Centre for Data Ethics and Innovation (CDEI). [online] Available from:
https://www.gov.uk/government/groups/centre-for-data-ethics-and-innovation-cdei [Accessed 10 May
STOA | Panel for the Future of Science and Technology
Government Offices of Sweden (2018). National approach to artificial intelligence. Ministry of Enterprise
Hadfield-Menell, D., Dragan, A., Abbeel, P., and Russell, S. (2016). The off-switch game. In: IJCAI-ECAI2018: International Joint Conference on Artificial Intelligence. IJCAI-ECAI-2018, 13-19 July 2018, Stockholm,
Hallaq, B.,, Somer, T., Osula, A., Ngo, K., & Mitchener-Nissen, T. (2017). Artificial intelligence within the
Hallevy, G. (2010) The Criminal Liability of Artificial Intelligence Entities (February 15, 2010). Available at
analysis of deception in computer-mediated communication. Discourse Processes. 45(1): 1–23.
Hardt, M. (2014). How Big Data is Unfair. Medium. [online] Available from [accessed 9 Apr. 2019]
Hawksworth, J. and Fertig, Y. (2018) What will be the net impact of AI and related technologies on jobs
Hern, A. (2016). 'Partnership on AI' formed by Google, Facebook, Amazon, IBM and Microsoft. The
Guardian. Available from: https://www.theguardian.com/technology/2016/sep/28/google-facebookamazon-ibm-microsoft-partnership-on-ai-tech-firms
The ethics of artificial intelligence: Issues and initiatives
Iglinski, H., Babiak, M. (2017). Analysis of the Potential of Autonomous Vehicles in Reducing the
International Telecommunication Union (2018). AI for Good Global Summit 2018 [online] Available from:
https://www.itu.int/en/ITU-T/AI/2018/Pages/default.aspx [Accessed 14 May 2019].
International Telecommunication Union (2018). United Nations Activities on Artificial Intelligence
https://www.nytimes.com/2016/10/26/technology/self-driving-trucks-first-mission-a-beer-run.html
Japanese Strategic Council for AI Technology (2017). Artificial Intelligence Technology Strategy. Available
JSAI (2017). Ethical Guidelines. [online] Available from: http://ai-elsi.org/wpcontent/uploads/2017/05/JSAI-Ethical-Guidelines-1.pdf [Accessed 7 May19].
JSAI (2019). Overview: Inaugural Address of President Naohiko Uramoto, Artificial Intelligence expanding its
scope and impact in our society. [online] Available from: https://www.ai-gakkai.or.jp/en/about/about-us/
Kayali, L. (2019). Next European Commission takes aim at AI. [online] POLITICO. Available at:
https://www.politico.eu/article/ai-data-regulator-rules-next-european-commission-takes-aim/
Kenyan Wall Street (2018). Kenya Govt unveils 11 Member Blockchain & AI Taskforce headed by Bitange
Ndemo. Kenyan Wallstreet. [online. Available from: https://kenyanwallstreet.com/kenya-govt-unveils11-member-blockchain-ai-taskforce-headed-by-bitange-ndemo/ [Accessed 6 May 2019].
STOA | Panel for the Future of Science and Technology
King, T.C., Aggarwal, N., Taddeo, M. et al. (2019). Artificial Intelligence Crime: An Interdisciplinary
Analysis of Foreseeable Threats and Solutions. Sci Eng Ethics. pp.1-32
Kingston, J. K. C. (2018) Artificial Intelligence and Legal Liability. Available at:
Knight, W. (2019). The World Economic Forum wants to develop global rules for AI. [online] MIT
Technology Review. Available at: https://www.technologyreview.com/s/613589/the-world-economicforum-wants-to-develop-global-rules-for-ai/ [Accessed 20 Aug. 2019].
LaRosa, E., & Danks, D. (2018). Impacts on Trust of Healthcare AI. In: AAAI / ACM Conference on Artificial
Sustainable AI report. AI Sustainability Centre. Available from: http://www.aisustainability.org/wpcontent/uploads/2019/04/SUSTAINABLE-AI.pdf
Lashbrook, A. (2018). AI-driven dermatology could leave dark-skinned patients behind. The Atlantic.
Long-Term Impact of Technology on Employment and Unemployment. Washington, DC: The National
The ethics of artificial intelligence: Issues and initiatives
Available from: https://www.theguardian.com/technology/2018/mar/22/video-released-of-uber-selfdriving-crash-that-killed-woman-in-arizona
Normative Behavior Across Cultures. In: AAAI / ACM Conference on Artificial Intelligence, Ethics and
Li, S., Williams, J. (2018). Despite what Zuckerberg's testimony may imply, AI Cannot Save Us. Electronic
Frontier Foundation. Available from: https://www.eff.org/deeplinks/2018/04/despite-whatzuckerbergstestimony-may-imply-ai-cannot-save-us
Lim, D., (2019). Killer Robots and Human Dignity. In: AAAI / ACM Conference on Artificial Intelligence,
Lin, P., Jenkins, R., & Abney, K. (2017). Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence.
Malta AI (2019). Malta AI: Towards a National AI Strategy [online] Available at: https://malta.ai [Accessed
Privacy Concerns in Intelligent Personal Assistants. In: AAAI / ACM Conference on Artificial Intelligence,
Marda, V,. (2018). Artificial intelligence policy in India: a framework for engaging the limits of datadriven decision-making. Philosophical Transactions of the Royal Society A: Mathematical, Physical and
(2018). Towards an AI Strategy in Mexico: Harnessing the AI Revolution.
Mattheij, J. (2016) 'Another Way Of Looking At Lee Sedol vs AlphaGo'. Jacques Mattheij: Technology,
Ethics and Information Technology, Sept 2004, Vol. 6, Issue 3, pp.175-183.
STOA | Panel for the Future of Science and Technology
Mbadiwe, T. (2017). The potential pitfalls of machine learning algorithms in medicine. Pulmonology
McAllister, A. (2017). Stranger than science fiction: The rise of AI interrogation in the dawn of
Millar, J. (2016). An Ethics Evaluation Tool for Automating Ethical Decision-Making in Robots and SelfDriving Cars. 30(8), 787-809.
Min, W. (2018) Smart Policies for Harnessing AI, OECD-Forum, 17 Sept 2018 [online] Available from:
https://www.oecd-forum.org/users/68225-wonki-min/posts/38898-harnessing-ai-for-smart-policies
Ministry of Economic Affairs and Employment of Finland (2017). Finland's Age of Artificial Intelligence.
Ministry of Economic Affairs and Employment of Finland (2018a). Artificial intelligence programme.
Ministry of Economic Affairs and Employment of Finland (2018b). Work in the Age of Artificial Intelligence.
Mizoguchi, R. (2004). The JSAI and AI activity in Japan. IEEE Intelligent Systems 19 (2).
Moon, M., (2017). Judge allows pacemaker data to be used in arson trial. Engadget. Available from:
National Science & Technology Council (2019) The National Artificial Intelligence Research and
Development Strategic Plan: 2019 Update. Available from: https://www.whitehouse.gov/wpcontent/uploads/2019/06/National-AI-Research-and-Development-Strategic-Plan-2019-Update-June2019.pdf
Nemitz, P,. (2018). Constitutional democracy and technology in the age of artificial intelligence.
The ethics of artificial intelligence: Issues and initiatives
NITI Aayog (2018). National Strategy for Artificial Intelligence #AIFORALL.
Nevejans, N. et al. (2018). Open letter to the European Commission on Artificial Intelligence and Robotics.
New America. (2018). Translation: Chinese government outlines AI ambitions through 2020. [online]
Available from: https://www.newamerica.org/cybersecurity-initiative/digichina/blog/translationchinese-government-outlines-ai-ambitions-through-2020/ [Accessed 27 Apr. 2019].
Nordic cooperation (2018). AI in the Nordic-Baltic region. [online] Available from:
https://www.norden.org/en/declaration/ai-nordic-baltic-region [Accessed 26 Apr. 2019].
O'Neil, C,. (2016). Weapons of Math Destruction: How Big Data Increases Inequality and Threatens
Privacy and Transborder Flows of Personal Data [OECD/LEGAL/0188]
OECD (n.d.) OECD initiatives on AI [online] Available at: http://www.oecd.org/going-digital/ai/
STOA | Panel for the Future of Science and Technology
Orseau, L. & Armstrong, S. (2016). Safely interruptible agents. In: Uncertainty in artificial intelligence: 32nd
Oxford Insights (2019) Government Artificial Intelligence Readiness Index. Available from:
https://ai4d.ai/wp-content/uploads/2019/05/ai-gov-readiness-report_v08.pdf
status of AI systems. Philosophical Transactions of the Royal Society A: Mathematical, Physical and
https://money.cnn.com/2017/11/09/technology/self-driving-bus-accident-las-vegas/index.html
Personal Data Protection Commission Singapore (2019). A Proposed Model Artificial Intelligence
Governance Framework. Available from: https://www.pdpc.gov.sg/-/media/Files/PDPC/PDFFiles/Resource-for-Organisation/AI/A-Proposed-Model-AI-Governance-Framework-January-2019.pdf
https://www.theguardian.com/technology/2014/oct/10/medical-robots-surgery-trust-future
Plantera, F. (2017). Artificial Intelligence is the next step for e-governance in Estonia, State adviser
Press Association (2019). Robots and AI to give doctors more time with patients, says report. The
Guardian. Available from: https://www.theguardian.com/society/2019/feb/11/robots-and-ai-to-givedoctors-more-time-with-patients-says-report
The ethics of artificial intelligence: Issues and initiatives
Information Technology. 20: 5. https://doi.org/10.1007/s10676-017-9430-8
automation' standard for self-driving vehicles. SAE International. Available from:
https://www.sae.org/news/press-room/2018/12/sae-international-releases-updated-visual-chart-forits-'levels-of-driving-automation'-standard-for-self-driving-vehicles
Saidot (2019). About us [online] Available from: https://www.saidot.ai/about-us [Accessed 3 May
Santos-Lang, C. (2002). Ethics for Artificial Intelligences. In Wisconsin State-Wide technology
Symposium 'Promise or Peril?'. Reflecting on computer technology: Educational, psychological, and ethical
Sarmah, H. (2019). Looking East: How South Korea Is Making A Strategic Move In AI. [online] Analytics
India Magazine. Available from: https://www.analyticsindiamag.com/looking-east-how-south-korea-ismaking-a-strategic-move-for-ai-leadership/ [Accessed 28 Apr. 2019].
STOA | Panel for the Future of Science and Technology
Sathe G. (2018). Cops in India are using artificial intelligence that can identify you in a crowd. Huffington
Scherer, M. U. (2016) Regulating Artificial Intelligence Systems: Risks, Challenges, Competencies, and
Schönberger, D. (2019). Artificial intelligence in healthcare: a critical analysis of the legal and ethical
implications. International Journal of Law and Information Technology 27 (2), 171–203.
Selbst, A. D. and Powles, J. (2017) Meaningful information and the right to explanation. Int. Data Privacy
Future: A Companion to Philosophy of Technology, New York: Routledge.
Servoz, M. (2019) The Future of Work? Work of the Future! On How Artificial Intelligence, Robotics and
Automation Are Transforming Jobs and the Economy in Europe, 10 May 2019. Available at:
Seth, S. (2017). Machine Learning and Artificial Intelligence Interactions with the Right to Privacy.
Ethics and Information Technology. 14 (1): 27-40.
from: https://www.theguardian.com/technology/2017/jan/11/robots-jobs-employees-artificialintelligence.
The ethics of artificial intelligence: Issues and initiatives
Smart Dubai (2019a). AI Ethics. [online] Available from: https://www.smartdubai.ae/initiatives/ai-ethics
Smith, A., & Anderson, J. (2014). AI, Robotics, and the Future of Jobs. Pew Research Center
Smith, B. (2018). Facial recognition technology: The need for public regulation and corporate
responsibility. Microsoft on the Issues. Available from: https://blogs.microsoft.com/on-theissues/2018/07/13/facial-recognition-technology-the-need-for-public-regulation-and-corporateresponsibility/
Guardian. Available from: https://www.theguardian.com/technology/2018/jan/24/self-driving-carsdangerous-period-false-security
Sparrow, R,. (2002). The march of the robot dogs. Ethics and Information Technology. 4 (4), 305–318.
Strubell, E., Ganesh, A. and McCallum, A. (2019) Energy and Policy Considerations for Deep Learning in
Swedish AI Council. (2019). Swedish AI Council. [online] Available from: https://swedishaicouncil.com
Taddeo, M. and Floridi, L. (2018) How AI can be a force for good. Science vol. 361, issue 6404, pp.751-
Task Force on Artificial Intelligence of the Agency for Digital Italy (2018). White Paper on Artificial
STOA | Panel for the Future of Science and Technology
The Danish Government (2019). National Strategy for Artificial Intelligence. Ministry of Finance and
The Future of Life Institute (n.d.) AI Policy Challenges and Recommendations. Available at:
https://futureoflife.org/ai-policy-challenges-and-recommendations/#top [Accessed 12/08/19].
The Future of Life Institute (2019). Background: Benefits and Risks of Artificial Intelligence.[online].
The Institute for Ethical AI & Machine Learning (2019). Homepage [online] Available from:
The Partnership on AI (2019). About us [online] Available from: https://www.partnershiponai.org/about/
The White House (2016) Artificial Intelligence, Automation, and the Economy [online] Available from:
The White House (2019a). Accelerating America's Leadership in Artificial Intelligence. [online] Available
The White House (2019b). Artificial Intelligence for the American People [online] Available from:
https://www.whitehouse.gov/ai/. [Accessed 28 Apr. 2019].
Thiagarajan, K. (2019). The AI program that can tell whether you may go blind. The Guardian. Available
from: https://www.theguardian.com/world/2019/feb/08/the-ai-program-that-can-tell-whether-youare-going-blind-algorithm-eye-disease-india-diabetes
Thielman, S. (2017). The customer is always wrong: Tesla lets out self-driving car data – when it suits.
The Guardian. Available from: https://www.theguardian.com/technology/2017/apr/03/the-customer-isalways-wrong-tesla-lets-out-self-driving-car-data-when-it-suits
Thurman N. (2011). Making 'The Daily Me': technology, economics and habit in the mainstream
The ethics of artificial intelligence: Issues and initiatives
Tindera, M. (2018). Government data says millions of health records are breached every year. Forbes.
https://www.forbes.com/sites/michelatindera/2018/09/25/government-data-says-millions-of-healthrecords-are-breached-every-year/#209fca3716e6
Torres Santeli, J. and Gerdon, S. (2019). 5 challenges for government adoption of AI. [online] World
TUM (2019). New Research Institute for Ethics in Artificial Intelligence [Press Release]. Available from:
UAE Government (2018). UAE Artificial Intelligence Strategy 2031. [online] Available from:
UCL (2019). IOE professor co-founds the UK's first Institute for Ethical Artificial Intelligence in Education
UNICRI (2019). UNICRI Centre for Artificial Intelligence and Robotics [online]. Available from:
UK Government Department for Digital, Culture, Media & Sport (2019). Centre for Data Ethics and
Innovation: 2-year strategy. Available from: https://www.gov.uk/government/publications/the-centrefor-data-ethics-and-innovation-cdei-2-year-strategy
UNI Global Union (n.d.) Top 10 principles for Ethical Artificial Intelligence [online]. Available from:
Université de Montréal (2017). Montreal Declaration for a Responsible Development of AI' [online]
US Department of Defence (2018). Summary of the 2018 Department of Defence Artificial Intelligence
Strategy: Harnessing AI to Advance Our Security and Prosperity. Available from:
https://media.defense.gov/2019/Feb/12/2002088963/-1/-1/1/SUMMARY-OF-DOD-AI-STRATEGY.PDF
U.S. Department of Education, (2014). Science, Technology, Engineering and Math.
STOA | Panel for the Future of Science and Technology
Veale, M., Binns., R & Edwards, L. (2018). Algorithms that remember: model inversion attacks and data
Villani, C. (2018). For a Meaningful Artificial Intelligence: Towards a French and European Strategy.
Vincent, J. (2017). Google's AI thinks this turtle looks like a gun, which is a problem. The Verge. Available
from: https://www.theverge.com/2017/11/2/16597276/google-ai-image-attacks-adversarial-turtle-rifle3d-printed
Vincent J. (2018). Drones taught to spot violent behavior in crowds using AI. The Verge. Available from:
https://www.theverge.com/2018/6/6/17433482/ai-automated-surveillance-drones-spotviolentbehavior-crowds.
does not exist in the general data protection regulation. Int. Data Privacy Law 7, 76–99.
Box: Automated Decisions and the GDPR. Harvard Journal of Law & Technology. 31 (2).
Conference on Artificial Intelligence, Ethics and Society. AIES: 2018, 1-3 February, 2018, New Orleans, USA.
West, D. M. (2018). The Future of Work: Robots, AI, and Automation. Brookings Institution Press
Williams, R. (2017). Lords select committee, artificial intelligence committee, written evidence (AIC0206).
The ethics of artificial intelligence: Issues and initiatives
http://data.parliament.uk/writtenevidence/committeeevidence.svc/evidencedocument/artificialintelligence-committee/artificial-intelligence/written/70496.html#_ftn13
artificial intelligence systems. Philosophical Transactions of the Royal Society A: Mathematical, Physical
Winfield, A. F. (2019a). Ethical standards in Robotics and AI. Nature Electronics, 2(2), 46-48.
Wolfe, F. and Mavon, K. (2017) How artificial intelligence will revolutionise the energy industry [online]
Technology. [online] Available at: https://www.weforum.org/press/2019/05/world-economic-foruminaugurates-global-councils-to-restore-trust-in-technology/ [Accessed 17 Aug. 2019].
https://www.theguardian.com/technology/2016/jun/30/tesla-autopilot-death-self-driving-car-elonmusk
Zou, J. & Schiebinger, L. (2018). 'AI can be sexist and racist — it's time to make it fair', Nature Available
implementation of artificial intelligence (AI)
and more complex and less certain implications of AI,
Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.[1] Such machines may be called AIs.
Some high-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); interacting via human speech (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT, and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: "A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore."[2][3]
The various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics.[a] General intelligence—the ability to complete any task performable by a human on an at least equal level—is among the field's long-term goals.[4] To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.[5]
Artificial intelligence was founded as an academic discipline in 1956,[6] and the field went through multiple cycles of optimism,[7][8] followed by periods of disappointment and loss of funding, known as AI winter.[9][10] Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques.[11] This growth accelerated further after 2017 with the transformer architecture,[12] and by the early 2020s hundreds of billions of dollars were being invested in AI (known as the "AI boom"). The widespread use of AI in the 21st century exposed several unintended consequences and harms in the present and raised concerns about its risks and long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.
The general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.[a]
Many of these algorithms are insufficient for solving large reasoning problems because they experience a "combinatorial explosion": They become exponentially slower as the problems grow.[15] Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.[16] Accurate and efficient reasoning is an unsolved problem.
Knowledge representation and knowledge engineering[17] allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval,[18] scene interpretation,[19] clinical decision support,[20] knowledge discovery (mining "interesting" and actionable inferences from large databases),[21] and other areas.[22]
Among the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous);[29] and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as "facts" or "statements" that they could express verbally).[16] There is also the difficulty of knowledge acquisition, the problem of obtaining knowledge for AI applications.[c]
In some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning), or the agent can seek information to improve its preferences.[37] Information value theory can be used to weigh the value of exploratory or experimental actions.[38] The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be.
Game theory describes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents.[40]
Machine learning is the study of programs that can improve their performance on a given task automatically.[41] It has been a part of AI from the beginning.[e]
There are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance.[44] Supervised learning requires a human to label the input data first, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).[45]
In reinforcement learning, the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as "good".[46] Transfer learning is when the knowledge gained from one problem is applied to a new problem.[47] Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.[48]
Computational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.[49]
Natural language processing (NLP)[50] allows programs to read, write and communicate in human languages such as English. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.[51]
Modern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning),[52] transformers (a deep learning architecture using an attention mechanism),[53] and others.[54] In 2019, generative pre-trained transformer (or "GPT") language models began to generate coherent text,[55][56] and by 2023, these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world applications.[57]
The field includes speech recognition,[59] image classification,[60] facial recognition, object recognition,[61]object tracking,[62] and robotic perception.[63]
However, this tends to give naïve users an unrealistic conception of the intelligence of existing computer agents.[66] Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis, wherein AI classifies the affects displayed by a videotaped subject.[67]
AI research uses a wide variety of techniques to accomplish the goals above.[b]
AI can solve many problems by intelligently searching through many possible solutions.[68] There are two very different kinds of search used in AI: state space search and local search.
State space search searches through a tree of possible states to try to find a goal state.[69] For example, planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.[70]
Local search uses mathematical optimization to find a solution to a problem. It begins with some form of guess and refines it incrementally.[74]
Gradient descent is a type of local search that optimizes a set of numerical parameters by incrementally adjusting them to minimize a loss function. Variants of gradient descent are commonly used to train neural networks.[75]
Distributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).[77]
Many problems in AI (including in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics.[86] Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis,[87] and information value theory.[88] These tools include models such as Markov decision processes,[89] dynamic decision networks,[90] game theory and mechanism design.[91]
Bayesian networks[92] are a tool that can be used for reasoning (using the Bayesian inference algorithm),[g][94] learning (using the expectation–maximization algorithm),[h][96] planning (using decision networks)[97] and perception (using dynamic Bayesian networks).[90]
Probabilistic algorithms can also be used for filtering, prediction, smoothing, and finding explanations for streams of data, thus helping perception systems analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).[90]
The simplest AI applications can be divided into two types: classifiers (e.g., "if shiny then diamond"), on one hand, and controllers (e.g., "if diamond then pick up"), on the other hand. Classifiers[98] are functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning. Each pattern (also called an "observation") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.[45]
There are many kinds of classifiers in use.[99] The decision tree is the simplest and most widely used symbolic machine learning algorithm.[100] K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.[101]
Neural networks are also used as classifiers.[104]
An artificial neural network is based on a collection of nodes also known as artificial neurons, which loosely model the neurons in a biological brain. It is trained to recognise patterns; once trained, it can recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output. Each node applies a function and once the weight crosses its specified threshold, the data is transmitted to the next layer. A network is typically called a deep neural network if it has at least 2 hidden layers.[104]
Learning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm.[105] Neural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function.[106]
In feedforward neural networks the signal passes in only one direction.[107] Recurrent neural networks feed the output signal back into the input, which allows short-term memories of previous input events. Long short term memory is the most successful network architecture for recurrent networks.[108] Perceptrons[109] use only a single layer of neurons; deep learning[110] uses multiple layers. Convolutional neural networks strengthen the connection between neurons that are "close" to each other—this is especially important in image processing, where a local set of neurons must identify an "edge" before the network can identify an object.[111]
Deep learning[110] uses several layers of neurons between the network's inputs and outputs. The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits, letters, or faces.[112]
Deep learning has profoundly improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, natural language processing, image classification,[113] and others. The reason that deep learning performs so well in so many applications is not known as of 2023.[114] The sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)[i] but because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.[j]
Generative pre-trained transformers (GPT) are large language models (LLMs) that generate text based on the semantic relationships between words in sentences. Text-based GPT models are pretrained on a large corpus of text that can be from the Internet. The pretraining consists of predicting the next token (a token being usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate knowledge about the world and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful, and harmless, usually with a technique called reinforcement learning from human feedback (RLHF). Current GPT models are prone to generating falsehoods called "hallucinations", although this can be reduced with RLHF and quality data. They are used in chatbots, which allow people to ask a question or request a task in simple text.[122][123]
Current models and services include Gemini (formerly Bard), ChatGPT, Grok, Claude, Copilot, and LLaMA.[124] Multimodal GPT models can process different types of data (modalities) such as images, videos, sound, and text.[125]
In the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models' training.[126] Specialized programming languages such as Prolog were used in early AI research,[127] but general-purpose programming languages like Python have become predominant.[128]
AI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search), targeting online advertisements, recommendation systems (offered by Netflix, YouTube or Amazon), driving internet traffic, targeted advertising (AdSense, Facebook), virtual assistants (such as Siri or Alexa), autonomous vehicles (including drones, ADAS and self-driving cars), automatic language translation (Microsoft Translator, Google Translate), facial recognition (Apple's Face ID or Microsoft's DeepFace and Google's FaceNet) and image labeling (used by Facebook, Apple's iPhoto and TikTok). The deployment of AI may be overseen by a Chief automation officer (CAO).
The application of AI in medicine and medical research has the potential to increase patient care and quality of life.[130] Through the lens of the Hippocratic Oath, medical professionals are ethically compelled to use AI, if applications can more accurately diagnose and treat patients.[131][132]
For medical research, AI is an important tool for processing and integrating big data. This is particularly important for organoid and tissue engineering development which use microscopy imaging as a key technique in fabrication.[133] It has been suggested that AI can overcome discrepancies in funding allocated to different fields of research.[133] New AI tools can deepen the understanding of biomedically relevant pathways. For example, AlphaFold 2 (2021) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein.[134] In 2023, it was reported that AI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-resistant bacteria.[135] In 2024, researchers used machine learning to accelerate the search for Parkinson's disease drug treatments. Their aim was to identify compounds that block the clumping, or aggregation, of alpha-synuclein (the protein that characterises Parkinson's disease). They were able to speed up the initial screening process ten-fold and reduce the cost by a thousand-fold.[136][137]
Game playing programs have been used since the 1950s to demonstrate and test AI's most advanced techniques.[138] Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997.[139] In 2011, in a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin.[140] In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. Then, in 2017, it defeated Ke Jie, who was the best Go player in the world.[141] Other programs handle imperfect-information games, such as the poker-playing program Pluribus.[142] DeepMind developed increasingly generalistic reinforcement learning models, such as with MuZero, which could be trained to play chess, Go, or Atari games.[143] In 2019, DeepMind's AlphaStar achieved grandmaster level in StarCraft II, a particularly challenging real-time strategy game that involves incomplete knowledge of what happens on the map.[144] In 2021, an AI agent competed in a PlayStation Gran Turismo competition, winning against four of the world's best Gran Turismo drivers using deep reinforcement learning.[145] In 2024, Google DeepMind introduced SIMA, a type of AI capable of autonomously playing nine previously unseen open-world video games by observing screen output, as well as executing short, specific tasks in response to natural language instructions.[146]
In mathematics, special forms of formal step-by-step reasoning are used. In contrast, LLMs such as GPT-4 Turbo, Gemini Ultra, Claude Opus, LLaMa-2 or Mistral Large are working with probabilistic models, which can produce wrong answers in the form of hallucinations. Therefore, they need not only a large database of mathematical problems to learn from but also methods such as supervised fine-tuning or trained classifiers with human-annotated data to improve answers for new problems and learn from corrections.[147] A 2024 study showed that the performance of some language models for reasoning capabilities in solving math problems not included in their training data was low, even for problems with only minor deviations from trained data.[148]
Alternatively, dedicated models for mathematic problem solving with higher precision for the outcome including proof of theorems have been developed such as Alpha Tensor, Alpha Geometry and Alpha Proof all from Google DeepMind,[149] Llemma from eleuther[150] or Julius.[151]
Some models have been developed to solve challenging problems and reach good results in benchmark tests, others to serve as educational tools in mathematics.[152]
Finance is one of the fastest growing sectors where applied AI tools are being deployed: from retail online banking to investment advice and insurance, where automated "robot advisers" have been in use for some years.[153]
World Pensions experts like Nicolas Firzli insist it may be too early to see the emergence of highly innovative AI-informed financial products and services: "the deployment of AI tools will simply further automatise things: destroying tens of thousands of jobs in banking, financial planning, and pension advice in the process, but I'm not sure it will unleash a new wave of [e.g., sophisticated] pension innovation."[154]
Various countries are deploying AI military applications.[155] The main applications enhance command and control, communications, sensors, integration and interoperability.[156] Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles.[155] AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles involving manned and unmanned teams.[156] AI was incorporated into military operations in Iraq and Syria.[155]
In November 2023, US Vice President Kamala Harris disclosed a declaration signed by 31 nations to set guardrails for the military use of AI. The commitments include using legal reviews to ensure the compliance of military AI with international laws, and being cautious and transparent in the development of this technology.[157]
In the early 2020s, generative AI gained widespread prominence. GenAI is AI capable of generating text, images, videos, or other data using generative models,[158][159] often in response to prompts.[160][161]
In March 2023, 58% of U.S. adults had heard about ChatGPT and 14% had tried it.[162] The increasing realism and ease-of-use of AI-based text-to-image generators such as Midjourney, DALL-E, and Stable Diffusion sparked a trend of viral AI-generated photos. Widespread attention was gained by a fake photo of Pope Francis wearing a white puffer coat, the fictional arrest of Donald Trump, and a hoax of an attack on the Pentagon, as well as the usage in professional creative arts.[163][164]
Artificial intelligent (AI) agents are software entities designed to perceive their environment, make decisions, and take actions autonomously to achieve specific goals. These agents can interact with users, their environment, or other agents. AI agents are used in various applications, including virtual assistants, chatbots, autonomous vehicles, game-playing systems, and industrial robotics. AI agents operate within the constraints of their programming, available computational resources, and hardware limitations. This means they are restricted to performing tasks within their defined scope and have finite memory and processing capabilities. In real-world applications, AI agents often face time constraints for decision-making and action execution. Many AI agents incorporate learning algorithms, enabling them to improve their performance over time through experience or training. Using machine learning, AI agents can adapt to new situations and optimise their behaviour for their designated tasks.[165][166][167]
There are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported having incorporated "AI" in some offerings or processes.[168] A few examples are energy storage, medical diagnosis, military logistics, applications that predict the result of judicial decisions, foreign policy, or supply chain management.
AI applications for evacuation and disaster management are growing. AI has been used to investigate if and how people evacuated in large scale and small scale evacuations using historical data from GPS, videos or social media. Further, AI can provide real time information on the real time evacuation conditions.[169][170][171]
In agriculture, AI has helped farmers identify areas that need irrigation, fertilization, pesticide treatments or increasing yield. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conduct predictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water.
Artificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for "classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights." For example, it is used for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. Additionally, it could be used for activities in space, such as space exploration, including the analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation.
During the 2024 Indian elections, US$50 millions was spent on authorized AI-generated content, notably by creating deepfakes of allied (including sometimes deceased) politicians to better engage with voters, and by translating speeches to various local languages.[172]
AI has potential benefits and potential risks.[173] AI may be able to advance science and find solutions for serious problems: Demis Hassabis of Deep Mind hopes to "solve intelligence, and then use that to solve everything else".[174] However, as the use of AI has become widespread, several unintended consequences and risks have been identified.[175] In-production systems can sometimes not factor ethics and bias into their AI training processes, especially when the AI algorithms are inherently unexplainable in deep learning.[176]
Machine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy, surveillance and copyright.
AI-powered devices and services, such as virtual assistants and IoT products, continuously collect personal information, raising concerns about intrusive data gathering and unauthorized access by third parties. The loss of privacy is further exacerbated by AI's ability to process and combine vast amounts of data, potentially leading to a surveillance society where individual activities are constantly monitored and analyzed without adequate safeguards or transparency.
Sensitive user data collected may include online activity records, geolocation data, video or audio.[177] For example, in order to build speech recognition algorithms, Amazon has recorded millions of private conversations and allowed temporary workers to listen to and transcribe some of them.[178] Opinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy.[179]
AI developers argue that this is the only way to deliver valuable applications. and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation, de-identification and differential privacy.[180] Since 2016, some privacy experts, such as Cynthia Dwork, have begun to view privacy in terms of fairness. Brian Christian wrote that experts have pivoted "from the question of 'what they know' to the question of 'what they're doing with it'."[181]
Generative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under the rationale of "fair use". Experts disagree about how well and under what circumstances this rationale will hold up in courts of law; relevant factors may include "the purpose and character of the use of the copyrighted work" and "the effect upon the potential market for the copyrighted work".[182][183] Website owners who do not wish to have their content scraped can indicate it in a "robots.txt" file.[184] In 2023, leading authors (including John Grisham and Jonathan Franzen) sued AI companies for using their work to train generative AI.[185][186] Another discussed approach is to envision a separate sui generis system of protection for creations generated by AI to ensure fair attribution and compensation for human authors.[187]
The commercial AI scene is dominated by Big Tech companies such as Alphabet Inc., Amazon, Apple Inc., Meta Platforms, and Microsoft.[188][189][190] Some of these players already own the vast majority of existing cloud infrastructure and computing power from data centers, allowing them to entrench further in the marketplace.[191][192]
In January 2024, the International Energy Agency (IEA) released Electricity 2024, Analysis and Forecast to 2026, forecasting electric power use.[193] This is the first IEA report to make projections for data centers and power consumption for artificial intelligence and cryptocurrency. The report states that power demand for these uses might double by 2026, with additional electric power usage equal to electricity used by the whole Japanese nation.[194]
Prodigious power consumption by AI is responsible for the growth of fossil fuels use, and might delay closings of obsolete, carbon-emitting coal energy facilities. There is a feverish rise in the construction of data centers throughout the US, making large technology firms (e.g., Microsoft, Meta, Google, Amazon) into voracious consumers of electric power. Projected electric consumption is so immense that there is concern that it will be fulfilled no matter the source. A ChatGPT search involves the use of 10 times the electrical energy as a Google search. The large firms are in haste to find power sources – from nuclear energy to geothermal to fusion. The tech firms argue that – in the long view – AI will be eventually kinder to the environment, but they need the energy now. AI makes the power grid more efficient and "intelligent", will assist in the growth of nuclear power, and track overall carbon emissions, according to technology firms.[195]
A 2024 Goldman Sachs Research Paper, AI Data Centers and the Coming US Power Demand Surge, found "US power demand (is) likely to experience growth not seen in a generation...." and forecasts that, by 2030, US data centers will consume 8% of US power, as opposed to 3% in 2022, presaging growth for the electrical power generation industry by a variety of means.[196] Data centers' need for more and more electrical power is such that they might max out the electrical grid. The Big Tech companies counter that AI can be used to maximize the utilization of the grid by all.[197]
In 2024, the Wall Street Journal reported that big AI companies have begun negotiations with the US nuclear power providers to provide electricity to the data centers. In March 2024 Amazon purchased a Pennsylvania nuclear-powered data center for $650 Million (US).[198] Nvidia CEO Jen-Hsun Huang said nuclear power is a good option for the data centers.[199]
After the last approval in September 2023, Taiwan suspended the approval of data centers north of Taoyuan with a capacity of more than 5 MW in 2024, due to power supply shortages.[202] Taiwan aims to phase out nuclear power by 2025.[202] On the other hand, Singapore imposed a ban on the opening of data centers in 2019 due to electric power, but in 2022, lifted this ban.[202]
Although most nuclear plants in Japan have been shut down after the 2011 Fukushima nuclear accident, according to an October 2024 Bloomberg article in Japanese, cloud gaming services company Ubitus, in which Nvidia has a stake, is looking for land in Japan near nuclear power plant for a new data center for generative AI.[203] Ubitus CEO Wesley Kuo said nuclear power plants are the most efficient, cheap and stable power for AI.[203]
On 1 November 2024, the Federal Energy Regulatory Commission (FERC) rejected an application submitted by Talen Energy for approval to supply some electricity from the nuclear power station Susquehanna to Amazon's data center.[204] 
YouTube, Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation, conspiracy theories, and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation.[205] This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government.[206] The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took steps to mitigate the problem [citation needed].
In 2022, generative AI began to create images, audio, video and text that are indistinguishable from real photographs, recordings, films, or human writing. It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda.[207] AI pioneer Geoffrey Hinton expressed concern about AI enabling "authoritarian leaders to manipulate their electorates" on a large scale, among other risks.[208]
Machine learning applications will be biased[k] if they learn from biased data.[210] The developers may not be aware that the bias exists.[211] Bias can be introduced by the way training data is selected and by the way a model is deployed.[212][210] If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine, finance, recruitment, housing or policing) then the algorithm may cause discrimination.[213] The field of fairness studies how to prevent harms from algorithmic biases.
COMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist. In 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different—the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend.[217] In 2017, several researchers[l] showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.[219]
A program can make biased decisions even if the data does not explicitly mention a problematic feature (such as "race" or "gender"). The feature will correlate with other features (like "address", "shopping history" or "first name"), and the program will make the same decisions based on these features as it would on "race" or "gender".[220] Moritz Hardt said "the most robust fact in this research area is that fairness through blindness doesn't work."[221]
Criticism of COMPAS highlighted that machine learning models are designed to make "predictions" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. If an application then uses these predictions as recommendations, some of these "recommendations" will likely be racist.[222] Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is descriptive rather than prescriptive.[m]
Bias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.[215]
There are various conflicting definitions and mathematical models of fairness. These notions depend on ethical assumptions, and are influenced by beliefs about society. One broad category is distributive fairness, which focuses on the outcomes, often identifying groups and seeking to compensate for statistical disparities. Representational fairness tries to ensure that AI systems do not reinforce negative stereotypes or render certain groups invisible. Procedural fairness focuses on the decision process rather than the outcome. The most relevant notions of fairness may depend on the context, notably the type of AI application and the stakeholders. The subjectivity in the notions of bias and fairness makes it difficult for companies to operationalize them. Having access to sensitive attributes such as race or gender is also considered by many AI ethicists to be necessary in order to compensate for biases, but it may conflict with anti-discrimination laws.[209]
At its 2022 Conference on Fairness, Accountability, and Transparency (ACM FAccT 2022), the Association for Computing Machinery, in Seoul, South Korea, presented and published findings that recommend that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe, and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed.[dubious – discuss][224]
Many AI systems are so complex that their designers cannot explain how they reach their decisions.[225] Particularly with deep neural networks, in which there are a large amount of non-linear relationships between inputs and outputs. But some popular explainability techniques exist.[226]
It is impossible to be certain that a program is operating correctly if no one knows how exactly it works. There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with a ruler as "cancerous", because pictures of malignancies typically include a ruler to show the scale.[227] Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at "low risk" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading.[228]
People who have been harmed by an algorithm's decision have a right to an explanation.[229] Doctors, for example, are expected to clearly and completely explain to their colleagues the reasoning behind any decision they make. Early drafts of the European Union's General Data Protection Regulation in 2016 included an explicit statement that this right exists.[n] Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.[230]
DARPA established the XAI ("Explainable Artificial Intelligence") program in 2014 to try to solve these problems.[231]
Several approaches aim to address the transparency problem. SHAP enables to visualise the contribution of each feature to the output.[232] LIME can locally approximate a model's outputs with a simpler, interpretable model.[233] Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned.[234] Deconvolution, DeepDream and other generative methods can allow developers to see what different layers of a deep network for computer vision have learned, and produce output that can suggest what the network is learning.[235] For generative pre-trained transformers, Anthropic developed a technique based on dictionary learning that associates patterns of neuron activations with human-understandable concepts.[236]
Artificial intelligence provides a number of tools that are useful to bad actors, such as authoritarian governments, terrorists, criminals or rogue states.
A lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision.[o] Widely available AI tools can be used by bad actors to develop inexpensive autonomous weapons and, if produced at scale, they are potentially weapons of mass destruction.[238] Even when used in conventional warfare, it is unlikely that they will be unable to reliably choose targets and could potentially kill an innocent person.[238] In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations' Convention on Certain Conventional Weapons, however the United States and others disagreed.[239] By 2015, over fifty countries were reported to be researching battlefield robots.[240]
AI tools make it easier for authoritarian governments to efficiently control their citizens in several ways. Face and voice recognition allow widespread surveillance. Machine learning, operating this data, can classify potential enemies of the state and prevent them from hiding. Recommendation systems can precisely target propaganda and misinformation for maximum effect. Deepfakes and generative AI aid in producing misinformation. Advanced AI can make authoritarian centralized decision making more competitive than liberal and decentralized systems such as markets. It lowers the cost and difficulty of digital warfare and advanced spyware.[241] All these technologies have been available since 2020 or earlier—AI facial recognition systems are already being used for mass surveillance in China.[242][243]
There many other ways that AI is expected to help bad actors, some of which can not be foreseen. For example, machine-learning AI is able to design tens of thousands of toxic molecules in a matter of hours.[244]
Economists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.[245]
In the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that "we're in uncharted territory" with AI.[246] A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed.[247] Risk estimates vary; for example, in the 2010s, Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at "high risk" of potential automation, while an OECD report classified only 9% of U.S. jobs as "high risk".[p][249] The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies.[245] In April 2023, it was reported that 70% of the jobs for Chinese video game illustrators had been eliminated by generative artificial intelligence.[250][251]
Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that "the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution" is "worth taking seriously".[252] Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.[253]
From the early days of the development of artificial intelligence, there have been arguments, for example, those put forward by Joseph Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.[254]
It has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicist Stephen Hawking stated, "spell the end of the human race".[255] This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like "self-awareness" (or "sentience" or "consciousness") and becomes a malevolent character.[q] These sci-fi scenarios are misleading in several ways.
First, AI does not require human-like "sentience" to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of a paperclip factory manager).[257] Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that "you can't fetch the coffee if you're dead."[258] In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity's morality and values so that it is "fundamentally on our side".[259]
Second, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies, law, government, money and the economy are made of language; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.[260]
The opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI.[261] Personalities such as Stephen Hawking, Bill Gates, and Elon Musk,[262] as well as AI pioneers such as Yoshua Bengio, Stuart Russell, Demis Hassabis, and Sam Altman, have expressed concerns about existential risk from AI.
In May 2023, Geoffrey Hinton announced his resignation from Google in order to be able to "freely speak out about the risks of AI" without "considering how this impacts Google."[263] He notably mentioned risks of an AI takeover,[264] and stressed that in order to avoid the worst outcomes, establishing safety guidelines will require cooperation among those competing in use of AI.[265]
In 2023, many leading AI experts issued the joint statement that "Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war".[266]
Other researchers, however, spoke in favor of a less dystopian view. AI pioneer Juergen Schmidhuber did not sign the joint statement, emphasising that in 95% of all cases, AI research is about making "human lives longer and healthier and easier."[267] While the tools that are now being used to improve lives can also be used by bad actors, "they can also be used against the bad actors."[268][269] Andrew Ng also argued that "it's a mistake to fall for the doomsday hype on AI—and that regulators who do will only benefit vested interests."[270] Yann LeCun "scoffs at his peers' dystopian scenarios of supercharged misinformation and even, eventually, human extinction."[271] In the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.[272] However, after 2016, the study of current and future risks and possible solutions became a serious area of research.[273]
Friendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.[274]
Active organizations in the AI open-source community include Hugging Face,[279] Google,[280] EleutherAI and Meta.[281] Various AI models, such as Llama 2, Mistral or Stable Diffusion, have been made open-weight,[282][283] meaning that their architecture and trained parameters (the "weights") are publicly available. Open-weight models can be freely fine-tuned, which allows companies to specialize them with their own data and for their own use-case.[284] Open-weight models are useful for research and innovation but can also be misused. Since they can be fine-tuned, any built-in security measure, such as objecting to harmful requests, can be trained away until it becomes ineffective. Some researchers warn that future AI models may develop dangerous capabilities (such as the potential to drastically facilitate bioterrorism) and that once released on the Internet, they cannot be deleted everywhere if needed. They recommend pre-release audits and cost-benefit analyses.[285]
Artificial Intelligence projects can have their ethical permissibility tested while designing, developing, and implementing an AI system. An AI framework such as the Care and Act Framework containing the SUM values—developed by the Alan Turing Institute tests projects in four main areas:[286][287]
Other developments in ethical frameworks include those decided upon during the Asilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative, among others;[288] however, these principles do not go without their criticisms, especially regards to the people chosen contributes to these frameworks.[289]
Promotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers.[290]
The UK AI Safety Institute released in 2024 a testing toolset called 'Inspect' for AI safety evaluations available under a MIT open-source licence which is freely available on GitHub and can be improved with third-party packages. It can be used to evaluate AI models in a range of areas including core knowledge, ability to reason, and autonomous capabilities.[291]
The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating AI; it is therefore related to the broader regulation of algorithms.[292] The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally.[293] According to AI Index at Stanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.[294][295] Between 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.[296] Most EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, U.S., and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.[296] The Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology.[296] Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI.[297] In 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years.[298] In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, governments officials and academics.[299] In 2024, the Council of Europe created the first international legally binding treaty on AI, called the "Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law". It was adopted by the European Union, the United States, the United Kingdom, and other signatories.[300]
In a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that "products and services using AI have more benefits than drawbacks".[294] A 2023 Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity.[301] In a 2023 Fox News poll, 35% of Americans thought it "very important", and an additional 41% thought it "somewhat important", for the federal government to regulate AI, versus 13% responding "not very important" and 8% responding "not at all important".[302][303]
In November 2023, the first global AI Safety Summit was held in Bletchley Park in the UK to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks.[304] 28 countries including the United States, China, and the European Union issued a declaration at the start of the summit, calling for international co-operation to manage the challenges and risks of artificial intelligence.[305][306] In May 2024 at the AI Seoul Summit, 16 global AI tech companies agreed to safety commitments on the development of AI.[307][308]
The study of mechanical or "formal" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as "0" and "1", could simulate any conceivable form of mathematical reasoning.[309][310] This, along with concurrent discoveries in cybernetics, information theory and neurobiology, led researchers to consider the possibility of building an "electronic brain".[r] They developed several areas of research that would become part of AI,[312] such as McCullouch and Pitts design for "artificial neurons" in 1943,[115] and Turing's influential 1950 paper 'Computing Machinery and Intelligence', which introduced the Turing test and showed that "machine intelligence" was plausible.[313][310]
The field of AI research was founded at a workshop at Dartmouth College in 1956.[s][6] The attendees became the leaders of AI research in the 1960s.[t] They and their students produced programs that the press described as "astonishing":[u] computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English.[v][7] Artificial intelligence laboratories were set up at a number of British and U.S. universities in the latter 1950s and early 1960s.[310]
Researchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine with general intelligence and considered this the goal of their field.[317] In 1965 Herbert Simon predicted, "machines will be capable, within twenty years, of doing any work a man can do".[318] In 1967 Marvin Minsky agreed, writing that "within a generation ... the problem of creating 'artificial intelligence' will substantially be solved".[319] They had, however, underestimated the difficulty of the problem.[w] In 1974, both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill[321] and ongoing pressure from the U.S. Congress to fund more productive projects.[322] Minsky's and Papert's book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether.[323] The "AI winter", a period when obtaining funding for AI projects was difficult, followed.[9]
In the early 1980s, AI research was revived by the commercial success of expert systems,[324] a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research.[8] However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.[10]
Up to this point, most of AI's funding had gone to projects that used high-level symbols to represent mental objects like plans, goals, beliefs, and known facts. In the 1980s, some researchers began to doubt that this approach would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition,[325] and began to look into "sub-symbolic" approaches.[326] Rodney Brooks rejected "representation" in general and focussed directly on engineering machines that move and survive.[x] Judea Pearl, Lofti Zadeh and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic.[86][331] But the most important development was the revival of "connectionism", including neural network research, by Geoffrey Hinton and others.[332] In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.[333]
AI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This "narrow" and "formal" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics).[334] By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as "artificial intelligence" (a tendency known as the AI effect).[335]
However, several academic researchers became concerned that AI was no longer pursuing its original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or "AGI"), which had several well-funded institutions by the 2010s.[4]
Deep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.[11]
Deep learning's success was based on both hardware improvements (faster computers,[337] graphics processing units, cloud computing[338]) and access to large amounts of data[339] (including curated datasets,[338] such as ImageNet). Deep learning's success led to an enormous increase in interest and funding in AI.[z] The amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019.[296]
In 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.[273]
In the late teens and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015, AlphaGo, developed by DeepMind, beat the world champion Go player. The program was taught only the rules of the game and developed strategy by itself. GPT-3 is a large language model that was released in 2020 by OpenAI and is capable of generating high-quality human-like text.[340] These programs, and others, inspired an aggressive AI boom, where large companies began investing billions in AI research. According to AI Impacts, about $50 billion annually was invested in "AI" around 2022 in the U.S. alone and about 20% of the new U.S. Computer Science PhD graduates have specialized in "AI".[341] About 800,000 "AI"-related U.S. job openings existed in 2022.[342]
Philosophical debates have historically sought to determine the nature of intelligence and how to make intelligent machines.[343] Another major focus has been whether machines can be conscious, and the associated ethical implications.[344] Many other topics in philosophy are relevant to AI, such as epistemology and free will.[345] Rapid advancements have intensified public discussions on the philosophy and ethics of AI.[344]
Russell and Norvig agree with Turing that intelligence must be defined in terms of external behavior, not internal structure.[1] However, they are critical that the test requires the machine to imitate humans. "Aeronautical engineering texts," they wrote, "do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons.'"[349] AI founder John McCarthy agreed, writing that "Artificial intelligence is not, by definition, simulation of human intelligence".[350]
McCarthy defines intelligence as "the computational part of the ability to achieve goals in the world".[351] Another AI founder, Marvin Minsky similarly describes it as "the ability to solve hard problems".[352] The leading AI textbook defines it as the study of agents that perceive their environment and take actions that maximize their chances of achieving defined goals.[1] These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the "intelligence" of the machine—and no other philosophical discussion is required, or may not even be possible.
Another definition has been adopted by Google,[353] a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.
Some authors have suggested in practice, that the definition of AI is vague and difficult to define, with contention as to whether classical algorithms should be categorised as AI,[354] with many companies during the early 2020s AI boom using the term as a marketing buzzword, often even if they did "not actually use AI in a material way".[355]
No established unifying theory or paradigm has guided AI research for most of its history.[aa] The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term "artificial intelligence" to mean "machine learning with neural networks"). This approach is mostly sub-symbolic, soft and narrow. Critics argue that these questions may have to be revisited by future generations of AI researchers.
Symbolic AI (or "GOFAI")[357] simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at "intelligent" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: "A physical symbol system has the necessary and sufficient means of general intelligent action."[358]
However, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec's paradox is the discovery that high-level "intelligent" tasks were easy for AI, but low level "instinctive" tasks were extremely difficult.[359] Philosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a "feel" for the situation, rather than explicit symbolic knowledge.[360] Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him.[ab][16]
The issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence,[362][363] in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches.
"Neats" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). "Scruffies" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s,[364] but eventually was seen as irrelevant. Modern AI has elements of both.
Finding a provably correct or optimal solution is intractable for many important problems.[15] Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks.
AI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals.[365][366] General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The sub-field of artificial general intelligence studies this area exclusively.
The philosophy of mind does not know whether a machine can have a mind, consciousness and mental states, in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that "[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on."[367] However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.
Computationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind–body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.[370]
Philosopher John Searle characterized this position as "strong AI": "The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds."[ac] Searle counters this assertion with his Chinese room argument, which attempts to show that, even if a machine perfectly simulates human behavior, there is still no reason to suppose it also has a mind.[374]
It is difficult or impossible to reliably evaluate whether an advanced AI is sentient (has the ability to feel), and if so, to what degree.[375] But if there is a significant chance that a given machine can feel and suffer, then it may be entitled to certain rights or welfare protection measures, similarly to animals.[376][377] Sapience (a set of capacities related to high intelligence, such as discernment or self-awareness) may provide another moral basis for AI rights.[376] Robot rights are also sometimes proposed as a practical way to integrate autonomous agents into society.[378]
In 2017, the European Union considered granting "electronic personhood" to some of the most capable AI systems. Similarly to the legal status of companies, it would have conferred rights but also responsibilities.[379] Critics argued in 2018 that granting rights to AI systems would downplay the importance of human rights, and that legislation should focus on user needs rather than speculative futuristic scenarios. They also noted that robots lacked the autonomy to take part to society on their own.[380][381]
Progress in AI increased interest in the topic. Proponents of AI welfare and rights often argue that AI sentience, if it emerges, would be particularly easy to deny. They warn that this may be a moral blind spot analogous to slavery or factory farming, which could lead to large-scale suffering if sentient AI is created and carelessly exploited.[377][376]
However, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.[383]
Edward Fredkin argues that "artificial intelligence is the next step in evolution", an idea first proposed by Samuel Butler's "Darwin among the Machines" as far back as 1863, and expanded upon by George Dyson in his 1998 book Darwin Among the Machines: The Evolution of Global Intelligence.[385]
Isaac Asimov introduced the Three Laws of Robotics in many stories, most notably with the "Multivac" super-intelligent computer. Asimov's laws are often brought up during lay discussions of machine ethics;[389] while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.[390]
Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.[391]
These were the four of the most widely used AI textbooks in 2008:
Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of humans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and problem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines. It is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe AI could solve major challenges and crisis situations.
First of all, the categorization of Artificial Intelligence is into four types. Arend Hintze came up with this categorization. The categories are as follows:
Type 2: Limited memory – These AI systems are capable of using past experiences to inform future ones. A good example can be self-driving cars. Such cars have decision making systems. The car makes actions like changing lanes. Most noteworthy, these actions come from observations. There is no permanent storage of these observations.
Type 3: Theory of mind – This refers to understand others. Above all, this means to understand that others have their beliefs, intentions, desires, and opinions. However, this type of AI does not exist yet.
Type 4: Self-awareness – This is the highest and most sophisticated level of Artificial Intelligence. Such systems have a sense of self. Furthermore, they have awareness, consciousness, and emotions. Obviously, such type of technology does not yet exist. This technology would certainly be a revolution.
First of all, AI has significant use in healthcare. Companies are trying to develop technologies for quick diagnosis. Artificial Intelligence would efficiently operate on patients without human supervision. Such technological surgeries are already taking place. Another excellent healthcare technology is IBM Watson.
Artificial Intelligence in business would significantly save time and effort. There is an application of robotic automation to human business tasks. Furthermore, Machine learning algorithms help in better serving customers. Chatbots provide immediate response and service to customers.
AI can certainly make education more efficient. AI technology can discover the needs of students. Then it can adapt according to their needs. AI tutors provide study help to students. Also, AI can automate grading which results in saving a lot of time.
AI can greatly increase the rate of work in manufacturing. Manufacture of a huge number of products can take place with AI. Furthermore, the entire production process can take place without human intervention. Hence, a lot of time and effort is saved.
Artificial Intelligence has applications in various other fields. These fields can be military, law, video games, government, finance, automotive, audit, art, etc. Hence, it’s clear that AI has a massive amount of different applications.
To sum it up, Artificial Intelligence looks all set to be the future of the World. Experts believe AI would certainly become a part and parcel of human life soon. AI would completely change the way we view our World. With Artificial Intelligence, the future seems intriguing and exciting.
“name”: “Give an example of AI reactive machines?”,
The incorporation of robotics in healthcare environments is becoming increasingly common. Currently, task automation is adapted to any sector and robotics in medicine is frequently used thanks, in part, to the evolution of technologies such as 5G, AI or augmented reality.
We are also talking about advantages such as administrative support, early detection of certain diseases, predictive systems or patient monitoring.
PHARAON aims to contribute to improving the aging conditions of the European population by creating a set of open and customizable platforms with advanced services, devices and tools including IoT, artificial intelligence, robotics, cloud computing, smart devices, Big Data and intelligent analytics.
Robotnik will provide its mobile platforms so that they can be used in the pilots, in addition to assisting with the integration of the technology developed within the project. These robots will be tested in various hospitals in Europe.
ODIN: Transforming the future of healthcare in Europe’s hospitals through AI.
This project addresses 11 hospital care challenges by seeking solutions that combine robotics, IoT and AI.
The extent of interaction between workers and robots is expected to increase in modern workplaces due to rapid advancements in robotic technologies. Advanced robotics often leverages progress in artificial intelligence, machine learning and sensor technologies to achieve higher levels of sophistication and versatility. The enhanced capabilities of new-generation robots facilitate increased collaboration between humans and robots, partly by ensuring safety when humans and robots are working in proximity. This marks a move away from traditional robots, often confined to cages on the shop floor to isolate them from human operators. In spite of the many benefits, there are lingering concerns around the requirement for workers to continually adapt to new or changing tasks and roles, the possibility of monitoring workers’ activities at an unprecedented level of granularity, diminished autonomy and control over the pace of work, and the emergence of new health and safety risks, including of a psychosocial nature. Drawing on survey data and case studies investigating advanced robotic systems and applications, this report explores the opportunities and challenges that come with closer human–robot interaction, with a view to contributing to the broader policy debate on the automation of work.
Advanced robotic systems and applications disrupt workplaces; they transform the way work is carried out, often resulting in changes to business models and redefining roles, tasks and methods of work. Artificial intelligence (AI) has played a pivotal role in enhancing these systems, giving them greater capabilities, functionalities and flexibility than more conventional robots. AI has also facilitated seamless collaboration and interaction between humans and robots in various industries. This is most prominently illustrated by collaborative robotic applications, through which AI enables closer worker–robot interaction in shared workspaces. 
Drawing on survey data and case studies investigating advanced robotic systems and applications for task automation, this report contributes to the policy debate on work automation, highlighting new forms of interaction between workers and robots and the changes to work organisation and working conditions that they entail. 
Unlike conventional robots, usually confined to cages and positioned at a safe distance from humans, advanced robots equipped with sensors and enhanced functionalities ensure greater safety when in proximity to humans. They enable closer human–robot interaction and collaboration characterised by shared goals and more synchronised tasks. Despite these benefits, the forms of interaction arising from the use of increasingly advanced robotic systems, especially those with embedded AI capabilities, may pose new policy and regulatory challenges. The notion of human centricity is more relevant than ever in ensuring safe and effective human–robot interaction. 
As part of the EU’s digital strategy, several policy initiatives on AI have emphasised a human-centric approach to technology development and use. In the context of advanced robotics, this involves ensuring that systems are designed and deployed in a manner that respects human values and fundamental rights. Furthermore, the European Commission has taken steps to address liability and accountability issues arising from AI use, proposing a revised product liability directive and an AI civil liability directive. 
When freely submitting your request, you are consenting Eurofound in handling your personal data to reply to you. Your request will be handled in accordance with the provisions of Regulation (EU) 2018/1725 of the European Parliament and of the Council of 23 October 2018 on the protection of natural persons with regard to the processing of personal data by the Union institutions, bodies, offices and agencies and on the free movement of such data. More information, please read the Data Protection Notice.
AI bias, also called machine learning bias or algorithm bias, refers to the occurrence of biased results due to human biases that skew the original training data or AI algorithm—leading to distorted outputs and potentially harmful outcomes.
When AI bias goes unaddressed, it can impact an organization’s success and hinder people’s ability to participate in the economy and society. Bias reduces AI’s accuracy, and therefore its potential.
Businesses are less likely to benefit from systems that produce distorted results. And scandals resulting from AI bias could foster mistrust among people of color, women, people with disabilities, the LGBTQ community, or other marginalized groups.
The models upon which AI efforts are based absorb the biases of society that can be quietly embedded in the mountains of data they're trained on. Historically biased data collection that reflects societal inequity can result in harm to historically marginalized groups in use cases including hiring, policing, credit scoring and many others.  According to The Wall Street Journal, “As use of artificial intelligence becomes more widespread, businesses are still struggling to address pervasive bias.”1
Learn key benefits of generative AI and how organizations can incorporate generative AI and machine learning into their business.   
Register for the ebook on AI data stores
When AI makes a mistake due to bias—such as groups of people denied opportunities, misidentified in photos or punished unfairly—the offending organization suffers damage to its brand and reputation. At the same time, the people in those groups and society as a whole can experience harm without even realizing it. Here are a few high-profile examples of disparities and bias in AI and the harm they can cause.
In healthcare, underrepresenting data of women or minority groups can skew predictive AI algorithms.2 For example, computer-aided diagnosis (CAD) systems have been found to return lower accuracy results for African-American patients than white patients.
While AI tools can streamline the automation of resume scanning during a search to help identify ideal candidates, the information requested and answers screened out can result in disproportionate outcomes across groups. For example, if a job ad uses the word “ninja,” it might attract more men than women, even though that is in no way a job requirement.3   
As a test of image generation, Bloomberg requested more than 5,000 AI images be created and found that, “The world according to Stable Diffusion is run by white male CEOs. Women are rarely doctors, lawyers or judges. Men with dark skin commit crimes, while women with dark skin flip burgers.”4  Midjourney conducted a similar study of AI art generation, requesting images of people in specialized professions. The result showed both younger and older people, but the older people were always men, reinforcing gender bias of the role of women in the workplace.5 
AI-powered predictive policing tools used by some organizations in the criminal justice system are supposed to identify areas where crime is likely to occur. However, they often rely on historical arrest data, which can reinforce existing patterns of racial profiling and disproportionate targeting of minority communities.6
Distorted results can harm organizations and society at large. Here are a few of the more common types of AI bias7. 
Algorithm bias: Misinformation can result if the problem or question asked is not fully correct or specific, or if the feedback to the machine learning algorithm does not help guide the search for a solution. 
Cognitive bias: AI technology requires human input, and humans are fallible. Personal bias can seep in without practitioners even realizing it. This can impact either the dataset or model behavior. 
Confirmation bias: Closely related to cognitive bias, this happens when AI relies too much on pre-existing beliefs or trends in the data—doubling-down on existing biases, and unable to identify new patterns or trends. 
Exclusion bias: This type of bias occurs when important data is left out of the data being used, often because the developer has failed to see new and important factors. 
Measurement bias: Measurement bias is caused by incomplete data. This is most often an oversight or lack of preparation that results in the dataset not including the whole population that should be considered. For example, if a college wanted to predict the factors to successful graduation, but included only graduates, the answers would completely miss the factors that cause some to drop out. 
Out-group homogeneity bias: This is a case of not knowing what one doesn’t know. There is a tendency for people to have a better understanding of ingroup members—the group one belongs to—and to think they are more diverse than outgroup members. The result can be developers creating algorithms that are less capable of distinguishing between individuals who are not part of the majority group in the training data, leading to racial bias, misclassification and incorrect answers. 
Prejudice bias: Occurs when stereotypes and faulty societal assumptions find their way into the algorithm’s dataset, which inevitably leads to biased results. For example, AI could return results showing that only males are doctors and all nurses are female. 
Recall bias: This develops during data labeling, where labels are inconsistently applied by subjective observations.  
Sample/Selection bias: This is a problem when the data used to train the machine learning model isn't large enough, not representative enough or is too incomplete to sufficiently train the system. If all school teachers consulted to train an AI model have the same academic qualifications, then any future teachers considered would need to have identical academic qualifications. 
Stereotyping bias: This happens when an AI system—usually inadvertently—reinforces harmful stereotypes. For example, a language translation system could associate some languages with certain genders or ethnic stereotypes. McKinsey gives a word of warning about trying to remove prejudice from datasets: “A naive approach is removing protected classes (such as sex or race) from data and deleting the labels that make the algorithm biased. Yet, this approach may not work because removed labels may affect the understanding of the model and your results’ accuracy may get worse.”8
The first step in avoiding the bias trap is just to step back at the beginning and give an AI effort some thought. As is true with almost any business challenge, problems are much easier to fix up-front rather than waiting for the train wreck and then sorting through the damaged result. But many organizations are in a rush: penny-wise-and-pound-foolish, and it costs them. 
Identifying and addressing bias in AI requires AI governance, or the ability to direct, manage and monitor the AI activities of an organization. In practice, AI governance creates a set of policies, practices and frameworks to guide the responsible development and use of AI technologies. When done well, AI governance helps to ensure that there is a balance of benefits bestowed upon businesses, customers, employees and society as a whole.
AI governance often includes methods that aim to assess fairness, equity and inclusion. Approaches such as counterfactual fairness identifies bias in a model’s decision making and ensures equitable results, even when sensitive attributes, such as gender, race or sexual orientation are included.
 Because of the complexity of AI, an algorithm can be a black box system with little insight into the data used to create it. Transparency practices and technologies help ensure that unbiased data is used to build the system and that results will be fair. Companies that work to protect customers’ information build brand trust and are more likely to create trustworthy AI systems.
Here’s a checklist of six process steps that can keep AI programs free of bias.
2.  Train with the right data: Machine learning trained on the wrong data will produce wrong results. Whatever data is fed into the AI should be complete and balanced to replicate the actual demographics of the group being considered.     
3.  Choose a balanced team: The more varied the AI team—racially, economically, by educational level, by gender and by job description—the more likely it will recognize bias. The talents and viewpoints on a well-rounded AI team should include AI business innovators, AI creators, AI implementers, and a representation of the consumers of this particular AI effort.9  
4.  Perform data processing mindfully: Businesses need to be aware of bias at each step when processing data. The risk is not just in data selection: whether during pre-processing, in-processing or post-processing, bias can creep in at any point and be fed into the AI.  
5.  Continually monitor: No model is ever complete or permanent. Ongoing monitoring and testing with real-world data from across an organization can help detect and correct bias before it causes harm. To further avoid bias, organizations should consider assessments by an independent team from within the organization or a trusted third-party.  
6.  Avoid infrastructural issues: Aside from human and data influences, sometimes infrastructure itself can cause bias. For example, using data collected from mechanical sensors, the equipment itself could inject bias if the sensors are malfunctioning. This kind of bias can be difficult to detect and requires investment in the latest digital and technological infrastructures.
Operationalize AI across your business to deliver benefits quickly and ethically. Our rich portfolio of business-grade AI products and analytics solutions are designed to reduce the hurdles of AI adoption and establish the right data foundation while optimizing for outcomes and responsible use.
Drive faster insights by delivering a comprehensive view of an entity’s data and relationships across the enterprise data fabric
In this episode of AI Academy, explore issues including AI hallucination, bias and risk, and learn how applying AI ethics and governance builds trust. 
Learn more about AI governance for responsible, transparent, and explainable workflows in this eBook. 
As companies increase their use of AI, people are questioning the extent to which human biases have made their way into AI systems. 
Accelerate responsible, transparent and explainable AI workflows across the lifecycle for both generative and machine learning models. Direct, manage, and monitor your organization’s AI activities to better manage growing AI regulations and detect and mitigate risk.
1 The Wall Street Journal: Rise of AI Puts Spotlight on Bias in Algorithms
2  Booz Allen Hamilton: Artificial Intelligence Bias in Healthcare
3  LinkedIn:  Reducing AI Bias — A Guide for HR Leaders
4  Bloomberg: Humans Are Biased. Generative AI Is Even Worse
5  The Conversation US: Ageism, sexism, classism and more — 7 examples of bias in AI-generated images
6  Technology Review:  Predictive policing is still racist—whatever data it uses
7  Tech Target: Machine learning bias (AI bias)
     Chapman University AI Hub: Bias in AI    
     AIMultiple: Bias in AI —What it is, Types, Examples & 6 Ways to Fix it in 2023
8  McKinsey: Tackling bias in artificial intelligence (and in humans)
9  Forbes:  The Problem With Biased AIs (and How To Make AI Better)
Artificial intelligence seems like it could change the world, right? It’s capable of writing the perfect party invitation, telling jokes, or anticipating what we want to see/say next. And while it can do all these things, it’s important to remember that artificial intelligence has certain limitations and should be used with caution, at least for now. 
What do we mean? Well, let’s go back to how artificial intelligence technologies are created. Data scientists feed computers and other machines with the information they want them to mimic, meaning this is the main source of information that machines have. Therefore, if there is any inconsistency or bias within the data, the computer will repeat that. 
If artificial intelligence is used for fun, such as writing a poem for a friend, there’s no issue. But when AI is used for decision making or is expected to draw conclusions on its own, bias, whether intentional or not, can severely impact the accuracy of the result. 
To understand exactly how ethics and bias play such a crucial role in artificial intelligence, let’s first cover the basics of AI and then give some examples of how bias and ethics can compromise the integrity of artificial intelligence. 
The ability of machines to replicate and mimic human responses and reactions to situations is what we know as artificial intelligence. By training machines to think like humans, we can automate otherwise tedious or repetitive tasks and use machine learning to process large amounts of data. 
Artificial intelligence has evolved considerably over time, but still has a long way to go to properly imitate human thinking. Even so, however, already existing advances have transformed the way in which we view machines and their potential. In our day-to-day lives, artificial intelligence manifests itself: 
In maps and transportation: ever wondered how your maps app can provide the latest information on traffic jams, closed roads, or the best route to take via public transportation, walking, or bike? Well, thanks to artificial intelligence, your maps app can update in real-time and provide you with the best possible experience. 
In facial recognition/identification: through collecting data about your facial structure and features, your phone is able to both recognize that there is a face in front of the screen and verify your identity.
In writing assistance: spell check isn’t the only assistance you get from writing–thanks to the incredibly high amount of data that machines have been fed, they’re able to suggest what you can write next. 
Artificial intelligence is quite useful in a wide range of applications–that much is clear. But as with anything, there are concerns and limitations of which to be aware. Now that we’re clear about what artificial intelligence is, let’s dive right into ethics and bias in artificial intelligence. 
A machine can’t have bias, right? After all, it doesn’t have experiences or memories from which to form said bias. Unfortunately, that’s not quite the case: machines can only learn from the data they have and if this data is biased, incomplete, or of poor quality, the output of the machine will reflect the same problems. 
The following are the most common examples of artificial intelligence bias: 
Algorithm bias: if the algorithm itself that determines the calculations of the machine are incorrect or faulty, the results will be as well. 
Prejudice bias: similarly to sample bias, prejudice bias uses data that is influenced by societal biases and therefore incorporates this prejudice into what should be opinion-free data. 
Example: you’re evaluating the gender distribution in certain occupations, but only count female teachers and male doctors, creating an inaccurate skew in your data. 
Measurement bias: measurement bias occurs when data is incorrectly gathered, specifically on how it was measured or valued. 
Exclusion bias: you can’t pick and choose the data you use in your analysis and if you (intentionally or by mistake) exclude data points, your results will be inaccurate.  
Example: if you think the middle-of-the-road answers to a survey aren’t consequential and remove them, you’ll end up with data skewed to both ends of the spectrum and an inaccurate representation of how the respondents actually feel. 
Selection bias: while it can be quite challenging to get a big enough sample or one that’s representative of the entire population, choosing only certain groups can make your data completely useless.
There are quite a few more ways that bias can appear in artificial intelligence, but the aforementioned ones are the most common. Here’s what you need to remember: artificial intelligence learns from the data that it’s fed and if that data is problematic or inaccurate, the outputs of artificial intelligence will be as well. Here’s what you can do to prevent bias: 
Lots of situations involving bias stem from small or limited datasets; do everything you can to collect as much data as possible from as many sources as you can, diversifying your dataset. 
As you begin to feed your computer with data, run tests during the early stages of testing to check for biases and correct them. 
Run your results by other experts to get other opinions and continuously check the quality of your data as time passes.  
You’ve definitely heard someone tell you that AI will take your job one day. And while the vast majority of jobs are safe (and those that AI can take over will morph into a different role), there are serious ethical considerations to keep in mind when discussing artificial intelligence.
One thing is clear: the power of artificial intelligence is massive and we’ve only just begun to uncover what it can do. But the following considerations are absolutely crucial when it comes to maintaining proper ethics in the future of artificial intelligence: 
Privacy: we’re feeding machines tons of data about people to help it react in a more human-like way, right? How do we ensure that the data we’re giving to the machine is both secure and private? Prioritizing data privacy throughout the entire artificial intelligence lifecycle is one of the world’s main concerns. 
Human dependence: yes, artificial intelligence is capable of automating some tasks that humans were previously handling and it can also handle much more data than people can. But it’s absolutely essential that AI isn’t left to make decisions on its own, as it will never replace human responsibility and accountability. 
Sustainability: advances in artificial intelligence and technology are supported, but as long as they don’t come at the expense of the environment and overall sustainability. 
Accessibility: new developments should be accessible worldwide, not just in highly developed countries with easy access to technology. 
To ensure that ethics in artificial intelligence is prioritized, many countries and global organizations have come together to come up with policies and regulations, such as the GDPR in the European Union. But achieving truly ethical technological advances in artificial intelligence will come from a commitment from every individual, company, and country across the world. 
The power of artificial intelligence is truly unmatched–but it’s on us to properly use it for good. And skilled artificial intelligence professionals are sorely needed across the tech industry, so if you’re interested in entering this up-and-coming field, look no further: there’s lots of room for advancement in artificial intelligence. 
The future of work is rapidly evolving with the integration of AI into the workplace. While this technological advancement brings numerous benefits, it also raises ethical concerns and job displacement issues. In this article, we will explore the impact of AI on jobs, discuss the ethical considerations surrounding its implementation, and provide insights on how individuals can navigate this changing landscape through reskilling and lifelong learning.
The integration of AI into the workplace has the potential to revolutionize industries by boosting efficiency and unleashing creativity. AI-powered automation streamlines repetitive tasks, allowing employees to focus on higher-value work that requires critical thinking and problem-solving skills. This shift in job roles enables individuals to tap into their full potential and contributes to overall workforce transformation.
However, as AI becomes more prevalent, concerns about job displacement arise. Traditional jobs in sectors such as manufacturing, data entry, healthcare, finance, transportation, and retail are at risk of being replaced by AI-powered systems. The increasing automation of tasks can lead to a significant reduction in certain job categories.
One of the key ethical concerns related to AI in the workplace is the use of algorithms for decision-making processes. For instance, using AI algorithms in hiring and loan approval processes can have far-reaching implications for individuals. Ensuring privacy rights are protected when collecting and analyzing employee data with AI technologies is also crucial.
Transparency and explainability are essential in AI systems to maintain trust and facilitate human oversight. It is important that individuals understand how decisions are made by AI algorithms and have the ability to question or challenge those decisions when necessary. Additionally, holding AI systems accountable for their actions and mitigating algorithmic biases are significant challenges that need to be addressed.
In conclusion, while the integration of AI into the workplace brings about efficiency gains and new opportunities, it also raises ethical concerns and job displacement issues. Reskilling and lifelong learning play a vital role in navigating this changing landscape. By acquiring new skills and adapting to the evolving job market, individuals can position themselves for success in an AI-driven future. In the following sections, we will delve deeper into these topics and explore case studies and strategies that can help individuals and organizations thrive in the face of these challenges.
In the age of AI, the job landscape is undergoing significant changes. With the integration of artificial intelligence into the workplace, there are both concerns and opportunities for workers. Let’s explore how AI is impacting jobs and transforming the workforce.
One of the key ways AI is transforming the workforce is by boosting efficiency and unleashing creativity. AI-powered automation is streamlining repetitive tasks, allowing employees to focus on higher-value work. Here are a few examples of how AI is making an impact:
By automating repetitive tasks and enhancing decision-making processes, AI allows employees to focus on tasks that require critical thinking, creativity, problem-solving, and emotional intelligence — skills that are uniquely human.
To illustrate this point further, a study conducted by researchers at Stanford University found that using deep learning algorithms reduced diagnostic errors in dermatology when compared to human dermatologists alone. The combination of AI and human expertise led to higher accuracy rates, emphasizing the potential of AI in augmenting human capabilities rather than replacing them.
Furthermore, a survey conducted by Deloitte found that 49% of executives believed that AI would lead to the creation of new roles within their organizations. These new roles would focus on managing and developing AI systems, as well as leveraging the insights generated by AI algorithms to drive innovation and business growth.
As the job landscape continues to evolve, it is crucial for individuals to adapt and acquire the skills necessary to thrive in an AI-driven workplace. This includes understanding and addressing privacy issues and challenges associated with AI implementation, as well as exploring opportunities such as using AI to translate signed languages which can enhance accessibility and inclusion for individuals with hearing impairments.
In the next section, we will explore the emergence of new job roles in the era of AI and the opportunities they present for growth and learning.
The impact of AI on jobs has been significant, changing how organizations operate and influencing our work methods. This transformation brings both new possibilities and challenges that demand a workforce capable of adjusting to emerging positions. Being able to quickly adapt to new roles based on the capabilities of AI has become a crucial skill for employees.
Here are some key job roles that have emerged as a result of AI integration:
1. Data Scientists
Data scientists play a crucial role in leveraging the power of AI. They are responsible for analyzing massive amounts of data and extracting valuable insights from it. By designing algorithms and predictive models, they help businesses make informed decisions and stay ahead of industry trends.
2. AI Ethicists
With the rise of AI technologies, there is a growing need to address the ethical implications associated with their use. This has led to the emergence of AI ethicists who specialize in examining these moral concerns. Their role involves guiding organizations in implementing AI in ways that are aligned with ethical standards and societal values.
Several industries are utilizing AI to streamline their processes and introduce innovative approaches to job tasks:
Medium’s impressive articles on Artificial Intelligence showcase how diverse industries are applying AI for growth and advancement. Similarly, digital marketing is being revolutionized by AI SEO tools, which optimize content creation and search engine rankings. These examples highlight the wide-ranging benefits of AI across various job functions.
As organizations continue to incorporate AI into their processes, employees will find themselves in unique roles that require a combination of technical expertise and adaptable soft skills. The future holds not only new job titles but also an expansion of existing positions to include AI-related competencies.
Artificial intelligence (AI) is revolutionizing our work landscape, but it also brings forth a range of critical ethical issues. As we delve into the realm of ethical AI, certain key concerns come to light:
One of the most pressing concerns revolves around the ethical implications of AI algorithms in decision making processes. For instance, in hiring new employees, companies may employ AI to screen resumes and predict candidate suitability. Similarly, financial institutions may rely on AI to evaluate creditworthiness when approving loans. However, there is a looming fear that these algorithms might make biased decisions based on flawed data or inherent biases within their systems.
The efficacy of AI technologies heavily relies on copious amounts of data, which inevitably raises privacy concerns. It is paramount to ensure that individuals’ privacy rights are safeguarded when their data is collected and analyzed by AI systems. This concern amplifies when dealing with employee data, often containing sensitive information that should only be accessed and used with stringent safeguards in place.
Trust in AI systems hinges upon comprehending their decision-making process. Consequently, clear explanations outlining the logic behind their choices become crucial. Not only does transparency and explainability foster confidence in these systems, but it also allows for human oversight. The ability to review and question the decision-making process becomes essential if concerns or disputes arise regarding the outcomes produced by AI.
Ensuring that AI systems can be held accountable for any harm they cause poses a complex challenge. Unlike humans who can be easily identified as responsible parties, determining liability when an automated decision leads to negative consequences is not always straightforward. Furthermore, there exists a risk of algorithmic biases perpetuating existing societal inequalities if left unaddressed. To mitigate this, diverse training datasets and inclusive design practices must be employed to minimize biases in AI systems.
Incorporating these principles into our workplace AI usage is not merely advisable; it is imperative for cultivating a future that is equitable and just.
Educational institutions have a crucial role in shaping the future workforce. They need to integrate AI literacy and skills development into their curricula. As the workplace changes, it’s important for individuals to continuously learn new skills and upgrade existing ones to stay relevant in the face of technological advancements. In this section, we will discuss why it’s essential for educational institutions to adapt their programs and support the growth of talent that can thrive in an AI-driven workplace.
By taking these steps, educational institutions can lead the way in preparing the workforce for an AI-first future. Their willingness to embrace change will greatly influence how individuals adapt to new job opportunities that arise as technology continues to evolve.
Biases in data and algorithmic design can perpetuate inequalities at work by reinforcing existing societal biases. When AI systems are trained on biased data, they can perpetuate and even exacerbate discrimination against certain groups.
Therefore, fostering diversity and inclusion within AI development teams is crucial to mitigating these biases and creating more equitable AI systems.
One strategy for promoting diversity and inclusion in the AI-powered workplace is to ensure that AI development teams are themselves diverse. By bringing together individuals from different backgrounds, experiences, and perspectives, organizations can challenge bias in algorithm design and decision-making processes.
Moreover, creating a culture of inclusivity within these teams can foster an environment where diverse viewpoints are valued, leading to more ethical and fair AI systems.
Another important strategy is to actively involve stakeholders from diverse backgrounds in the design, testing, and validation of AI systems. This approach ensures that a wide range of perspectives is considered throughout the development process, helping to identify and address potential biases before deployment.
Fostering diversity and inclusion in the AI-powered workplace is essential for creating ethical AI systems that serve all members of society equitably.
The future of work is clear: AI will be integrated into the workplace, bringing both opportunities and challenges. We cannot ignore the impact of AI on jobs. It’s important that we address concerns about job displacement and ethics so that humans and AI can work together effectively.
By taking these actions, we can ensure that AI is a positive force in the workplace:
It’s important to remember that while certain jobs may be replaced by AI, there will also be new roles created. The emergence of specialized positions like data scientists and AI ethicists shows the need for skills in these areas.
In conclusion, the impact of AI on the workforce is undeniable. However, it is within our power to ensure that AI is a force for good, benefiting both businesses and employees in a fair and sustainable manner. By addressing job displacement concerns, promoting ethical practices, fostering diversity and inclusion, and embracing lifelong learning, we can shape a future where humans and AI coexist harmoniously. Let us seize this opportunity to create a future of work that leverages the power of technology while prioritizing human well-being.
This resource serves as an introduction to a wider conversation regarding information privacy and AI. It is written for a non-technical audience and does not endeavour to solve questions posed, nor provide legal guidance. It should be noted that there are many other ethical, technical and legal issues associated with AI that are beyond the scope of this document.
Artificial Intelligence (AI) at its most simple, is a sub-field of computer science with the goal of creating programs that can perform tasks generally performed by humans. These tasks can be considered intelligent, and include visual and audio perception, learning and adapting, reasoning, pattern recognition and decision-making. ‘AI’ is used as an umbrella term to describe a collection of related techniques and technologies including machine learning, predictive analytics, natural language processing and robotics.
While the philosophy of Artificial Intelligence has been argued since at least Leibnitz in the early 18th Century, the concept of AI as we use it has existed since the early 1940s and made famous with the development of the “Turing test” in 1950. More recently, we are experiencing a period of rapid development in the field of AI as a result of three factors: improved algorithms, increased networked computing power, and increased ability to capture and store an unprecedented amount of data.1 As well as technological advancements, the very way of thinking about intelligent machines has shifted significantly since the 1960s, which has enabled many of the developments we are seeing today.
Real-life applications of AI technologies are already established in our everyday lives, although many people are not conscious of this. One of the characteristics of AI is that once the technology works, it stops being referred to as AI and transforms into mainstream computing.2 For example, being greeted by an automated voice on the other end of the phone, or being suggested a movie based on your preferences, are examples of mainstream AI technology. Now that these systems are an established element in our lives, the fact that AI techniques – including speech recognition, natural language processing and predictive analytics – are at work is often forgotten.
The ways that AI can enrich our lives are immense. Increased efficiency and lower costs, huge improvements in healthcare and research, increased safety of vehicles, and general convenience, are just some of the promises of AI. But, as with any new technology, the opportunities of AI come with an array of challenges for society and the law.3
There is a significant amount of terminology and technical jargon surrounding AI that is often used interchangeably and can cause confusion, especially for those without a technical background. Below is a simple explanation of key terms designed to assist the everyday reader understand some of the terminology surrounding AI, and the discussion within this document. This list is neither exhaustive, nor intended to be technologically in-depth.
Most AI that we experience today is ‘narrow’. This means that it has been deliberately programmed to be competent in one specific area. It is sometimes also referred to as augmented intelligence to highlight its ability to enhance (but not necessarily replace) human intelligence. For example, a computer developed by IBM in the 1980s called Deep Blue can play chess at a level superior to human beings; a feat of huge importance in the timeline of AI development. However, while Deep Blue exhibits an above-human ability in chess, its intelligence ends there.
Building upon the idea of AGI, artificial superintelligence is generally regarded as AI that is both general and exceeds human levels of intelligence. A notable writer on this subject, Nick Bostrom, defines superintelligence as “an intellect that is much smarter than the best human brains in practically every field, including scientific creativity, general wisdom and social skills.”4
Many pop culture depictions of AI, such as in films Ex Machina and Her, display AI in the form of superintelligence. This kind of portrayal can contribute to the hype and/or fear surrounding AI, and while it is a popular idea in science fiction, there is significant debate regarding the likelihood, imminence and consequences of ever developing such technology. The scope of this discussion is limited to narrow AI, which will simply be referred to as AI hereafter.
The relationship between AI and big data goes two ways. While big data analytics processes already exist, much of big data’s true value is only able to be realised using AI techniques. In the other direction, big data offers AI an immense and rich source of input data to develop and learn from. In this sense, AI and big data are strongly intertwined.
There is no one established definition of big data, however it is generally used to describe massive amounts of data produced and collected in a variety of forms.5 The types and scale of information included under the term ‘big data’ cannot be understated; almost everything individuals do generates data – searching online; sharing and transmitting day to day information with government, companies and social media; even just walking around with a smartphone – all (intentionally or unintentionally) create vast amounts of information about individuals. As the Internet of Things (IoT) pushes the network further into our physical environment and personal spaces, the scope of data created, collected and fed into AI systems stands to delve further into our personal lives.
The Information Commissioner’s Office of the United Kingdom sums up the connection between AI and big data quite eloquently:
Big data can be seen as an asset that is difficult to exploit. AI can be seen as a key to unlocking the value of big data; and machine learning is one of the technical mechanisms that underpins and facilitates AI.6
Machine learning is a computer science technique that allows computers to ‘learn’ on their own. It is often characterised as AI, but that is only one element of it. The characteristic that separates machine learning from other forms of AI is its dynamic ability to modify itself when exposed to more data. Through ingesting data, the machine is training itself by developing its own logic according to the data it has analysed.
There are two main types of machine learning: supervised and unsupervised. Supervised learning requires a human to provide both the data and the solution, letting the machine determine the connection between the two. Unsupervised learning allows the machine to learn more freely by ingesting a large amount of data (often big data) and iterating over it to find patterns and insights.
For example, you might be interested in predicting the price of a house. To do this you could tell the machine to look at a variety of features such as the number of rooms, if there is a garden etc. Using a supervised learning technique, you would also provide the historical prices of comparable houses, so the algorithm can build a model to understand the relationship between certain features and price, and therefore be able to reasonably predict a house price based on those features. In an unsupervised learning context, the machine would not be provided with the historical house prices, nor told which features are important to consider – rather, it would determine the patterns on its own.
These techniques are used in different contexts and for varying purposes. Neither requires explicit programming on what to look for, which gives a level of autonomy to the system to generate its own logic, identifying trends that may otherwise have been missed by humans.7  Machine learning algorithms are already widely used in modern life. Some examples include producing web search results, suggestive services such as Netflix and Pandora, and predicting the monetary value of a product given the existing market. The extent to which machine learning is useful is determined by the input data provided. Because of this, big data has played a pivotal role in the success of machine learning.
Deep learning is a subset of machine learning, most commonly used to refer to deep neural networks.8 In generalist terms, a neural network processes data through a layered approach, where each successive layer takes its input from the output of the layer before it. The term deep refers to the number of layers in the neural network.
As the output of each layer becomes the input of the next, it can become increasingly difficult to understand the decisions and inferences made at each level. The process of going through each layer can create what is referred to as the ‘black box’ effect, making it challenging to truly understand and describe the steps that lead to a particular outcome.9 The human brain is often used as an analogy to explain neural networks, however this is not particularly helpful as it implies machines understand information in a similar manner to human thinking, which is not the case.
Deep learning is an extremely powerful tool, and many credit it for the recent explosion of AI. It has given computers the ability to recognise spoken words almost as well as a human, transformed computer vision and dramatically improved machine translation – abilities that are far too complex to code into machines by hand. The nature of this process presents challenges for transparency of decisions, as the logic can become increasingly obscure to the human eye with each layer of processing. Further, neural networks are not immune to bias. For example, a recurrent neural network (RNN) will take data it has previously been exposed to into consideration. Some describe RNNs as having a memory, which similarly to human beings, affects its output. For example, in 2016 Microsoft trained an AI bot using a RNN on Twitter data, which demonstrated the potential for unintended consequences of this way of learning.10
While development of AI technology is being driven mainly by industry and academic research, AI applications and development are also relevant to the public sector. Government already uses AI in many areas, but it stands to benefit from further adoption of these technologies. Further, government has a significant role to play in shaping how AI technologies impact citizens’ lives through regulation, policy, and demonstrating best practices. It is important that government is not left behind as the private sector steams ahead – this means taking a proactive, dynamic and informed approach to the technology and its interaction with law and society.
The current and future use cases of AI in government remain bounded by resources, technical capability and public trust. Some of the most immediate beneficial opportunities for the public sector are those where AI can reduce administrative burdens and help resolve resource allocation problems. In the short-term, AI applications have the potential to be immensely useful in increasing efficiency of established government process such as answering questions, filling out and searching documents, routing requests, translation and drafting documents.11 As an example, the use of chat bots to provide customer service and advice to individuals already occurs in some of the larger Australian government organisations.
In the longer term, AI has the potential to go beyond merely enhancing established processes and alter government operations altogether. It is likely to require organisations to adapt to evolving citizen needs and expectations, and to alter the regulatory and legislative landscape to make way for new uses of technology.
While AI promises many opportunities for the public sector, it cannot be seen as a panacea to all existing challenges of government. The use and regulation of AI technologies need to be implemented strategically and thoughtfully, with particular care given to information management including privacy, protective data security, and ethics more broadly.12
This section explores some of the key questions prompted by AI in relation to information privacy. This is not an exhaustive exploration of all issues; rather, it is designed to provide an overview and act as a launch pad for further discussion regarding some of the more prominent information privacy considerations.
In Victoria and more broadly, information privacy law is generally based on the 1980 OECD Guidelines on the Protection of Privacy and Transborder Flows of Personal Data. These guidelines contain eight key principles that continue to be enshrined in privacy law around the world, including the Privacy and Data Protection Act 2014 (PDP Act). One of the benefits of having principle-based legislation is that it recognises the complicated and nuanced nature of privacy, and allows a degree of flexibility in how privacy can be protected in varying contexts and alongside evolving technologies and societal norms. While the OECD Guidelines have been remarkably successful in promoting information privacy legislation around the world, AI presents challenges to the underlying principles upon which the Guidelines are based.
While traditional notions of privacy may be challenged by AI, it is not a given that AI must undermine privacy by default; it is possible to envisage a future in which AI can help enable privacy. For instance, it is likely to mean that less people will actually need access to raw data in order to work with it, which could in turn minimise the risk of privacy breaches due to human error. It could also empower more meaningful consent, in which individuals receive personalised services dependent on privacy preferences that have been learnt over time. The increased use of AI may require the status quo of privacy protection to be revisited, however it does not mean privacy will cease to exist or become irrelevant.
One important factor of information privacy is that it provides an important framework for making ethical choices about how we use new technologies. Considering the ethics of technology and solving the privacy challenges will be essential to the long-term success of AI. A balance between technological innovation and privacy considerations will promote the development of socially responsible AI that can assist in the creation of public value in the long term.
Emerging technology almost always brings with it important privacy considerations, yet the scale and application of AI creates a unique and unprecedented environment of challenges. In some ways, the implications of AI can be seen as an extension of those created by big data, yet AI technology brings with it not only the ability to process huge amounts of data, but also to use it to learn, develop adaptive models and make actionable predictions – much of this without transparent, explainable processes.
The development of AI technology brings with it a significant risk of the assumptions and biases of the individuals and companies that create it influencing the outcome of the AI. Unintended consequences caused by biases and opaque results from using neural networks pose challenges for government organisations wishing to use this technology for decision making purposes. The possibility for discrimination and how this interacts with privacy is discussed further below.
Another key point of differentiation between AI and existing analytics technologies is the potential to automate all of these areas. Where humans have historically been able to exercise a high degree of control over data processing, the increased use of AI means this may no longer be the case. Further, the application of AI to existing technologies stands to profoundly alter their current use and privacy considerations. For example, the use of CCTV cameras in public spaces for surveillance is a relatively widespread practice and not considered to be unreasonably intrusive in modern society. However, combined with the use of facial recognition software, a network of cameras could be transformed into a tool that is much more privacy invasive.
AI also has the potential to change the way that humans interact with machines. For instance, a lot of AI already embodies human characteristics. The use of anthropomorphic interfaces, such as human sounding voices used in assistants such as Alexa and Siri, may raise novel privacy concerns. Social science research indicates people are inclined to interact with technology as if it were human.13 This means people may be more likely to develop trusting relationships with AI designed to replicate human characteristics, and consequently be more inclined to share increasingly personal information as compared with other forms of technology that collect information in a traditional manner.
Much of information privacy discourse around AI has not accounted for the growing power asymmetries between institutions that accumulate data, and the individuals who generate it.14 Current models generally treat data as a good that can be traded, which does not fully acknowledge the difficulty for people to make decisions about their data when dealing with systems they do not understand – particularly when the system understands them well and has learnt, by way of ingesting their data, how to manipulate their preferences. Further, many adaptive algorithms used in AI change constantly, to the extent that often those who create them cannot fully explain the results they generate.
Established notions of information privacy are based on the idea that humans are the primary handlers of information and were not designed to contend with the computational ability of AI that does not conform to traditional ideas of data collection and handling.15 The way we currently think about concepts such as informed consent, notice, and what it means to access or control personal information have never before been so fundamentally challenged as they are by AI. As highlighted above, incorporating privacy considerations as part of an ethical framework could assist in the creation of AI that does not undermine information privacy as these concepts evolve.
In general, the concept of personal information relies on the idea of identifiability – whether or not a person’s identity can be reasonably ascertained from that information. However, the distinction between what is and is not considered to be ‘personal’ is being challenged by the increasing ability to link and match data to individuals, even where previously thought to be ‘de-identified’ or non-identifying to begin with. In this sense, a combination of seemingly non-personal information can become personal information when analysed or correlated. As the amount of available data increases, and technologies for processing and combining it improve, it becomes increasingly difficult to assess whether a given piece of data is ‘identifiable’; considering a piece of data in isolation is not compatible with AI technology, and is no longer a true reflection of whether it can be deemed ‘personal information’.
Much of the value of AI is its ability to identify patterns unseen to the human eye, learn, and make predictions about individuals and groups. In this sense, AI can create information that is otherwise difficult to collect or does not already exist. This means information being collected and used may extend beyond what was originally knowingly disclosed by an individual. Part of the promise of predictive technologies is that deductions can be made from other (seemingly unrelated and innocuous) pieces of data. For example, an AI system designed to make the recruitment process more efficient may be able to infer an applicant’s political persuasion from other information they have supplied, and then incorporate it into the decision-making process.
The current binary notion of personal information is already being challenged by mainstream technologies, yet AI blurs the distinction to the point where what is and is not ‘personal information’ is becoming considerably more difficult to define. The increased emergence of AI is likely to lead to an environment in which all information that is generated by or related to an individual is identifiable.
In this situation, determining what is or is not protected by privacy law according to the definition of personal information is not likely to be technically or legally practical, nor particularly helpful as an effective way to protect the privacy of individuals. Many argue that there is a need to shift focus away from the binary understanding of personal information in order for privacy law to continue to protect the information privacy of individuals in an AI environment.
The underlying goal of these intertwined principles is to minimise the amount of information any one organisation holds about an individual, and to ensure that the way the information is handled is consistent with the expectations of that individual. AI fundamentally challenges all three of these principles.
The very nature of many AI techniques, particularly machine learning, rely on ingesting massive amounts of data in order to train and test algorithms. Collecting such large amounts of data can assist the development of AI, but it can also directly oppose the collection limitation principle. Technological developments in IoT devices, smartphones and web tracking means that the data being fed into AI systems is often not collected in a traditional transaction whereby people consciously provide their personal information to someone who is asking for it.16 In fact, many individuals are often not fully aware of the amount of information being collected about them from their devices and subsequently being used as input data for AI systems. This creates a level of conflict as limiting the collection of personal information is incompatible with the functionality of AI technologies and the devices that collect data to support it, but collecting such vast amounts of information creates inherent privacy risks.
Providing an explanation of the purpose of collection (generally through a collection notice) is how most organisations adhere to the purpose specification principle. The ability of AI to extract meaning from data beyond what it was initially collected for presents a significant challenge to this principle. In some cases, organisations may not necessarily know ahead of time how the information will be used by AI in the future. There is a risk of excessive data collection beyond what is necessary ‘just in case’, using overly broad collection notices and privacy policies in an attempt to ‘catch-all’. This kind of practice allows organisations to claim technical compliance with their privacy obligations, but it is disingenuous and inconsistent with the underlying goal of the collection limitation principle. Further, it undermines the ability of individuals to exercise meaningful control over their personal information.
Conversely, AI could be leveraged to enhance the ability of individuals to specify their preferences for how their personal information is used. For instance, it is not unreasonable to imagine services that are able to learn their users’ privacy preferences and apply different conditions to the data that is collected about different individuals. In this way AI could be pivotal in the establishment of individualised, preference-based models that have the potential to meet the transparency, consent and reasonable expectations objectives of information privacy law, even more effectively than the current model of notice and consent.
Once collected, the use limitation principle endeavours to ensure personal information is only used for the purpose for which it was collected. In general, organisations are also permitted to use personal information for a secondary purpose that would be ‘reasonably expected’ by the individual. This raises the question of whether information being used as input data for an AI system can be considered a ‘reasonably expected secondary purpose’, given that in many instances, the outcome of doing so would be unknown to the individual. Just as AI can highlight patterns and relationships in data unforeseen by humans, it could also reveal new potential uses for that information. Combining this with the issues of purpose specification above, organisations are likely to find it difficult to ensure personal information is only used for the purpose it was collected for when using AI technologies.
The assumption that people, particularly young people or ‘digital natives’, are becoming less concerned about their information privacy may prompt the idea that a reasonably expected secondary purpose for use of information would be quite broad. This is not necessarily the case. The Boston Consulting Group found that for 75% of consumers in most countries, privacy of personal information remains a top issue, and that people aged 18-24 are only slightly less cautious than older generations.17 This indicates that people are not by default becoming less concerned about how their personal information is being used just because technology is becoming ubiquitous, and therefore may not always regard the use of their personal information by AI as a reasonably expected secondary purpose.18 AI is likely to blur the distinction between what is considered a primary and secondary purpose to the extent that the practicality of the use limitation principle may need to be reconsidered.
Taken together, the purpose specification, collection limitation and use limitation principles are significantly challenged by AI. Mass data collection, often by means that are not obvious to individuals; vague or misleading collection notices; and an assumption that people are more comfortable with the secondary use of their information than they actually are, lead to a situation in which the current understanding of information privacy through these principles may no longer be effective. However, AI also brings with it opportunities to revolutionise the way traditional privacy principles are realised. For instance, training a machine learning algorithm on massive amounts of data in a secure environment before being released could in turn allow for increased data security.
Widespread use of AI will prompt us to change the way we apply traditional privacy principles – whether this is an improvement or a degradation on the standards of privacy protection however, remains to be seen. By considering privacy as a foundational element within an ethical framework for developing AI, there is potential for organisations to improve collection notice practices and enable individuals to have a more nuanced and informed interaction with organisations regarding the use – and secondary use – of their information.
Our current understanding of information privacy rests on the ability of individuals to exercise choices regarding the information others have about them and what is done with it. Yet, the complexity surrounding AI can mean that processes are unclear to individuals’ whose information is being used, making truly informed and meaningful consent unattainable. For instance, deep learning techniques can pose challenges to transparency, as providing an explanation about how conclusions are drawn can at times be difficult even for those initially developing the algorithms, let alone the average individual. Organisations will struggle to be transparent in their AI practices, or to obtain consent, if they cannot communicate the processes to citizens.
There is much research upon the emergence of a ‘privacy paradox’, in which people express concern for their privacy, but in practice continue to willingly contribute their information via the systems and technologies they use.19 One interpretation of this paradox indicates that even when informed, individuals often have no choice but to enter an ‘unconscionable contract’ to allow their data to be used.20 In this sense, many may feel resigned to the use of their data because they feel there is no alternative, rather than positively welcoming it.21 An increasing complexity of the networks and systems we use, combined with the widening variety of data collection methods renders a binary yes/no response to consent at the beginning of a transaction less and less meaningful in the modern world.22 While AI technologies encourage many of these challenges, they also have the potential to be the solution, by presenting novel ways of explaining what is happening to an individual’s data within each layer of processing, or enabling individualised platforms for people to exercise consent.
One potential way to increase transparency and also scrutinise, challenge and restrain decision making that has occurred without human involvement is being explored in the ‘right to explanation’. Such a right would provide individuals with the ability to question decisions that affect them, which have been made on a purely algorithmic basis.23 Despite the current technological challenge to enable this, many key figures in the AI community see transparency of decisions, or ‘explainability’, as integral to developing and maintaining trust in the evolving relationship between humans and intelligent machines.24
There is much work already being done to build algorithms that can explain how and why they came to produce their output.25 With this kind of ability, AI could potentially facilitate transparency, in that it would be able to clearly explain decisions and be tested for bias – a process that is not always achievable for human decision makers. From a legal and policy perspective, this right is being explored in Article 22 of the European Union General Data Protection Regulation. It remains to be seen how effective this will be, with some critics arguing that there remain “serious practical and conceptual flaws,” as the right only applies to decisions that are solely automated, which is rarely the case.26
Information privacy is generally regarded as an enabling right, meaning that a lot of its value lies in its ability to enable other human rights to be realised, such as the rights to freedom of association and freedom of expression. Privacy protections can also assist in the protection against discrimination by placing controls on how information about a person can be collected, used and disclosed. For example, information regarding an individual’s ethnic origin or sexual orientation has stronger protections under privacy law. This is due to the inherent sensitive nature of the information, and aims to minimise the risk of harm that can be caused by making decisions based upon it. One of the most prominent ethical issues of AI with immediate ramifications is its potential to discriminate, perpetuate biases, and exacerbate existing inequalities. Because algorithms are trained on existing data, they can end up replicating unwanted patterns of unfairness due to the data they have ingested.27
Further, those building the systems may unknowingly introduce their own human biases into the functionality. Because AI challenges the ability of information privacy to operate as it has done historically, the safeguard against discrimination that information privacy provides as an enabling right risks becoming dismantled. Interestingly, AI technology also has the potential to minimise discrimination if developed with consideration of these issues – by removing or supporting the human element of many decision-making processes, innate human biases can be avoided.
Governance and oversight are championed in information privacy law to ensure appropriate structures are in place that prevent a power imbalance between citizens and government. This relies on regulators ensuring that personal information is being handled appropriately. The challenges to our understanding of information privacy outlined in the sections above are replicated when it comes to effectively regulating AI technology.
The difficulty of regulating technology has been discussed elsewhere in depth,28 however some considerations with particular relevance to AI and information privacy include:
Good governance frameworks can be used to promote good design, structure and oversight of AI technologies and how they interact with privacy. By creating an environment in which general rights and protections are enshrined, regulation can prompt the development of automated systems that are underpinned by information privacy, consistent with a Privacy by Design approach to privacy protection.
Privacy governance cannot be achieved solely through top-down control from regulators; those who control the data, and those building the technology, should themselves be involved in the design of privacy-enhancing systems.29
We already live in a world of big data, and the expansion of computational power through AI stands to drastically alter the landscape of information privacy. A connected life through IoT devices and smart cities technology – fuelled by AI – promises a wealth of potential benefits, including more dynamic use of resources, increased efficiency and a higher standard of living. The possibilities that AI technology could provide in healthcare, the justice system and government services are immense. Yet, as many technologies before it, AI presents social, technological and legal challenges to how we understand and protect information privacy.
This resource has stepped through some of the key information privacy considerations of AI, and how AI will require our established understanding of personal information to be revisited. However, while the long-held principles of information privacy may need to be reconceptualised, the emergence of AI does not mean that privacy will cease to matter or exist. Privacy provides an important framework for making ethical choices about how we develop, use and regulate new technologies. It will also continue to be integral to how we mediate our identities, develop a sense of self, and realise other important rights including freedom of speech and association. Answering the privacy questions raised by AI will be essential to its long-term success.
Moving forward, our understanding of AI and privacy may see a shift in focus from the collection aspect of information privacy, toward emphasising safeguards to ensure information is handled ethically and responsibly once it is obtained. Attempts to control or limit collection of data are likely to become increasingly difficult as data-collecting technology becomes ubiquitous. As such, shifting the emphasis toward ‘ethical data stewardship’ over data once it is collected has been posited as an option. This would require a genuine commitment to transparency and accountability through good governance practices.
Government has an important role to play in creating an environment in which a commitment to developing safe and fair AI can be balanced with technological progress.30 The right balance necessitates a consultative, interdisciplinary approach, as excessive, inappropriate or misplaced regulation could slow the adoption of AI or fail to address its true challenges. Leveraging existing information privacy frameworks, as well as re-imagining traditional concepts will be a key component in building, using and regulating AI.
As companies increase their use of artificial intelligence (AI), people are questioning the extent to which human biases have made their way into AI systems. Examples of AI bias in the real world show us that when discriminatory data and algorithms are baked into AI models, the models deploy biases at scale and amplify the resulting negative effects.
Companies are motivated to tackle the challenge of bias in AI not only to achieve fairness, but also to ensure better results. However, just as systemic racial and gender bias have proven difficult to eliminate in the real world, eliminating bias in AI is no easy task.
In the article, What AI can and can’t do (yet) for your business, authors Michael Chui, James Manyika, and Mehdi Miremadi of McKinsey noted, “Such biases have a tendency to stay embedded because recognizing them, and taking steps to address them, requires a deep mastery of data-science techniques, as well as a more meta-understanding of existing social forces, including data collection. In all, debiasing is proving to be among the most daunting obstacles, and certainly the most socially fraught, to date.”
Examples of AI bias from real life provide organizations with useful insights on how to identify and address bias. By looking critically at these examples, and at successes in overcoming bias, data scientists can begin to build a roadmap for identifying and preventing bias in their machine learning models.
AI bias, also referred to as machine learning bias or algorithm bias, refers to AI systems that produce biased results that reflect and perpetuate human biases within a society, including historical and current social inequality. Bias can be found in the initial training data, the algorithm, or the predictions the algorithm produces.
When bias goes unaddressed, it hinders people’s ability to participate in the economy and society. It also reduces AI’s potential. Businesses cannot benefit from systems that produce distorted results and foster mistrust among people of color, women, people with disabilities, the LGBTQ community, or other marginalized groups of people.
Eliminating AI bias requires drilling down into datasets, machine learning algorithms and other elements of AI systems to identify sources of potential bias.
AI systems learn to make decisions based on training data, so it is essential to assess datasets for the presence of bias. One method is to review data sampling for over- or underrepresented groups within the training data. For example, training data for a facial recognition algorithm that over-represents white people may create errors when attempting facial recognition for people of color. Similarly, security data that includes information gathered in geographic areas that are predominantly black could create racial bias in AI tools used by police.
Bias can also result from how the training data is labeled. For example, AI recruiting tools that use inconsistent labeling or exclude or over-represent certain characteristics could eliminate qualified job applicants from consideration.
Using flawed training data can result in algorithms that repeatedly produce errors, unfair outcomes, or even amplify the bias inherent in the flawed data. Algorithmic bias can also be caused by programming errors, such as a developer unfairly weighting factors in algorithm decision-making based on their own conscious or unconscious biases. For example, indicators like income or vocabulary might be used by the algorithm to unintentionally discriminate against people of a certain race or gender.
When people process information and make judgments, we are inevitably influenced by our experiences and our preferences. As a result, people may build these biases into AI systems through the selection of data or how the data is weighted. For example, cognitive bias could lead to favoring datasets gathered from Americans rather than sampling from a range of populations around the globe.
According to NIST, this source of bias is more common than you might think. In its report Towards a Standard for Identifying and Managing Bias in Artificial Intelligence (NIST Special Publication 1270), NIST noted that “human and systemic institutional and societal factors are significant sources of AI bias as well, and are currently overlooked. Successfully meeting this challenge will require taking all forms of bias into account. This means expanding our perspective beyond the machine learning pipeline to recognize and investigate how this technology is both created within and impacts our society.”
As society becomes more aware of how AI works and the possibility for bias, organizations have uncovered numerous high-profile examples of bias in AI in a wide range of use cases.
Identifying and addressing bias in AI begins with AI governance, or the ability to direct, manage and monitor the AI activities of an organization. In practice, AI governance creates a set of policies, practices and frameworks to guide the responsible development and use of AI technologies. When done well, AI governance ensures that there is a balance of benefits bestowed upon businesses, customers, employees and society as a whole.
Through AI governance policies, companies can build the following practices:
A proper technology mix can be crucial to an effective data and AI governance strategy, with a modern data architecture and trustworthy AI platform being key components. Policy orchestration within a data fabric architecture is an excellent tool that can simplify the complex AI audit processes. By incorporating AI audit and related processes into the governance policies of your data architecture, your organization can help gain an understanding of areas that require ongoing inspection.
At IBM Consulting, we have been helping clients set up an evaluation process for bias and other areas. As AI adoption scales and innovations evolve, so will the security guidance mature, as is the case with every technology that’s been embedded into the fabric of an enterprise across the years. Below, we share some best practices from IBM to help organizations prepare for the secure deployment of AI across their environments:
Interest in Artificial Intelligence (AI) is increasing as more individuals and businesses witness its benefits in various use cases. However, there are also some valid concerns surrounding AI technology:
In this article, we focus on AI bias and will answer all important questions regarding biases in artificial intelligence algorithms from types and examples of AI biases to removing those biases from AI algorithms.
AI bias is an anomaly in the output of machine learning algorithms, due to the prejudiced assumptions made during the algorithm development process or prejudices in the training data.
AI systems contain biases due to two reasons:
Based on the training data, AI models can suffer from several biases such as:
Since 2022, the launch of ChatGPT, the interest in and applications of in generative AI tools have been increasing. Gartner forecasts that by 2025, generative AI will produce 10% of all generated data.2  
However, the latest research shows that the data created by GenAI can be biased just like other AI models. For example, A 2023 analysis of over 5,000 images created with the generative AI tool that it amplifies both gender and racial stereotypes. 3 
Another study compares three GenAI tools for their age, gender and emotion representations (See Figure 2), showing how all models reproduce the social biases and inequalities.4  
Such biases in AI can have real-world impacts, such as increasing the risk of harm to over-targeted populations when integrated into police department software, leading to potential physical injury or unlawful imprisonment.
Technically, yes. An AI system can be as good as the quality of its input data. If you can clean your training dataset from conscious and unconscious assumptions on race, gender, or other ideological concepts, you are able to build an AI system that makes unbiased data-driven decisions.
However, in the real world, we don’t expect AI to ever be completely unbiased any time soon due to the same argument we provided above. AI can be as good as data and people are the ones who create data. There are numerous human biases and ongoing identification of new biases is increasing the total number constantly. Therefore, it may not be possible to have a completely unbiased human mind so does AI system. After all, humans are creating the biased data while humans and human-made algorithms are checking the data to identify and remove biases.
What we can do about AI bias is to minimize it by testing data and algorithms and developing AI systems with responsible AI principles in mind.
Firstly, if your data set is complete, you should acknowledge that AI biases can only happen due to the prejudices of humankind and you should focus on removing those prejudices from the data set. However, it is not as easy as it sounds. 
A naive approach is removing protected classes (such as sex or race) from data and deleting the labels that make the algorithm biased. Yet, this approach may not work because removed labels may affect the understanding of the model and your results’ accuracy may get worse.
So there are no quick fixes to removing all biases but there are high level recommendations from consultants like McKinsey highlighting the best practices of AI bias minimization:
Steps to fixing bias in AI systems:
A data-centric approach to AI development can also help minimize bias in AI systems.
To prevent AI bias, companies can benefit from these technologies and tools:
AI governance tools ensure that AI technologies adhere to ethical and legal standards, preventing biased outputs and promoting transparency. These tools help in addressing bias throughout the AI lifecycle by monitoring ai tools for algorithmic bias and other existing biases.
A responsible AI platform can offer integrated solutions for ai design, prioritizing fairness and accountability. They include features like bias detectionand ethical risk assessments, preventing stereotyping bias and ensuring AI systems do not reinforce harmful stereotypes or discrimination against marginalized groups or certain genders.
MLOps tools (Machine Learning Operations) platforms streamline machine learning processes by integrating responsible AI practices, reducing potential bias in models. These platforms ensure continuous monitoring and transparency, safeguarding against explicit biases in machine learning software.
LLMOps tools (Large Language Model Operations) platforms focus on managing generative AI models, ensuring they do not perpetuate confirmation bias or out group homogeneity bias. These platforms include tools for bias mitigation, maintaining ethical oversight in the deployment of large language models.
Data governance tools manage the data used to train AI models, ensuring representative data sets free from institutional biases. They enforce standards and monitor data collected, preventing flawed data or incomplete data from introducing measurement bias into AI systems, which can lead to biased results and bias in artificial intelligence.
Racism in AI occurs when algorithms and models display unfair prejudice toward certain racial or ethnic groups. This bias can lead to serious societal harms, such as wrongful arrests due to misidentifications in facial recognition or unequal job opportunities due to biased hiring algorithms. These biases perpetuate systemic racism by reinforcing existing prejudices, as AI often replicates the biases present in its training data, which can further entrench racial inequalities in society.
For example, a researcher inputted phrases such as “Black African doctors caring for white suffering children” into an AI program meant to create photo-realistic images. The aim was to challenge the “white savior” stereotype of helping African children. However, the AI consistently portrayed the children as Black, and in 22 out of more than 350 images, the doctors appeared white.
Sexism in AI manifests when systems favor one gender over another, often prioritizing male candidates for jobs or defaulting to male symptoms in health apps. These biases can limit opportunities for women and even endanger their health. By reproducing traditional gender roles and stereotypes, AI can perpetuate gender inequality, as seen in biased training data and the design choices made by developers.
A UNDP study analyzed how two popular generative AI models, DALL-E 2 and Stable Diffusion, represent STEM professions. When asked to visualize roles like “engineer” or “scientist,” 75-100% of the AI-generated images depicted men, perpetuating biases (See Image 5). This starkly contrasts with real-world data, where women make up between 28% and 40% of STEM graduates globally, though their representation decreases as they advance in their careers, a phenomenon known as the “Leaky Pipeline.” 
UNDP advices to develop develop AI models with diverse teams, ensuring fair representation and implementing transparency, continuous testing, and user feedback mechanisms.
Ageism in AI involves the marginalization of older individuals or the perpetuation of stereotypes about age. This bias can result in older adults being excluded from certain services or misdiagnosed by health algorithms. AI can reproduce societal attitudes that undervalue the elderly, as seen when algorithms favor youthful images or struggle to accommodate the vocal patterns of older users, reinforcing age-related biases.
Ableism in AI occurs when systems prioritize able-bodied perspectives or fail to accommodate disabilities. This can exclude individuals with disabilities from using technology, as seen in voice recognition software that struggles with speech impairments. AI often reflects societal biases by failing to represent the full spectrum of human diversity, highlighting the need for more inclusive design and training data that consider the needs of disabled individuals.
Bay Area startup Sanas developed an AI-based accent translation system to make call center workers from around the world sound more familiar to American customers. The tool transforms the speaker’s accent into a “neutral” American accent in real time. As SFGATE reports, Sanas president Marty Sarim says accents are a problem because “they cause bias and they cause misunderstandings.”
Racial biases cannot be eliminated by making everyone sound white and American. To the contrary, it will exacerbate these biases since non-American call center workers who don’t use this technology will face even worse discrimination if a white American accent becomes the norm.
Here is a full list of case studies and real-life examples from famous AI tools and academia:
Melissa Heikkilä, a journalist at MIT Technology Review, tested the AI-powered app Lensa and found it generated hypersexualized images, particularly of Asian women, including herself.8  
She noted that the AI’s training data, sourced from the internet, contained sexist and racist content, leading to these biased results. This issue highlights how AI models can perpetuate harmful stereotypes against marginalized groups. 
Despite some efforts to address these biases, developers’ choices and flawed data still cause significant problems. These biases could negatively impact how society views women and how women perceive themselves. 
With the dream of automating the recruiting process, Amazon started an AI project in 2014. Their project was solely based on reviewing job applicants’ resumes and rating applicants by using AI-powered algorithms so that recruiters don’t spend time on manual resume screen tasks. However, by 2015, Amazon realized that their new AI recruiting system was not rating candidates fairly and it showed bias against women.
Amazon had used historical data from the last 10-years to train their AI model. Historical data contained biases against women since there was a male dominance across the tech industry and men were forming 60% of Amazon’s employees. Therefore Amazon’s recruiting system incorrectly learnt that male candidates were preferable. It penalized resumes that included the word “women’s,” as in “women’s chess club captain.” Therefore, Amazon stopped using the algorithm for recruiting purposes.
A health care risk-prediction algorithm that is used on more than 200 million U.S. citizens, demonstrated racial bias because it relied on a faulty metric for determining the need. 
The algorithm was designed to predict which patients would likely need extra medical care, however, then it is revealed that the algorithm was producing faulty results that favor white patients over black patients.
The algorithm’s designers used previous patients’ healthcare spending as a proxy for medical needs. This was a bad interpretation of historical data because income and race are highly correlated metrics and making assumptions based on only one variable of correlated metrics led the algorithm to provide inaccurate results.
There are numerous examples of human bias and we see that happening in tech platforms. Since data on tech platforms is later used to train machine learning models, these biases lead to biased machine learning models.
Krita Sharma, who is an artificial intelligence technologist and business executive, is explaining how the lack of diversity in tech is creeping into AI and is providing three ways to make more ethical algorithms:
Barak Turovsky, who is the product director at Google AI, is explaining how Google Translate is dealing with AI bias:
Hope this clarifies some of the major points regarding biases in AI. For more on how AI is changing the world, you can check out articles on AI, AI technologies and AI applications in marketing, sales, customer service, IT, data or analytics.
Also, feel free to follow our Linkedin page where we share how AI is impacting businesses and individuals or our Twitter account.
If you are looking for AI vendors, you can benefit from our data-driven lists of:
GDPR provisions debuted six years ago to help standardize European privacy and data protection frameworks. Due to the massive interest in AI, the GDPR is seen as a first line of protection against the uncertainties of new techniques, business models and data processing pipelines.
Data privacy concerns have grown more complicated with the surge in generative AI applications. Companies like OpenAI have been reluctant to share information about how their training data was collected and how they address privacy concerns pertinent to the use of these AI models.
Regulators in Italy, for example, initially blocked the rollout of OpenAI's ChatGPT, citing data privacy concerns. Four weeks later, regulators allowed the chatbot interface to large language models (LLMs) to operate, only to report privacy violations in early 2024. Privacy issues aren't limited to large AI vendors. Enterprises are starting to mix and match newer LLMs with their internal processes and data.
Privacy experts are also concerned that the GDPR didn't plan for some of the potential issues arising from new AI models. "The fact that AI can be used to automate decision-making and profiling highlights the need for regulators to implement measures that ensure such activity is done fairly and ethically," said Martin Davies, audit alliance manager at compliance automation platform provider Drata. The GDPR, for example, contains provisions for algorithmic transparency in certain defined decision-making processes. But AI systems and models can become black boxes, making it challenging for regulators and enterprise leaders charged with protecting data to understand how personal information is used within them.
Resolving these issues is important not just for regulatory compliance, but also to build trust in AI applications, Davies reasoned. "By balancing its rapid technological advancement with a framework that protects fundamental rights," he explained, "an environment of trust and confidence in AI technologies will be created."
The GDPR has been important in advancing privacy protections in Europe and inspiring regulators worldwide. But when it comes to AI, the regulation has many shortcomings.
Ironically, one of GDPR's biggest weaknesses is also a major strength -- the "right to be forgotten" framework emphasizing individual control over personal data, according to Davi Ottenheimer, vice president of trust and digital ethics at data infrastructure software provider Inrupt. "Imagine a robot that can only be powered off but not reprogrammed, and you see the problem with AI and GDPR," said Ottenheimer, who believes "the right to be understood" would better serve the framing of the GDPR. "This will force transparency engineering into AI systems such that individuals can comprehend and challenge decisions being made," he explained.
The GDPR applies to AI whenever personal data is processed during model training or deployment, said Sophie Stalla-Bourdillon, senior privacy counsel and legal engineer at data security platform provider Immuta. Yet the regulation doesn't always apply when trained on nonpersonal data, she said, adding that the GDPR also hasn't been the most effective mechanism for identifying red flags.
"The GDPR's principle-based approach becomes less effective at guiding practices when organizations are determined to participate in the AI race regardless of the consequences," Stalla-Bourdillon explained. Enterprises need clearer, earlier and more specific signals from the regulation to know when to hit the brakes. The EU Artificial Intelligence Act tries to fill this gap with a three-fold distinction among prohibited AI practices, high-risk AI systems and other AI systems as well as concepts like general-purpose AI systems and models.
Numerous AI risks in sectors like education, social benefits, judicial and law enforcement have often been ignored and should be considered in shaping new regulations, suggested Stalla-Bourdillon, who is also a visiting law professor at the University of Southampton, U.K. In the U.S., the COMPAS algorithm used for AI-powered sentencing in courts recommended longer sentences for black defendants compared to white defendants by unevenly predicting recidivism rates. The French equivalent of the U.S. Department of Education has been called out for an opaque college recommendation algorithm. The Dutch tax authority has been criticized for relying heavily on a flawed AI algorithm to pursue innocent people for tax fraud.
The GDPR doesn't explicitly mention AI and the many new ways AI can be used to process personal information, which can create confusion among data management and technology teams.  "Although the GDPR can be interpreted and applied generally to AI, practitioners of AI are likely looking for additional guidance," surmised Tom Moore, senior managing director at consultancy Protiviti. More specific guidance could further help enterprises take advantage of AI's data protection capabilities, achieve GDPR compliance and avoid the substantial penalties codified in the law. Moore said the GDPR faces several unique AI challenges, including the following:
The EU AI Act takes a risk-based approach to fill these gaps by imposing requirements based on associated risk levels with specific AI applications. It also includes provisions on transparency, human oversight and accountability.
Governments want their economies to realize the benefits of AI, but society is just learning about the risks associated with it. Crafting better regulations that balance rewards and risks can require input from several sources. "The European Data Protection Board [EDPB], European Data Protection Supervisor [EDPS], national data protection authorities, academics, civil society organizations as well as commercial enterprises and many others all want to have their voices heard during any legislative process," Moore said.
Establishing regulations that are adaptable and future-proof to keep pace with technological progress, Moore noted, can be difficult and time-consuming. Previous examples of European technology protection legislation, including the GDPR, Digital Markets Act and Digital Services Act, took the EU many years and, in some cases, decades to develop and enact. Stalla-Bourdillon said a lack of consensus among lawmakers and intense lobbying by AI vendors can also slow the regulatory process. "Every piece of legislation is a political compromise," she said, "and politics takes time."
The AI Act moved much more quickly, but Moore believes a faster pace could sacrifice sufficient deployment details and specificity. "Until and even after the authorities provide implementation details," he conjectured, "industry practitioners will want to work with their advisors to help assess the law's implications."
The GDPR established national data protection authorities and European-wide bodies, such as the EDPS and EDPB. These bodies are likely to issue guidance to help citizens and enterprises understand AI and the various laws governing it. They might also enforce AI practitioners' behavior, either alone or with other regulatory bodies, and use AI to manage enterprise data protection activities, respond to citizen inquiries and conduct investigations.
In addition, Moore said GDPR provisions can influence the development and deployment of AI in several ways, including the following:
"The future of AI and regulations in Europe," Moore conjectured, "is likely to have a significant impact on the industry globally as the GDPR did upon its introduction." The AI Act, for example, could become a global benchmark for AI governance, influencing regulations in other jurisdictions and shaping industry practices worldwide.
However, the AI Act includes numerous exceptions, which risk undermining its whole purpose, Stalla-Bourdillon argued. It delegates standards-setting for new metrics to various bodies, which will depend on their work and the oversight performed by auditors. Standards and auditing, for example, typically focus only on processes rather than substance to protect privacy.
The rapid adoption of AI will require building trust rather than just faster models, Inrupt's Ottenheimer cautioned. "AI development accelerates when it's made measurably safer, like how a fast car needs quality brakes and suspension," he explained. "It fosters public trust and enhances competitiveness." With the emphasis on safe AI in the AI Act, he added, "Europe now serves as a global model for ethical practices, shaping the future of the industry in tangible societal benefits and establishing important benchmarks for individual freedom and progress."
Data protection vs. security vs. privacy: Key differences
Data protection vs. data backup: How are they different?
Core elements of a successful data protection strategy
International Journal of Educational Technology in Higher Education
Metrics details
Artificial Intelligence (AI) and robotics are likely to have a significant long-term impact on higher education (HE). The scope of this impact is hard to grasp partly because the literature is siloed, as well as the changing meaning of the concepts themselves. But developments are surrounded by controversies in terms of what is technically possible, what is practical to implement and what is desirable, pedagogically or for the good of society. Design fictions that vividly imagine future scenarios of AI or robotics in use offer a means both to explain and query the technological possibilities. The paper describes the use of a wide-ranging narrative literature review to develop eight such design fictions that capture the range of potential use of AI and robots in learning, administration and research. They prompt wider discussion by instantiating such issues as how they might enable teaching of high order skills or change staff roles, as well as exploring the impact on human agency and the nature of datafication.
The potential of Artificial Intelligence (AI) and robots to reshape our future has attracted vast interest among the public, government and academia in the last few years. As in every other sector of life, higher education (HE) will be affected, perhaps in a profound way (Bates et al., 2020; DeMartini and Benussi, 2017). HE will have to adapt to educate people to operate in a new economy and potentially for a different way of life. AI and robotics are also likely to change how education itself works, altering what learning is like, the role of teachers and researchers, and how universities work as institutions.
However, the potential changes in HE are hard to grasp for a number of reasons. One reason is that impact is, as Clay (2018) puts it, “wide and deep” yet the research literature discussing it is siloed. AI and robotics for education are separate literatures, for example. AI for education, learning analytics (LA) and educational data mining also remain somewhat separate fields. Applications to HE research as opposed to learning, such as the robot scientist concept or text and data mining (TDM), are also usually discussed separately. Thus if we wish to grasp the potential impact of AI and robots on HE holistically we need to extend our vision across the breadth of these diverse literatures.
A further reason why the potential implications of AI and robots for HE are quite hard to grasp is because rather than a single technology, something like AI is an idea or aspiration for how computers could participate in human decision making. Faith in how to do this has shifted across different technologies over time; as have concepts of learning (Roll and Wylie, 2016). Also, because AI and robotics are ideas that have been pursued over many decades there are some quite mature applications: impacts have already happened. Equally there are potential applications that are being developed and many only just beginning to be imagined. So, confusingly from a temporal perspective, uses of AI and robots in HE are past, present and future.
Although hard to fully grasp, it is important that a wider understanding and debate is achieved, because AI and robotics pose a range of pedagogic, practical, ethical and social justice challenges. A large body of educational literature explores the challenges of implementing new technologies in the classroom as a change management issue (e.g. as synthesised by Reid, 2014). Introducing AI and robots will not be a smooth process without its challenges and ironies. There is also a strong tradition in the educational literature of critical responses to technology in HE. These typically focus on issues such as the potential of technology to dehumanise the learning experience. They are often driven by fear of commercialisation or neo-liberal ideologies wrapped up in technology. Similar arguments are developing around AI and robotics. There is a particularly strong concentration of critique around the datafication of HE. Thus the questions around the use of AI and robots are as much about what we should do as what is possible (Selwyn, 2019a). Yet according to a recent literature review most current research about AI in learning is from computer science and seems to neglect both pedagogy and ethics (Zawacki-Richter et al., 2019). Research on AIEd has also been recognised to have a WEIRD (western, educated, industrialized, rich and democratic) bias for some time (Blanchard, 2015).
One device to make the use of AI and robots more graspable is fiction, with its ability to help us imagine alternative worlds. Science fiction has already had a powerful influence on creating collective imaginaries of technology and so in shaping the future (Dourish and Bell, 2014). Science fiction has had a fascination with AI and robots, presumably because they enhance or replace defining human attributes: the mind and the body. To harness the power of fiction for the critical imagination, a growing body of work within Human Computer Interaction (HCI) studies adopts the use of speculative or critical narratives to destabilise assumptions through “design fictions” (Blythe 2017): “a conflation of design, science fact, and science fiction” (Bleecker, 2009: 6). They can be used to pose critical questions about the impact of technology on society and to actively engage wider publics in how technology is designed. This is a promising route for making the impact of AI and robotics on HE easier to grasp. In this context, the purpose of this paper is to describe the development of a collection of design fictions to widen the debate about the potential impact of AI and robots on HE, based on a wide-ranging narrative literature review. First, the paper will explain more fully the design fiction method.
There are many types of fictions that are used for our thinking about the future. In strategic planning and in future studies, scenarios—essentially fictional narratives—are used to encapsulate contrasting possible futures (Amer et al., 2013; Inayatullah, 2008). These are then used collaboratively by stakeholders to make choices about preferred directions. On a more practical level, in designing information systems traditional design scenarios are short narratives that picture use of a planned system and that are employed to explain how it could be used to solve existing problems. As Carroll (1999) argues, such scenarios are also essentially stories or fictions and this reflects the fact that system design is inherently a creative process (Blythe, 2017). They are often used to involve stakeholders in systems design. The benefit is that the fictional scenario prompts reflection outside the constraints of trying to produce something that simply works (Carroll, 1999). But they tend to represent a system being used entirely as intended (Nathan et al., 2007). They typically only include immediate stakeholders and immediate contexts of use, rather than thinking about the wider societal impacts of pervasive use of the technology. A growing body of work in the study of HCI refashions these narratives:
Design fictions create a speculative space in which to raise questions about whether a particular technology is desirable, the socio-cultural assumptions built into technologies, the potential for different technologies to make different worlds, our relation to technology in general, and indeed our role in making the future happen.
Fictions (or an artefact such as a video based on them) are used to elicit research data, e.g. through interviews or focus groups Lyckvi et al. (2018).
For a study of the potential impact of AI and robots on HE, design fictions are a particularly suitable method. They are already used by some authors working in the field such as Pinkwart (2016), Luckin and Holmes (2017) and Selwyn et al. (2020). As a research tool, design fictions can encapsulate key issues in a short, accessible form. Critically, they have the potential to change the scope of the debate, by shifting attention away from the existing literature and its focus on developing and testing specific AI applications (Zawacki-Richter et al., 2019) to weighing up more or less desirable directions of travel for society. They can be used to pose critical questions that are not being asked by developers because of the WEIRD bias in the research community itself (Blanchard, 2015), to shift focus onto ethical and social justice issues, and also raise doubts based on practical obstacles to their widespread adoption. Fictions engage readers imaginatively and on an affective level. Furthermore, because they are explicitly fictions readers can challenge their assumptions, even get involved in actively rewriting them.
Design fictions are often individual texts. But collections of fictions create potential for reading against each other, further prompting thoughts about alternative futures. In a similar way, in future studies, scenarios are often generated around four or more alternatives, each premised on different assumptions (Inayatullah, 2008). This avoids the tendency towards a utopian/ dystopian dualism found in some use of fiction (Rummel et al., 2016; Pinkwart 2016). Thus in this study the aim was to produce a collection of contrasting fictions that surface the range of debates revolving around the application of AI and robotics to HE.
In this study the foundation for the fictions was a wide-ranging narrative review of the literature (Templier and Paré, 2015). The purpose of the review was to generate a picture of the pedagogic, social, ethical and implementation issues raised by the latest trends in the application of AI and robots to teaching, research and administrative functions in HE, as a foundation for narratives which could instantiate the issues in a fictional form. We know from previous systematic reviews that these type of issue are neglected at least in the literature on AIEds (Zawacki-Richter et al., 2019). So the chief novelty of the review lay in (a) focusing on social, ethical, pedagogic and management implications (b) encompassing both AI and robotics as related aspects of automation and (c) seeking to be inclusive across the full range of functions of HE, including impacts on learning, but also on research and scholarly communications, as well as administrative functions, and estates management (smart campus).
In order to gather references for the review, systematic searches on the ERIC database for relevant terms such as “AI or Artificial Intelligence”; “conversational agent”, “AIED” were conducted. Selection was made for items which either primarily addressed non-technical issues or which themselves contained substantial literature reviews that could be used to gain a picture of the most recent applications. This systematic search was combined with snowballing (also known as pearl growing techniques) using references by and to highly relevant matches to find other relevant material. While typically underreported in systematic reviews this method has been shown to be highly effective in retrieving more relevant items (Badampudi et al. 2015). Some grey literature was included because there are a large number of reports by governmental organisations summarizing the social implications of AI and robots. Because many issues relating to datafication are foreshadowed in the literature on learning analytics, this topic was also included. In addition, some general literature on AI and robots, while not directly referencing education, was deemed to be relevant, particularly as it was recognised that education might be a late adopter and so impacts would be felt through wider social changes rather than directly through educational applications. Literature reviews which suggested trends in current technologies were included but items which were detailed reports of the development of technologies were excluded. Items prior to 2016 tended also to be excluded, because the concern was with the latest wave of AI and robots. As a result of these searches in the order of 500 items were consulted, with around 200 items deemed to be of high relevance. As such there is no claim that this was an “exhaustive” review, rather it should be seen as complimenting existing systematic reviews by serving a different purpose. The review also successfully identified a number of existing fictions in the literature that could then be rewritten to fit the needs of the study, such as to apply to HE, to make them more concise or add new elements (fictions 1, 3, 4).
As an imaginative act, writing fictions is not reducible to a completely transparent method, although some aspects can be described (Lyckvi et al., 2018). Some techniques to create effective critical designs are suggested by Auger (2013) such as placing something uncanny or unexpected against the backdrop of mundane normality and a sense of verisimilitude (perhaps achieved through mixing fact and fiction). Fiction 6, for example, exploits the mundane feel of committee meeting minutes to help us imagine the debates that would occur among university leaders implementing AI. A common strategy is to take the implications of a central counterfactual premise to its logical conclusion: asking: “what if?” For example, fiction 7 extends existing strategies of gathering data and using chatbots to act on them to its logical extension as a comprehensive system of data surveillance. Another technique used here was to exploit certain genres of writing such as in fiction 6 where using a style of writing from marketing and PR remind us of the role of EdTech companies in producing AI and robots.
Table 1 offers a summary of the eight fictions produced through this process. The fictions explore the potential of AI and robots in different areas of university activity, in learning, administration and research (Table 1 column 5). They seek to represent some different types of technology (column 2). Some are rather futuristic, most seem feasible today, or in the very near future (column 3). The full text of the fictions and supporting material can be downloaded from the University of Sheffield data repository, ORDA, and used under a cc-by-sa licence (https://doi.org/10.35542/osf.io/s2jc8). The following sections describe each fiction in turn, showing how it relates to the literature and surfaces relevant issues. Table 2 below will summarise the issues raised.
Much of the literature around AI in learning focuses on tools that directly teach students (Baker and Smith, 2019; Holmes et al., 2019; Zawacki-Richter et al., 2019). This includes classes of systems such as:
Automatic writing evaluation (AWE) which are tools to assess and offer feedback on writing style (rather than content) such as learnandwrite, Grammarly and Turnitin’s Revision Assistant (Strobl, et al. 2019; Hussein et al., 2019; Hockly, 2019).
Conversational agents (also known as Chatbots or virtual assistants) which are AI tools designed to converse with humans (Winkler and Sӧllner, 2018).
Much of such literature reflects the development of AI technologies and their evaluation compared to other forms of teaching. However, according to a recent review it is primarily written by computer scientists mostly from a technical point of view with relatively little connection to pedagogy or ethics (Zawacki-Richter et al., 2019). In contrast some authors such as Luckin and Holmes, seek to move beyond the rather narrow development of tools and their evaluation, to envisioning how AI can address the grand challenges of learning in the twenty-first century (Luckin, et al. 2016; Holmes et al., 2019; Woolf et al., 2013). According to this vision many of the inefficiencies and injustices of the current global education system can be addressed by applying AI.
To surface such discussion around what is possible fiction 1 is based loosely on a narrative published by Luckin and Holmes (2017) themselves. In their paper, they imagine a school classroom ten years into the future from the time of writing, where a teacher is working with an AI teaching assistant. Built into their fiction are the key features of their vision of AI (Luckin et al. 2016), thus emphasis is given to:
AI designed to support teachers rather than replacing them;
The monitoring of haptic data to adjust learning material to students’ emotional and physical state in real time;
The potential of AI to support learning twenty-first century skills, such as collaborative skills;
Teachers developing skills in data analysis as part of their role;
Students (and parents) as well as teachers having access to data about their learning.
While Luckin and Holmes (2017) acknowledge that the vision of AI sounds a “bit big brother” it is, as one would expect, essentially an optimistic piece in which all the key technologies they envisage are brought together to improve learning in a broad sense. The fiction developed here retains most of these elements, but reimagined for an HE context, and with a number of other changes:
Reference is also made to rooting teaching in learning science, one of the arguments for AI Luckin makes in a number of places (e.g. Luckin et al. 2016).
Students developing a long term relationship with the AI. It is often seen as a desirable aspect of providing AI as a lifelong learning partner (Woolf, et al. 2013).
Of course, the more sceptical reader may be troubled by some aspects of this vision, including the potential effects of continuously monitoring performance as a form of surveillance. The emphasis on personalization of learning through AI has been increasingly questioned (Selwyn, 2019a).
Actually, I partly picked this Uni because I knew they had AI like AIDan which teach you on principles based in learning science.
I have set tutorials with AIDan to analyse data on my performance. Jane often talks me through my learning data as well.
Some of my data goes to people in the department (like my personal tutor) to student and campus services and the library to help personalise their services.
Luckin and Holmes (2017) see AI as instantiated by sensors and cameras built into the classroom furniture. Their AI does not seem to have a physical form, though it does have a human name. But there is also a literature around educational robots: a type of social robot for learning.
The protagonist in fiction 2 describes the high level and employability skills he is learning from a sporting application of robotics. This also reminds us of how the widespread use of AI and robots in wider social contexts may be a key driver for adoption in HE.
Both fictions 1 and 2 are glossy science fictions, with a strongly futuristic feel and, as in traditional design scenarios the technology seems to be used as intended by the designer. In contrast, the third fiction is inspired by Bayne’s (2015) description of Teacherbot, a chatbot developed to support a MOOC on elearning and digital cultures. Teacherbot does not masquerade as human. Students on the course are told what it is and its interactions are clumsy enough to reveal this anyway. Yet Bayne’s (2015) argument is that it offers positive non-human affordances. Students seem to learn from it, partly by reflecting on its place in their learning. Thus fiction 3, echoing the sample transcripts between Teacherbot and real students quoted in Bayne (2015), is a fictional dialogue between a conversational agent and a group of students working on an assignment (itself on the topic of bias in AI). Criticalbot, as its name suggests, is being imagined used to teach the students to be more critical, e.g. by prompting them to think harder about how to read an academic text, raising questions about the authority of authors, and prompting discussion around quotes from a key text.
CriticalBot: Sorry. I should have typed: Blanchard, E. G. (2015). Socio-cultural imbalances in AIED research: Investigations, implications and opportunities. International Journal of Artificial Intelligence in Education, 25(2), 204–228. No one’s perfect.
As the quotation from the fiction illustrates, echoing Bayne (2015), the conversation in Fiction 2 is not necessarily smooth; misunderstandings and conflicts occur. The fiction brings into view the less compliant vision of the student who might wish to game the system, a potential problem with AI which is apparent in the literature of AWE (Hussein et al. 2019). This fiction encapsulates an important alternative potential imaginary of AI, as a simple, low-tech intervention. At the same time in being designed to promote critical thinking it can also be seen as teaching a key, high-level skill. This challenges us to ask if an AI can truly do that and how.
The AIED literature with its emphasis on the direct application of AI to learning accounts for a big block of the literature about AI in Higher Education, but not all of it. Another rather separate literature exists around the smart or intelligent campus (e.g. JISC 2018; Min-Allah and Alrashed, 2020; Dong et al., 2020). This is the application of Internet of Things and increasingly AI to the management of the campus environment. This is often oriented towards estates management, such as monitoring room usage and controlling lighting and heating. But it does also encompass support of wayfinding, attendance monitoring, and ultimately of student experience, so presents an interesting contrast to the AIEd literature.
Data driven support of wayfinding and time management;
The student also muses about the ethics of the AI. She is presented as a little ambivalent about the monitoring technologies, and as in Luckin and Holmes (2017), it is referred to in her own words as potentially “a bit big brother” (JISC 2018: 9). But ultimately she concludes that the smart campus improves her experience as a student. In this narrative, unlike in the Luckin and Holmes (2017) fiction, the AI is much more in the background and lacks a strong personality. It is a different sort of optimistic vision geared towards convenience rather than excellence. There is much less of a futuristic feel, indeed one could say that not only does the technology exist to deliver many of the services described, they are already available and in use—though perhaps not integrated within one application.
The fiction seeks to bring out more about the idea of “nudging” to change behaviours a concept often linked to AI and the ethics of which are queried by Selwyn (2019a). The issue of how AI and robots might impact the agency of the learner recurs across the first four fictions.
So far in this paper most of the focus has been on the application of AI and robotics to learning. AI also has applications in university research, but it is an area far less commonly considered than learning and teaching. Only 1% of CIOs responding to a survey of HEIs by Gartner had deployed AI for research, compared to 27% for institutional analytics and 10% for adaptive learning (Lowendahl and Williams, 2018). Some AI could be used directly in research, not just to perform analytical tasks, but to generate hypotheses to be tested (Jones et al., 2019). The “robot scientist” being tireless and able to work in a precise way could carry through many experiments and increase reproducibility (King, et al., 2009; Sparkes et al., 2010). It might have the potential to make significant discoveries independently, perhaps by simply exploiting its tirelessness to test every possible hypothesis rather than use intuition to select promising ones (Kitano, 2016).
Another direct application of AI to research is text and data mining (TDM). Given the vast rate of academic publishing there is growing need to mine published literature to offer summaries to researchers or even to develop and test hypotheses (McDonald and Kelly, 2012). Advances in translation also offer potential to make the literature in other languages more accessible, with important benefits.
Developments in publishing give us a further insight into how AI might be applied in the research domain. Publishers are investing heavily in AI (Gabriel, 2019). One probable landmark was that in 2019, Springer published the first “machine generated research book” (Schoenenberger, 2019: v): a literature review of research on Lithium-Ion batteries, written entirely automatically. This does not suggest the end of the academic author, Springer suggest, but does imply changing roles (Schoenenberger, 2019). AI is being applied to many aspects of the publication process: to identify peer reviewers (Price and Flach, 2017), to assist review by checking statistics, to summarise open peer reviews, to check for plagiarism or for the fabrication of data (Heaven, 2018), to assist copy editing, to suggest keywords and to summarise and translate text. Other tools claim to predict the future citation of articles (Thelwall, 2019). Data about academics, their patterns of collaboration and citation through scientometrics are currently based primarily on structured bibliographic data. The cutting edge is the application of text mining techniques to further analyse research methods, collaboration patterns, and so forth (Atanassova et al., 2019). This implies a potential revolution in the management and evaluation of research. It will be relevant to ask what responsible research metrics are in this context (Wilsdon, 2015).
Academic Mentor ™ is our premium meta analysis service. Drawing on historic career data from across the disciplines, it identifies potential career pathways to inform your choices in your research strategy. By identifying structural holes in research fields it enables you to position your own research within emerging research activity, so maximising your visibility and contribution. Mining data from funder strategy, the latest publications, preprints and news sources it identifies emergent interdisciplinary fields, matching your research skills and interests to the complex dynamics of the changing research landscape.
This fiction prompts questions about the nature of the researcher’s role and ultimately about what research is. At what point does the AI become a co-author, because it is making a substantive intellectual contribution to writing a research output, making a creative leap or even securing funding? Given the centrality of research to academic identity this indeed may feel even more challenging than the teaching related scenarios. This fiction also recognised the important role of EdTech companies in how AI reaches HE, partly because of the high cost of AI development. The reader is also prompted to wonder how the technology might disrupt the HE landscape if those investing in these technologies were ambitious newer institutions keen to rise in university league tables.
A very large literature around technologies in HE in general focuses on the challenges of implementing them as a change management problem. Reid (2014), for example, seeks to develop a model of the differing factors that block the smooth implementation of learning technologies in the classroom, such as problems with access to the technology, project management challenges, as well as issues around teacher identity. Echoing these arguments, Tsai et al.’s (2017, 2019) work captures why for all the hype around it, Learning Analytics have not yet found extensive practical application in HE. Given that AI requires intensive use of data, by extension we can argue that the same barriers will probably apply to AI. Specifically Tsai et al. (2017, 2019) identify barriers in terms of technical, financial and other resource demands, ethics and privacy issues, failures of leadership, a failure to involve all stakeholders (students in particular) in development, a focus on technical issues and neglect of pedagogy, insufficient staff training and a lack of evidence demonstrating the impact on learning. There are hints of similar types of challenge around the implementation of administration focussed applications (Nurshatayeva, et al., 2020) and TDM (FutureTDM, 2016).
Reflecting these thoughts, the fifth fiction is an extract from an imaginary committee meeting, in which senior university managers discuss the challenges they are facing in implementing AI. It seeks to surface issues around teacher identity, disciplinary differences and resource pressures that might shape the extensive implementation of AI in practice.
Faculty of Engineering Director: The pilot project also showed improved student satisfaction. Data also showed better student performance. Less drop outs.
Faculty of Engineering Director: The impact on employability has also been fantastic, in terms of employers starting to recognise the value of our degrees now fluency with automation is part of our graduate attributes statement.
Given the strong relation between “big data” and AI, the claimed benefits and the controversies that already exist around LA are relevant to AI too (Selwyn, 2019a). The main argument for LA is that they give teachers and learners themselves information to improve learning processes. Advocates talk of an obligation to act. LA can also be used for the administration of admissions decisions and ensuring retention. Chatbots are now being used to assist applicants through complex admissions processes or to maintain contact to ensure retention and appear to offer a cheap and effective alternative (Page and Gehlbach, 2017; Nurshatayeva et al., 2020). Gathering more data about HE also promotes public accountability.
However, data use in AI does raise many issues. The greater the dependence on data or data driven AI the greater the security issues associated with the technology. Another inevitable concern is with legality and the need to abide by appropriate privacy legislation, such as GDPR in Europe. Linked to this are clearly privacy issues, implying consent, the right to control over the use of one’s data and the right to withdraw (Fjeld et al., 2020). Yet a recent study by Jones (2020) found students knew little of how LA were being used in their institution or remembered consenting to allowing their data to be used. These would all be recognised as issues by most AI projects.
However, increasingly critiques of AI in learning centre around the datafication of education (Jarke and Breiter, 2019; Williamson and Eynon, 2020; Selwyn, 2019a; Kwet and Prinsloo, 2020). A data driven educational system has the potential to be used or experienced as a surveillance system. “What can be accomplished with data is usually a euphemism for what can be accomplished with surveillance” (Kwet and Prinsloo, 2020: 512). Not only might individual freedoms be threatened by institutions or commercial providers undertaking surveillance of student and teaching staff behaviour, there is also a chilling effect just through the fear of being watched (Kwet and Prinsloo, 2020). Students become mere data points, as surveillance becomes intensified and normalised (Manolev et al. 2019). While access to their own learning data could be empowering for students, techniques such as nudging intended to influence people without their knowledge undermine human agency (Selwyn, 2019b). Loss of human agency is one of the fears revolving around AI and robots.
Further, a key issue with AI is that although predictions can be accurate or useful it is quite unclear how these were produced. Because AI “learns” from data, even the designers do not fully understand how the results were arrived at so they are certainly hard to explain to the public. The result is a lack of transparency, and so of accountability, leading to deresponsibilisation.
Much of the current debate around big data and AI revolves around bias, created by using training data that does not represent the whole population, reinforced by the lack of diversity among designers of the systems. If data is based on existing behaviour, this is likely to reproduce existing patterns of disadvantage in society, unless AI design takes into account social context—but datafication is driven by standardisation. Focussing on technology diverts attention from the real causes of achievement gaps in social structures, it could be argued (Macgilchrist, 2019). While often promoted as a means of empowering learners and their teachers, mass personalisation of education redistributes power away from local decision making (Jarke and Breiter, 2019; Zeide, 2017). In the context of AIEd there is potential for assumptions about what should be taught to show very strong cultural bias, in the same way that critics have already argued that plagiarism detection systems impose culturally specific notions of authorship and are marketed in a way to reinforce crude ethnic stereotypes (Canzonetta and Kannan, 2016).
Datafication also produces performativity: the tendency of institutions (and teachers and students) to shift their behaviour towards doing what scores well against the metric, in a league table mentality. Yet what is measured is often a proxy of learning or reductive of what learning in its full sense is, critics argue (Selwyn, 2019b). The potential impact is to turn HE further into a marketplace (Williamson, 2019). It is evident that AI developments are often partly a marketing exercise (Lacity, 2017). Edtech companies play a dominant role in developing AI (Williamson and Eynon, 2020). Selwyn (2019a) worries that those running education will be seduced by glittering promises of techno-solutionism, when the technology does not really work. The UK government has invested heavily in gathering more data about HE in order to promote the reform of HE in the direction of marketisation and student choice (Williamson and Eynon, 2020). Learning data could also increasingly itself become a commodity, further reinforcing the commercialisation of HE.
Thus fiction 6 explores the potential to gather data about learning on a huge scale, make predictions based on it and take actions via conveying information to humans or through chatbots. In the fiction the protagonist explains an imaginary institutional level system that is making data driven decisions about applicants and current students.
Then here we monitor live progress of current students within their courses. We can dip down into attendance, learning environment use, library use, and of course module level performance and satisfaction plus the extra-curricula data. Really low-level stuff some of it. It’s pretty much all there, monitored in real time. We are really hot on transition detection and monitoring. The chatbots are used just to check in on students, see they are ok, nudge things along, gather more data. Sometimes you just stop and look at it ticking away and think “wow!”. That all gets crunched by the system. All the time we feed the predictives down into departmental dashboards, where they pick up the intervention work. Individual teaching staff have access via smart speaker. Meanwhile, we monitor the trend lines up here.
In the fiction the benefits in terms of being able to monitor and address attainment gaps is emphasised. The protagonist’s description of projects that are being worked on suggests competing drivers behind such developments including meeting government targets, cost saving and the potential to make money by reselling educational data.
A further dimension to the controversy around AI is to consider its environmental cost and the societal impact of the wider infrastructures needed to support AI. Brevini (2020) points out that a common AI training model in linguistics can create the equivalent of five times the lifetime emissions of an average US car. This foregrounds the often unremarked environmental impact of big data and AI. It also prompts us to ask questions about the infrastructure required for AI. Crawford and Joler’s (2018) brilliant Anatomy of an AI system reveals that making possible the functioning of a physically rather unassuming AI like Amazon echo, is a vast global infrastructure based on mass human labour, complex logistic chains and polluting industry.
The first part of fiction 8 describes a personal assistant based on voice recognition, like Siri, which answers all sorts of administrative questions.The protagonist expresses some unease with how the system works, reflecting the points made by Rummel et al. (2016) about the failure of systems if despite their potential sophistication they lack nuance and flexibility in their application. There is also a sense of alienation (Griffiths, 2015). The second part of the fiction extends this sense of unease to a wider perspective on the usually invisible, but very material infrastructure which AI requires, as captured in Crawford and Joler (2018). In addition, imagery is drawn from Maughan’s (2016) work where he travels backwards up the supply chain for consumer electronics from the surreal landscape of hi-tech docks then visiting different types of factories and ending up visiting a huge polluted lake created by mining operations for rare earth elements in China. This perspective queries all the other fictions with their focus on using technologies or even campus infrastructure by widening the vision to encompass the global infrastructures that are required to make AI possible.
The vast effort of global logistics to bring together countless components to build the devices through which we interact with AI. Lorries queuing at the container port as another ship comes in to dock.
As we have seen each of the fictions seeks to open up different positive visions or dimensions of debate around AI (summarised in Table 2 below). All implicitly ask questions about the nature of human agency in relationship to AI systems and robots, be that through empowerment through access to learning data (fiction 1), their power to play against the system (Fiction 3) or the hidden effects of nudging (Fiction 4) and the reinforcements of social inequalities. Many raise questions about the changing role of staff or the skills required to operate in this environment. They are written in a way seeking to avoid taking sides, e.g. not to always undercut a utopian view or simply present a dark dystopia. Each contains elements that might be inspirational or a cause of controversy. Specifically, they can be read together to suggest tensions between different possible futures. In particular fictions 7 and 8 and the commercial aspects implied by the presentation of fiction 5, reveal aspects of AI largely invisible in the glossy strongly positive images in fictions 1 and 2, or the deceptive mundanity of fiction 3. It is also anticipated that the fictions will be read “against the grain” by readers wishing to question what the future is likely to be or should be like. This is one of the affordances of them being fictions.
The most important contribution of the paper was the wide-ranging narrative literature review emphasising the social, ethical, pedagogic and management issues of automation through AI and robots on HE as a whole. On the basis of the understanding gained from the literature review a secondary contribution was the development of a collection of eight accessible, repurposable design fictions that prompt debate about the potential role of AI and robots in HE. This prompts us to notice common challenges, such as around commodification and the changing role of data. It encompasses work written by developers, by those with more visionary views, those who see the challenges as primarily pragmatic and those coming from much more critical perspectives.
The fictions are intended to be used to explore staff and student responses through data collection using the fictions to elicit views. The fictions could also be used in teaching to prompt debate among students, perhaps setting them the task to write new fictions (Rapp, 2020). Students of education could use them to explore the potential impact of AI on educational institutions and to discuss the role of technologies in educational change more generally. The fictions could be used in teaching students of computer science, data science, HCI and information systems in courses about computer ethics, social responsibility and sustainable computing—as well as those directly dealing with AI. They could also be used in Media Studies and Communications, e.g. to compare them with other future imaginaries in science fiction or to design multimedia creations inspired by such fictions. They might also be used for management studies as a case study of strategizing around AI in a particular industry.
While there is an advantage in seeking to encompass the issues within a small collection of engaging fictions that in total run to less than 5000 words, it must be acknowledged that not every issue is reflected. For example, what is not included is the different ways that AI and robots might be used in teaching different disciplines, such as languages, computer science or history. The many ways that robots might be used in background functions or to play the role themselves of learner also requires further exploration. Most of the fictions were located in a fairly near future, but there is also potential to develop much more futuristic fictions. These gaps leave room for the development of more fictions.
Data from the project is available from the University of Sheffield repository, ORDA. https://doi.org/10.35542/osf.io/s2jc8.
Atanassova, I., Bertin, M., & Mayr, P. (2019). Editorial: mining scientific papers: NLP-enhanced bibliometrics. Frontiers in Research Metrics and Analytics. https://doi.org/10.3389/frma.2019.00002.
Badampudi, D., Wohlin, C., & Petersen, K. (2015). Experiences from using snowballing and database searches in systematic literature studies. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (pp. 1–10).
Baker, T., Smith, L. and Anissa, N. (2019). Educ-AI-tion Rebooted? Exploring the future of artificial intelligence in schools and colleges. NESTA.  https://www.nesta.org.uk/report/education-rebooted/.
Bates, T., Cobo, C., Mariño, O., & Wheeler, S. (2020). Can artificial intelligence transform higher education? International Journal of Educational Technology in Higher Education. https://doi.org/10.1186/s41239-020-00218-x.
Blanchard, E. G. (2015). Socio-cultural imbalances in AIED research: Investigations, implications and opportunities. International Journal of Artificial Intelligence in Education, 25(2), 204–228.
Brevini, B. (2020). Black boxes, not green: Mythologizing artificial intelligence and omitting the environment. Big Data & Society, 7(2), 2053951720935141.
Clay, J. (2018). The challenge of the intelligent library. Keynote at What does your eResources data really tell you? 27th February, CILIP.
Crawford, K., & Joler, V. (2018) Anatomy of an AI system, https://anatomyof.ai/.
Fjeld, J., Achten, N., Hilligoss, H., Nagy, A., & Srikumar, M. (2020). Principled artificial intelligence: Mapping consensus in ethical and rights-based approaches to principles for AI. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.3518482.
Følstad, A., Skjuve, M., & Brandtzaeg, P. (2019). Different chatbots for different purposes: Towards a typology of chatbots to understand interaction design. Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). 11551 LNCS, pp. 145–156. Springer Verlag.
Gabriel, A. (2019). Artificial intelligence in scholarly communications: An elsevier case study. Information Services & Use, 39(4), 319–333.
Heaven, D. (2018). The age of AI peer reviews. Nature, 563, 609–610.
Hockly, N. (2019). Automated writing evaluation. ELT Journal, 73(1), 82–88.
Holmes, W., Bialik, M. and Fadel, C. (2019). Artificial Intelligence in Education. The center for curriculum redesign. Boston, MA.
Jarke, J., & Breiter, A. (2019). Editorial: the datafication of education. Learning, Media and Technology, 44(1), 1–6.
JISC. (2019). The intelligent campus guide. Using data to make smarter use of your university or college estate. https://www.jisc.ac.uk/rd/projects/intelligent-campus.
Jones, K., Asher, A., Goben, A., Perry, M., Salo, D., Briney, K., & Robertshaw, M. (2020). “We’re being tracked at all times”: Student perspectives of their privacy in relation to learning analytics in higher education. Journal of the Association for Information Science and Technology. https://doi.org/10.1002/asi.24358.
King, R. D., Rowland, J., Oliver, S. G., Young, M., Aubrey, W., Byrne, E., et al. (2009). The automation of science. Science, 324(5923), 85–89.
Kitano, H. (2016). Artificial intelligence to win the nobel prize and beyond: Creating the engine for scientific discovery. AI Magazine, 37(1), 39–49.
Lacity, M., Scheepers, R., Willcocks, L. & Craig, A. (2017). Reimagining the University at Deakin: An IBM Watson Automation Journey. The Outsourcing Unit Working Research Paper Series.
Lowendahl, J.-M., & Williams, K. (2018). 5 Best Practices for Artificial Intelligence in Higher Education. Gartner. Research note.
Luckin, R. (2017). Towards artificial intelligence-based assessment systems. Nature Human Behaviour, 1(3), 1–3.
Luckin, R., Holmes, W., Griffiths, M., & Pearson, L. (2016). Intelligence unleashed an argument for AI in Education. Pearson. https://www.pearson.com/content/dam/one-dot-com/one-dot-com/global/Files/about-pearson/innovation/open-ideas/Intelligence-Unleashed-v15-Web.pdf.
Macgilchrist, F. (2019). Cruel optimism in edtech: When the digital data practices of educational technology providers inadvertently hinder educational equity. Learning, Media and Technology, 44(1), 77–86.
Manolev, J., Sullivan, A., & Slee, R. (2019). The datafication of discipline: ClassDojo, surveillance and a performative classroom culture. Learning, Media and Technology, 44(1), 36–51.
Nurshatayeva, A., Page, L. C., White, C. C., & Gehlbach, H. (2020). Proactive student support using artificially intelligent conversational chatbots: The importance of targeting the technology. EdWorking paper, Annenberg University https://www.edworkingpapers.com/sites/default/files/ai20-208.pdf.
Pinkwart, N. (2016). Another 25 years of AIED? Challenges and opportunities for intelligent educational technologies of the future. International journal of artificial intelligence in education, 26(2), 771–783.
Price, S., & Flach, P. (2017). Computational support for academic peer review: A perspective from artificial intelligence. Communications of the ACM, 60(3), 70–79.
Rapp, A. (2020). Design fictions for learning: A method for supporting students in reflecting on technology in human–computer interaction courses. Computers & Education, 145, 103725.
Renz, A., & Hilbig, R. (2020). Prerequisites for artificial intelligence in further education: Identification of drivers, barriers, and business models of educational technology companies. International Journal of Educational Technology in Higher Education. https://doi.org/10.1186/s41239-020-00193-3.
Roll, I., & Wylie, R. (2016). Evolution and Revolution in Artificial Intelligence in Education. International Journal of Artificial Intelligence in Education, 26(2), 582–599.
Rummel, N., Walker, E., & Aleven, V. (2016). Different futures of adaptive collaborative learning support. International Journal of Artificial Intelligence in Education, 26(2), 784–795.
Selwyn, N. (2019a). Should robots replace teachers? AI and the future of education. New Jersey: Wiley.
Selwyn, N., Pangrazio, L., Nemorin, S., & Perrotta, C. (2020). What might the school of 2030 be like? An exercise in social science fiction. Learning, Media and Technology, 45(1), 90–106.
Thelwall, M. (2019). Artificial intelligence, automation and peer review. Bristol: JISC.
Tsai, Y. S., Poquet, O., Gašević, D., Dawson, S., & Pardo, A. (2019). Complexity leadership in learning analytics: Drivers, challenges and opportunities. British Journal of Educational Technology, 50(6), 2839–2854.
Williamson, B. (2019). Policy networks, performance metrics and platform markets: Charting the expanding data infrastructure of higher education. British Journal of Educational Technology, 50(6), 2794–2809.
Williamson, B., & Eynon, R. (2020). Historical threads, missing links, and future directions in AI in education. Learning, Media and Technology. https://doi.org/10.1080/17439884.2020.1798995.
Wilsdon, J. (2015). The metric tide: Independent review of the role of metrics in research assessment and management. Sage.
Winkler, R. & Söllner, M. (2018). Unleashing the potential of chatbots in education: A state-of-the-art analysis. In: Academy of Management Annual Meeting (AOM). Chicago, USA.
Woolf, B. P., Lane, H. C., Chaudhri, V. K., & Kolodner, J. L. (2013). AI grand challenges for education. AI Magazine, 34(4), 66–84.
Zawacki-Richter, O., Marín, V., Bond, M., & Gouverneur, F. (2019). Systematic review of research on artificial intelligence applications in higher education—where are the educators? International Journal of Educational Technology in Higher Education. https://doi.org/10.1186/s41239-019-0171-0.
Zeide, E. (2017). The structural consequences of big data-driven education. Big Data, 5(2), 164–172.
Cox, A.M. Exploring the impact of Artificial Intelligence and robots on higher education through literature-based design fictions.
The Impact Of Artificial Intelligence On Environment And
Citation: Dr. Ziaul Islam et al. (2024) The Impact Of Artificial Intelligence On Environment And Sustainable Development In India,
The integration of Artificial Intelligence (AI) into various sectors has reshaped
amidst rapid technological advancement, understanding the implications of AI on
multifaceted impact of AI on environmental sustainability in India, delving into
aims to provide comprehensive insights into how AI can be leveraged to address
emergence of Artificial Intelligence (AI) presents both opportunities and challenges for India's environmental
The intention of this research article is to thoroughly investigate the diverse usage of AI in environmental
conservation. We intend to explore how AI is utilized in various aspects such as remote sensing, wildlife
and ethical considerations that accompany the deployment of AI, thereby laying the groundwork for
Artificial Intelligence (AI) is increasingly acknowledged as a potent instrument for realizing the Sustainable
Development Goals (SDGs) set forth by the United Nations. Across various domains, AI applications are
development. For instance, in tackling poverty (SDG 1), AI helps identify patterns in impoverished areas,
communities.3 Similarly, in the quest for zero hunger (SDG 2), AI aids in optimizing agricultural practices,
predicting food shortages, and streamlining food distribution networks to reduce waste.4 Moreover, AI
(SDG 4) benefits from AI-powered adaptive learning platforms, offering personalized learning experiences and
addressing individual student needs effectively.6 Gender equality (SDG 5) efforts are supported by AI in
AI assists in managing water resources (SDG 6)8, optimizing energy consumption (SDG 7)9, fostering economic
Reducing inequalities (SDG 10) is facilitated by AI-driven analyses of socioeconomic data, informing policies
benefit from AI technologies in optimizing urban systems, enhancing public services, and improving resource
efficiency13. Sustainable production and consumption (SDG 12) are advanced through AI's optimization of
resource usage, waste reduction, and supply chain transparency14. Climate action (SDG 13) efforts leverage AI
planning.15 Biodiversity conservation (SDG 14) and land preservation16 (SDG 15) are supported by AI-enabled
habitat monitoring and enforcement against illegal activities. Furthermore, AI contributes to promoting peace,
resolution strategies.17 Lastly, partnerships for the goals (SDG 17) are fostered by AI-driven data insights,
potential of AI in advancing sustainable development and building a more equitable and resilient future.
However, it's essential to address challenges such as algorithmic bias and privacy concerns to ensure that AI
AI APPLICATIONS ON ENVIRONMENTAL CONSERVATION & SUSTAINABLE
1. Utilizing AI for Satellite Data Analysis in Environmental Monitoring
However, processing vast data volumes requires advanced capabilities. AI, particularly convolutional neural
2. AI Applications in Timely Detection of Environmental Changes
AI-powered remote sensing tools facilitate near-real-time monitoring of environmental indicators. By
analyzing changes in vegetation cover and land use, AI-driven systems promptly identify illegal logging and
1. AI-Driven Monitoring Systems for Endangered Species Tracking
wildlife monitoring techniques may be laborious, costly, and restricted in range. AI has transformed wildlife
recognizing individual creatures, gauging population magnitudes, and monitoring migratory routes, AI
2. AI Applications in Combating Illegal hunting and illicit trafficking of wildlife
habitats. AI technologies, including machine vision and natural language processing, analyze vast online
content to identify and combat illegal wildlife trade networks. Moreover, AI-driven surveillance systems
1. AI Models for Enhanced Climate Modeling and Extreme Weather Prediction
economies. AI-powered climate models enhance our understanding of complex climate processes and improve
the accuracy of long-term climate predictions. Additionally, AI algorithms identify trends and patterns in
historical climate data, enabling the projection of future scenarios and informing policymakers about potential
2. AI Applications in Climate Change Adaptation and Mitigation
AI's analytical capabilities empower decision-makers to formulate targeted climate change adaptation and
resilient infrastructure, AI-guided solutions play a pivotal role in enhancing climate resilience at both local and
global levels. Furthermore, AI technologies aid in developing efficient renewable energy systems, facilitating a
1. AI-driven solutions for optimizing energy consumption and transportation
of AI for traffic management, public transportation optimization, waste segregation, and energy-efficient
The rise of AI-driven waste management systems plays a significant role in mitigating the environmental
footprint of urban environments. These systems utilize AI-powered algorithms to streamline waste collection
routes and sorting procedures, AI not only improves operational effectiveness but also minimizes
environmental impact. Moreover, AI-driven urban planning models facilitate the development of sustainable
and resilient cities. These models take into account various factors such as the incorporation of green spaces,
provision of public amenities, and optimization of infrastructure, thereby fostering the creation of livable and
3. AI's role in improving the efficiency of renewable energy systems
and efficiency enhancements. Artificial Intelligence (AI) assumes a pivotal role in streamlining energy usage,
enhancing grid supervision, and expediting the shift towards renewable energy sources. For instance, AIpowered predictive analytics can enhance the efficiency of renewable energy systems, optimize power
distribution networks, and enable smart energy management solutions. The deployment of AI-driven
4. AI applications in optimizing agricultural practices and minimizing environmental impact :
challenges such as climate change, water scarcity, and soil degradation. AI-driven innovations in precision
productivity, optimize resource use, and ensure food security. By leveraging AI technologies such as satellite
imagery analysis, drones, and sensor-based monitoring systems, farmers in India can utilize data-driven
to the selection of SmartTerra, a startup specializing in urban water management, to develop an AI-powered
operational intelligence platform. This platform aims to transition water utility operations towards predictive
and efficiency-driven models, addressing challenges such as water distribution losses and network health. The
pilot project, implemented in central Bengaluru's D1A zone, involved analyzing extensive data to identify areas
for improvement in revenue recovery and distribution efficiency. SmartTerra's AI-driven platform seeks to
Scientists at IIT Kharagpur have created an artificial intelligence-driven forecasting system to identify arsenic
extent and mechanisms. Leveraging AI, the researchers successfully predicted groundwater arsenic
to provide safe drinking water to every household by 2024. This innovative use of AI in geoscience lays
using traditional methods despite a 2017 directive mandating conversion to cleaner technology. Leveraging
space technology and AI, the platform identifies brick kiln hotspots, simplifying regulatory oversight in Bihar.
Google's Flood Prediction Initiative employs artificial intelligence to provide precise, up-to-date flood
ML expertise for flood forecasting. By integrating AI and physics-based modeling, Google develops precise and
scalable inundation models, enhancing forecasting accuracy and lead time. Collaborating with the Central
physics with machine learning techniques, improving accuracy by 3% compared to traditional models. This
Despite its transformative capacity, the extensive uptake of AI in India presents numerous hurdles and ethical
deliberations that necessitate attention.Alternatives encompass concerns related to data privacy, algorithmic
bias, job displacement, and environmental sustainability. The energy-energy-intensive nature of AI
long-term sustainability of AI technologies. Moreover, the ethical implications of autonomous systems,
algorithmic decision-making, and AI-driven surveillance require careful scrutiny to ensure that technological
1. Tackling Ethical Concerns in AI Applications for Conservation
The increasing integration of AI in environmental conservation prompts ethical inquiries regarding data usage,
storage, and utilization of data in AI-driven initiatives.
2. Counteracting Bias in Data and Algorithms for Equitable Outcomes
AI algorithms inherently reflect the data they are trained on, rendering them susceptible to biases. In
environmental conservation, biased data can result in unjust decision-making and worsen existing
environmental disparities.31 It is crucial to recognize and alleviate prejudices in AI models to advance just and
Data Availability and Quality
1. Overcoming Challenges in Accessing and Processing Environmental Data
The effectiveness of AI in environmental conservation heavily relies on the availability and quality of
environmental data. However, issues related to data accessibility and interoperability pose significant hurdles,
particularly in remote and under-resourced areas.32 Collaborative endeavors are essential to ensure data
sharing and open access, facilitating broader AI applications for conservation efforts.
2. Enhancing Data Collection and Sharing Strategies
To address data-related obstacles, partnerships between governments, non-governmental organizations, and
private entities are essential. Investment in innovative data collection approaches, such as citizen science
1. Establishing Regulatory Frameworks for Responsible AI Deployment in Environmental
The rapid advancement of AI has surpassed the establishment of comprehensive regulatory frameworks.
Policymakers must proactively address the ethical, social, and environmental ramifications of AI in
conservation. By building upon existing privacy and data protection laws, specific regulations tailored to AI
2. Resolving Legal and Policy Challenges for AI-driven Conservation Initiatives
data sharing, thereby advancing global endeavors in biodiversity preservation and climate change mitigation.
The impact of Artificial Intelligence on the environment and sustainable development in India is profound and
multifaceted. While AI offers unprecedented opportunities to address environmental challenges and foster
full potential of AI for environmental sustainability, India needs to adopt a holistic approach that integrates
leveraging AI-driven solutions in sectors such as environmental monitoring, energy efficiency, agriculture, and
society to guarantee that AI acts as a catalyst for beneficial transformation while maintaining environmental
can emerge as a global leader in harnessing the transformative power of AI for environmental sustainability
In conclusion, this article highlights the significant impact of Artificial Intelligence on India's environment and
sustainable development. Through a thorough examination of AI's contributions across various sectors aligned
with the Sustainable Development Goals, it becomes evident that AI holds immense potential to drive positive
change and foster inclusive growth in the Indian context. By harnessing the capabilities of AI technologies,
advance towards a more prosperous and resilient future for all its citizens. However, while acknowledging AI's
AI deployment in India is ethical, equitable, and aligned with the principles of sustainability and social justice.
1. Pedro F, Subosa M, Rivas A, Valverde P. Artificial intelligence in education: Challenges and opportunities
3. Mhlanga D. FinTech and Artificial Intelligence in Addressing Poverty, Towards Sustainable Development.
InFinTech and Artificial Intelligence for Sustainable Development: The Role of Smart Technologies in
5. Kasula BY, Whig P. AI-Driven Machine Learning Solutions for Sustainable Development in Healthcare—
Development Through AI, ML and IoT. 2023 Dec 6;2(2):1-7.
6. Rane N, Choudhary S, Rane J. Education 4.0 and 5.0: Integrating Artificial Intelligence (AI) for
8. Yeşim AH, GÜLTAŞ AP, KÖKSAL MS. ARTIFICIAL INTELLIGENCE MODEL USAGE BASED ON DATA
9. Ahmad T, Zhang D, Huang C, Zhang H, Dai N, Song Y, Chen H. Artificial intelligence in sustainable energy
10. Sampene AK, Agyeman FO, Robert B, Wiredu J. Artificial intelligence as a path way to Africa's
transformations. Artificial Intelligence. 2022 Jan;9(1).
11. Mhlanga D. Artificial intelligence in the industry 4.0, and its impact on poverty, innovation, infrastructure
12. Bachmann N, Tripathi S, Brunner M, Jodlbauer H. The contribution of data-driven technologies in
13. Yigitcanlar T, Mehmood R, Corchado JM. Green artificial intelligence: Towards an efficient, sustainable
and equitable technology for smart cities and futures. Sustainability. 2021 Aug 10;13(16):8952.
F, Guevara Z. Deploying artificial intelligence for climate change adaptation. Technological Forecasting
16. Isabelle DA, Westerlund M. A review and categorization of artificial intelligence-based opportunities in
18. Di Vaio A, Palladino R, Hassan R, Escobar O. Artificial intelligence and business models in the sustainable
19. Li C, Hsu NC, Tsay SC. A study on the potential applications of satellite data in air quality monitoring and
forecasting. Atmospheric Environment. 2011 Jul 1;45(22):3663-75.
20. Dattamajumdar A. An early warning AI-powered portable system to reduce workload and inspect
21. Chisom ON, Biu PW, Umoh AA, Obaedo BO, Adegbite AO, Abatan A. Reviewing the role of AI in
environmental monitoring and conservation: A data-driven revolution for our planet. World Journal of
22. Nandutu I, Atemkeng M, Okouma P. Integrating AI ethics in wildlife conservation AI systems in South
Africa: A review, challenges, and future research agenda. AI & SOCIETY. 2023 Feb 1:1-3.
23. Torky M, Gad I, Darwish A, Hassanien AE. artificial intelligence for predicting floods: A climatic change
phenomenon. InThe Power of Data: Driving Climate Change with Data Science and Artificial Intelligence
F, Guevara Z. Deploying artificial intelligence for climate change adaptation. Technological Forecasting
25. Sethy A, Shaik N, Saravanan V, Karthika S. 10 The future with AI and AI in action. Toward Artificial
General Intelligence: Deep Learning, Neural Networks, Generative AI. 2023 Nov 6:213.
27. Franki V, Majnarić D, Višković A. A comprehensive review of artificial intelligence (AI) companies in the
28. Shaikh TA, Rasool T, Lone FR. Towards leveraging the role of machine learning and artificial intelligence
29. Google.com. [cited 2024 Apr 2]. Available from: https://indiaai.gov.in/article/five-use-cases-to-showthat-ai-is-promoting-sustainable-development-in-india
30. Mantelero A. Beyond data: Human rights, ethical and social impact assessment in AI. Springer Nature;
31. Scatiggio V. Tackling the issue of bias in artificial intelligence to design AI-driven fair and inclusive service
systems. How human biases are breaching into AI algorithms, with severe impacts on individuals and
32. Kavetski D, Kuczera G, Franks SW. Calibration of conceptual hydrological models revisited: 1.
33. Raihan A. Artificial intelligence and machine learning applications in forest management and biodiversity
34. Narayanan S. Developing Responsible AI Business Model. InResponsible Artificial Intelligence:
35. Marda V. Artificial intelligence policy in India: a framework for engaging the limits of data-driven
Foundation models have transformed artificial intelligence. The growth trajectory of robotics foundation models is accelerating rapidly thanks to access to large, highly diverse, production-setting robotic data. As a result, Covariant has invested in the next generation of AI technologies such as NVIDIA A100 Tensor Core and H100 Tensor Core GPUs for training and RTX A5000 GPUs for inference to increase compute power— enabling unprecedented levels of scale, intelligence, and adaptability for our customers.
While the idea of artificial intelligence has existed since 1956, it wasn’t until 2012 that we saw a major inflection point. That’s when AlexNet, a pioneering convolutional neural network (CNN), opened the door for modern AI.
Powered by deep learning-based neural networks, it became possible to train AI models to perform very specific tasks like natural language processing (NLP), image recognition, and language translation.
The next significant breakthrough in modern AI came with the advent of GPT, or Generative Pre-trained Transformers. Leveraging vast amounts of data from the internet, the core technology of GPTs has enabled AI models to be more generalized.
Instead of having separate models for specific tasks such as NLP and image recognition, GPT-based AI can perform a wide variety of tasks using a single foundation model.
Foundation models are neural networks “pre-trained” on massive amounts of data without specific use cases in mind. As that generalized model is trained on a wider set of tasks, performance on each specific task gets better, because of ‘transfer learning’.
Foundation models have transformed AI in the digital world — powering large language models (LLMs) such as ChatGPT and DALL-E. We’ve seen foundation models enable these applications to understand and react to the most unusual situations with human-like dexterity.
The impact of foundation models will go far beyond text and image generation — and into the physical world. Many believe that foundation models will one day be the basis of all AI-powered software applications.
But when it comes to applications in the physical world, like robotics, these foundation models have, for good reason, taken a little longer to build.
In 2017, Pieter Abbeel, Rocky Duan, Tianhao Zhang, and I co-founded Covariant to build the first foundation model for robotics. Previously, we had pioneered robot learning, deep reinforcement learning, and deep generative models at OpenAI and UC Berkeley.
There had been some promising academic research in AI-powered robotics, but we felt there was a significant gap when it came to applying these advancements to real-world applications, such as robotic picking in warehouses.
When thinking about applications in the physical world, why did we start with warehouses? It was because these are the ideal environments for AI models — many have hundreds of thousands or even millions of different stock-keeping units (SKUs) flowing through at any given moment.
One key factor that has enabled the success of generative AI in the digital world is a foundation model trained on a tremendous amount of internet-scale data.
However, a comparable dataset did not previously exist in the physical world to train a robotics foundation model. That dataset had to be built from the ground up — composed of vast amounts of “warehouse-scale” real-world data and synthetic data.
So how did we build this dataset in a relatively short time? Covariant’s unique application of fleet learning enables hundreds of connected robots across 4 different continents to share live data and learnings across the entire fleet.
This real-world data has extremely high fidelity and surfaces new unknown factors that researchers would not have been able to imagine. Added to this is synthetic data that provides infinite variations of known factors. This data is multimodal, including images, depth maps, robot trajectories, and time-series suction readings.
Covariant’s robotics foundation model relies on this mix of data. General image data, paired with text data, is used to help the model learn a foundational semantic understanding of the visual world. Real-world warehouse production data, augmented with simulation data, is used to refine its understanding of specific tasks needed in warehouse operations, such as object identification, 3D understanding, grasp prediction, and place prediction.
One key factor that has enabled the success of generative AI in the digital world is a foundation model trained on a tremendous amount of internet-scale data.
However, a comparable dataset did not previously exist in the physical world to train a robotics foundation model. That dataset had to be built from the ground up — composed of vast amounts of “warehouse-scale” real-world data and synthetic data.
So how did we build this dataset in a relatively short time? Covariant’s unique application of fleet learning enables hundreds of connected robots across 4 different continents to share live data and learnings across the entire fleet.
This real-world data has extremely high fidelity and surfaces new unknown factors that researchers would not have been able to imagine. Added to this is synthetic data that provides infinite variations of known factors. This data is multimodal, including images, depth maps, robot trajectories, and time-series suction readings.
Covariant’s robotics foundation model relies on this mix of data. General image data, paired with text data, is used to help the model learn a foundational semantic understanding of the visual world. Real-world warehouse production data, augmented with simulation data, is used to refine its understanding of specific tasks needed in warehouse operations, such as object identification, 3D understanding, grasp prediction, and place prediction.
As the amount of data grows and model complexity increases, Covariant has invested in the next generation of AI technologies to increase scalability and compute power. At the core of our compute power are NVIDIA A100 Tensor Core and H100 Tensor Core GPUs for training and RTX A5000 GPUs for inference.
With access to NVIDIA GPUs, Covariant’s world-class AI researchers and engineers can run hundreds of computing jobs simultaneously, instead of just a handful.
Covariant’s current robotics foundation model is unparalleled in terms of autonomy (level of reliability) and generality (breadth of supported hardware and use cases), and we’re continuing to further expand its reliability thanks to the unique data of (rare) long-tail errors we collect in production.
Robotics is a separate entity in Artificial Intelligence that helps study the creation of intelligent robots or machines. Robotics combines electrical engineering, mechanical engineering and computer science & engineering as they have mechanical construction, electrical component and programmed with programming language. Although, Robotics and Artificial Intelligence both have different objectives and applications, but most people treat robotics as a subset of Artificial Intelligence (AI). Robot machines look very similar to humans, and also, they can perform like humans, if enabled with AI.
In earlier days, robotic applications were very limited, but now they have become smarter and more efficient by combining with Artificial Intelligence. AI has played a crucial role in the industrial sector by replacing humans in terms of productivity and quality. In this article, 'Robotics and Artificial Intelligence, we will discuss Robots & Artificial Intelligence and their various applications, advantages, differences, etc. Let's start with the definition of Artificial Intelligence (AI) and Robots.
Artificial Intelligence is defined as the branch of Computer Science & Engineering, which deals with creating intelligent machines that perform like humans. Artificial Intelligence helps to enable machines to sense, comprehend, act and learn human like activities. There are mainly 4 types of Artificial Intelligence: reactive machines, limited memory, theory of mind, and self-awareness.
A robot is a machine that looks like a human, and is capable of performing out of box actions and replicating certain human movements automatically by means of commands given to it using programming. Examples: Drug Compounding Robot, Automotive Industry Robots, Order Picking Robots, Industrial Floor Scrubbers and Sage Automation Gantry Robots, etc.
Robots can also see, and this is possible by one of the popular Artificial Intelligence technologies named Computer vision. Computer Vision plays a crucial role in all industries like health, entertainment, medical, military, mining, etc.
Computer Vision is an important domain of Artificial Intelligence that helps in extracting meaningful information from images, videos and visual inputs and take action accordingly.
NLP (Natural Languages Processing) can be used to give voice commands to AI robots. It creates a strong human-robot interaction. NLP is a specific area of Artificial Intelligence that enables the communication between humans and robots. Through the NLP technique, the robot can understand and reproduce human language. Some robots are equipped with NLP so that we can't differentiate between humans and robots.
Similarly, in the health care sector, robots powered by Natural Language Processing may help physicians to observe the decease details and automatically fill in EHR. Besides recognizing human language, it can learn common uses, such as learn the accent, and predict how humans speak.
Edge computing in robots is defined as a service provider of robot integration, testing, design and simulation. Edge computing in robotics provides better data management, lower connectivity cost, better security practices, more reliable and uninterrupted connection.
For example, the deployment of an airbag in a car is a complex event based on the data from multiple sensors in real-time. This idea is used in Robotics, for example, Event-Processing in Autonomous Robot Programming.
Reinforcement learning is a feedback-based learning method in machine learning that enables an AI agent to learn and explore the environment, perform actions and learn automatically from experience or feedback for each action. Further, it is also having feature of autonomously learn to behave optimally through hit-and-trail action while interacting with the environment. It is primarily used to develop the sequence of decisions and achieve the goals in uncertain and potentially complex environment. In robotics, robots explore the environment and learn about it through hit and trial. For each action, he gets rewarded (positive or negative). Reinforcement learning provides Robotics with a framework to design and simulate sophisticated and hard-to-engineer behaviours.
Artificial intelligent robots connect AI with robotics. AI robots are controlled by AI programs and use different AI technologies, such as Machine learning, computer vision, RL learning, etc. Usually, most robots are not AI robots, these robots are programmed to perform repetitive series of movements, and they don't need any AI to perform their task. However, these robots are limited in functionality.
AI algorithms are necessary when you want to allow the robot to perform more complex tasks.
A warehousing robot might use a path-finding algorithm to navigate around the warehouse. A drone might use autonomous navigation to return home when it is about to run out of battery. A self-driving car might use a combination of AI algorithms to detect and avoid potential hazards on the road. All these are the examples of artificially intelligent robots.
Here is the difference between Artificial Intelligence and Robots:
We provides tutorials and interview questions of all technology like java tutorial, android, java frameworks
Technology helps people work faster, better, and more efficiently. However, having and operating a machine that can perform certain automated tasks is not enough anymore. We want it to be able to see, perceive, and think just like we do. Now we need robotic assistants that can detect and identify objects, analyze their context, make autonomous decisions, and perform physical actions based on these. And what used to be sci-fi just half a century ago is our new reality today due to AI in Robotics.
Similar to how the introduction of assembly lines contributed to the Industrial Revolution, the collaboration of Robotics and AI is now disrupting business operations. Able to process visual and audio data, understand natural language, and make decisions in real time, robots help increase business productivity, reduce costs, eliminate the human factor, and boost workplace safety.
In this article, we will discuss how AI works for Robotics, which industries benefit from the application of AI in Robotics today, and what challenges and opportunities are for the technology. We will also look at some examples of AI in Robotics and see how Waverley works on such projects.
There can be some misconceptions that anything that is AI-powered is a robot or that all robots are smart (i.e. AI-powered). In fact, any computer system can make use of AI provided it has enough computing power and is running the necessary AI algorithms and models to complete “intelligent” or “human” tasks, such as processing visual data, understanding natural language, analytical thinking, decision making, and more. On the other hand, robots do not necessarily need AI to operate – they can be pre-programmed for certain repetitive tasks using other kinds of algorithms and calculations or be manipulated by an operator.
Thus, Artificial Intelligence is the branch of computer science that focuses on how machines can be taught and learn to perform complex intellectual tasks, including perception, human language processing, reasoning, decision-making, and even emotional intelligence.
With AI application in Robotics, we come to enjoy the multitude of autonomous smart machines that can help humans, or substitute them, in performing repetitive, physically demanding, or dangerous tasks. The most common example of AI in Robotics could be AI-powered robotic vacuum cleaners. Unlike their less advanced counterparts, they are furnished with cameras that allow the smart robotic system to detect and measure distance to objects near it in real time to avoid obstacles.
Now, let’s take a look at how exactly AI technologies can work for robotics, making them truly autonomous and smart.
First of all, for robots to work with AI, they need to be equipped with hardware with plenty of computing power to handle AI workloads. Depending on the robot’s design and measurements and whether it will be handling general-purpose or specific-purpose workloads, computing can be done onboard or in the cloud. With on-board computing, real-time data processing can be done with practically no restrictions and without any internet connection. Meanwhile, cloud computing solutions can help design AI-powered lightweight robots but they will require stable network connectivity to function properly.
Next, there are various AI technologies and algorithms designed to solve data processing problems for robots to resemble human-like perception, reasoning, and behavior:
Summing this up, the application of AI in Robotics makes it possible for machines to be autonomous and adaptive using their sensors – cameras, accelerometers, vibration and proximity sensors, etc. They can understand their context in real-time, act accordingly, and learn from new data, improving their behavior.
Businesses, organizations, governments, and individual users are opening up endless opportunities in the application of Artificial Intelligence in Robotics. Statistics show that as soon as by the end of this decade, more than a quarter of the global GDP will be generated by AI. Meanwhile, the AI-driven robotics market size is projected to develop between 2024 and 2030 at an annual growth rate of 11.63%, earning US$36.78bn by 2030.
In this section, we take a closer look at the benefits of AI for Robotics and global business growth.
Powered with AI, robots function autonomously or semi-autonomously which means they no longer need to be controlled by an operator all the time. Thus business owners can finally delegate time-consuming, repetitive, and mundane tasks to robots, freeing up their human resources for higher-level work that requires skills robots cannot provide. Also, autonomous robots can work 24/7, without taking shifts, lunch breaks, sick leaves, and vacations, ensuring uninterrupted service and product delivery.
The AI technologies mentioned above, especially deep learning, reinforcement learning, and sensor fusion contribute greatly to increasing the accuracy of intelligent machines. With self-learning algorithms enabling them to learn from experience and advanced sensor data processing in real-time, dexterous robots can manipulate their limbs and adapt grip force well enough to cut and cook food, assemble small and fragile mechanisms, and even perform open-heart surgeries with better precision than humans.
This advantage of Artificial Intelligence for Robotics comes logically with the prior ones – more efficient and accurate work, in the long run, brings faster results with fewer defects and losses. Additionally, machines’ work efficiency won’t be affected by physically challenging conditions, such as extreme temperatures, heights, weight loads, or lack of light and fresh air.
Hybrid automation and AI in robotics are game-changing for domains and environments with increased risks for human health and life. Such critical activities as working with hazardous chemicals and organisms in labs, rescue operations in dangerous locations, and aid in military and anti-terrorist missions can become much safer. Also, intelligent robotic systems increase worker safety in potentially harmful environments, such as plants and factories, or ensure patient wellness making high-precision procedures less invasive.
An AI-powered robotic system may look like a bulky investment, but it is a one-time investment. It won’t ask you for salary increases, bonuses, perks, and social benefits. A fleet of robots in a warehouse or at a manufacturing facility can do the job of dozens of workers with increased efficiency and precision while it will only need a handful of specialists for support and maintenance.
Of course, like in any sphere, the use of AI in Robotics also faces certain challenges that NGOs and researchers, such as the Trustworthy Autonomous Systems Hub, are working on to resolve. The challenges posed by the implementation of AI for robotics software development include the following:
With the abovementioned benefits of AI-powered robotic systems in mind, we now may consider some of the actual use cases for these smart machines and the way they help businesses from different industries achieve better results.
Naturally flowing from AI robotic applications in various domains, it’s time we reviewed some of the most prominent implementations of AI used in robotics.
These are usually wheeled robots that can move around an environment independently, using their 2D and 3D cameras to localize themselves, process this data in real time, and complete some actions based on their decision-making capabilities. They are most often used in warehouse and manufacturing environments, helping workers move heavy loads at long distances, such as collaboration robots, inventory transportation robots, and storage picking robots. Interestingly, autonomous cars also belong here.
The company delivers a range of AMR models with different designs and functionality for a variety of applications, both commercial and industrial. As an AI in robotics example, their Autonomous Floor Scrubber for cleaning large surface areas is adaptable to the environment and, in addition to autonomous navigation, path planning, and obstacle avoidance due to their Lidar sensors and cameras, can analyze and optimize its movement patterns and performance using data analytics and ML.
This type of robot is specifically designed to perform such tasks as autonomous collecting and moving of items, or assembling and crafting mechanisms. AI algorithms help articulated robots learn to control their manipulations and pressure on objects more accurately. Such robots as Cartesian robotic arms type or SCARA are usually bulky and used in industrial settings, while Articulated (or Jointed) robots may have broader applications, including healthcare, prosthetics, and even household.
Experienced professionals in 3D vision systems (since 1990), today this company provides a range of robotic arm models for industrial automation. Powered with proprietary AI vision software, Solomon’s vision-guided robots can efficiently do object picking and placing, material handling and positioning, and defect inspection and repair.
This is a Kickstarter project for an AI-powered high-precision articulated robot for a household or a small business. It is equipped with a camera and microphones with computer vision and voice recognition capabilities. Its robotic arm is modular, so it can serve as a 3D printer, laser cutter and engraver, vacuum gripper, pen holder for writing and drawing, and more, depending on the model in use.
[source: https://www.kickstarter.com/projects/huenit/huenit-ai-camera-and-modular-robot-arm]
Cobots can be shaped in different ways – as fixed robotic arms, humanoids, legged and wheeled robots. Their main purpose is to function adequately in collaboration with a human, hence “cobot” – a collaborative robot. Cobots rely on AI technologies to be able to identify, process, and respond to human speech and gestures, and even learn from them. They are designed to make work easier for human operators when it comes to extreme weight lifting or precision.
This is a series of armed robots for the manufacturing industry, enhanced with AI vision technology to better feel the environment they operate in. The company has developed tailored TM AI+ Training Server, TM AI+ AOI Edge, and TM Image Manager software to enable clients to train AI models for their cobots, increase their accuracy, and deal with factory deployment.
It is one more creation from Boston Dynamics that blew our minds for the first time when we saw it dancing. Having incredible abilities to run, jump, skip, and even flip quite smoothly due to advanced hardware and an AI-powered control system, Atlas is known today as the most dynamic robot in the world, fighting the constraints of this type of robot. So far, it has been used for purely research purposes, helping robotic engineers study and push the limits of robotic mobility.
As a company with strong expertise and experience in Robotics development services and AI development services, Waverley Software has to share some practical insights from the domain of AI robot development.
Speaking of AI-powered Robotics, we can define two types of hardware we will need for AI-Driven robotics development:
As we’ve mentioned earlier, the computing hardware you choose for AI workloads can be general-purpose and specific-purpose. The former will require more computing power to process and will be more expensive while the latter can be more lightweight and cheaper. For example, Luxonis, the creators of a single embedded ML and CV platform, create advanced cameras with on-chip processing, which allows robotics enthusiasts and startups to save on general-purpose computing hardware. Because these cameras have the hardware capacity to run various computer vision models themselves, robot creators don’t have to allocate additional computing resources for this on the robots.
Meanwhile, hardware making up the robot’s body and ensuring its movement includes a massive variety of models and elements. Depending on your desired application for the robot, you can choose from a variety of parts, such as robot bases, joints, flanges, motors, propellers, and drives to build humanoid robots, aerial robots, arms or legs only, platform-like robots, wheeled robots, or mixed robots of different sizes.
In addition to “body” parts and the “brain” robots can’t do without such hardware elements as sensors for data collection, actuators for part movement, communication interfaces for information exchange with other devices and software, power sources, and, of course, controllers – micro- or mini-computers that are programmed to control the robot’s movements and actions. For the robot to be able to see and hear, it will need a camera and a microphone.
Such algorithm as Sensor Fusion is used for combining data from the numerous sensors a robot has to increase the robot’s accuracy and reliability. Simultaneous Localization and Mapping (SLAM) relies on sensors to help the robotic system create a map of the environment and locate itself within this environment. Autonomous navigation algorithms help robots in path planning and navigating around the surroundings using the data collected from the sensors.
IoT development, which is also rooted in embedded systems, converges with robotic system development in terms of communication and data exchange with other, connected, devices. This can be mirrored in robot fleet management and synchronization in robotics. Also, as in IoT devices, data collected from sensors is used by robots for performance and environment analytics enabling them to improve their autonomy. Altogether, advanced control systems and device communication push forward AI and IoT-based intelligent automation in Robotics, making machines safer and more accurate.
Robot programming can be done through a web or desktop interface as well as from an IDE via a remote SSH session. Developers can set up visual dashboards reflecting the robot’s hardware performance and analytics, streaming content from the robot’s sensors in real time, containing a UI for robot controls, and more. This can be done with any front-end development technology or using ready-made platforms, such as Formant.
Same as with hardware, your robot’s software depends on the area of application and the purpose of using AI for robotics you have in mind. Some hardware, like the cameras and microphones, come with embedded software. Manufacturers may provide out-of-box development kits, specifically built for AI applications in robotics packed with ready-made ML models, libraries, documentation, and knowledge base, for example, DepthAI or Intel’s RealSense platform.
If you choose to move your computing to the cloud, then you will have the choice from the range of AI technologies and models that solve general ML tasks cloud vendors have to offer. For example, if you want your robot to be able to hold a conversation, you may try using existing services that provide chatbot experience, such as GCP’s Dialogflow or Amazon’s Lex, or deploy your own conversation engines leveraging Meta’s Llama2 in any cloud. You can also create your own ML models and algorithms with Amazon’s no-code solution SageMaker Canvas, Microsoft’s enterprise-grade platform Azure Machine Learning, or GCP’s Vertex AI.
This is more of a data science part of the AI robotics development process. When collecting and preparing data for your robot, it is important to take into account the following key aspects:
On Waverley’s blog, you can find an in-depth guide on Data Collection for Machine Learning for actionable insights and strategies.
However, unlike software QA, AI robotics testing includes more than one layer of testing – both software and hardware as well as AI functionality and autonomous work. This should include, for example:
In addition, it’s always worth mentioning that following best development practices depending on programming languages, processes, and project constraints is the optimal strategy for software development and testing and appliesy equally to AI robotics.
Same as testing, application deployment and monitoring are iterative processes, and continuous feedback from real-world usage is essential for refining and optimizing AI robotic systems over time. Regular updates, maintenance, and improvements based on monitoring insights contribute to the long-term success and reliability of the deployed systems.
As active participants in business-critical, invasive, or potentially harmful operations and processes, AI-powered robots must be restricted by rigorous safety and security legislation, policies, and guidelines. So far, this aspect of advancements in AI and Robotics faces a range of problems to deal with:
OECD’s Artificial Intelligence Policy Observatory stresses that one of the obstacles hardest to overcome is the considerable gap between the pace of AI technology development and regulatory activity. Regulating tech advancements is about finding the balance between risks and opportunities which is very disputable, especially in the context of global international cooperation.
However, there’s some progress in ensuring data privacy and security on the regional and national levels, pressing software creators to inform users on how their data is used and ask for their consent to do so. Both AI and Robotics industries have to comply with the existing regulations related to data privacy:
There is also a sector-specific approach to data security regulations:
Considering all of the above, it is key to account for your target market’s safety and security requirements for AI and Robotics development, as they may be looser or stricter across regions, countries, and even states.
Waverley’s engineering experts have been working on robotics projects years before this domain gained its present popularity. For our clients, this means a deep understanding of the foundational technologies and their evolution that translated into long-lasting and scalable products with a solid core. Today, we apply our expertise in Artificial Intelligence for robotics, delivering advanced solutions for a variety of industry domains.
As a result, Jibo can recognize his users’ faces and voices, interpret their requests, provide answers to them, even tell jokes, and “dance” in response to certain commands, thus creating deep emotional connections with humans. More importantly, compared to the competitors’ solutions, the robot’s distinctive feature is increased user data security and privacy, which doesn’t allow server and network providers to see any data collected by the robot from its interactions with users.
R&DThis is ShadowRobot’s extremely sensitive and accurate articulated robot that closely resembles a human hand. It is equipped with over 100 sensors and numerous actuators allowing independent motion for each finger, customizable tactile sensing, postural stability, shock mitigation, and natural bending. Powered with AI, deep learning, and reinforcement learning specifically, it can be trained to master new moves and manipulate an endless nomenclature of objects in real-life settings.
The company leveraged Waverley’s know-how in the AI and Robotics domains to enhance the robot’s cloud infrastructure and DevOps with the AWS provider. As the client’s trusted nearshore software developers, our engineers worked on enhancing the security of user data critical for research activities and providing support to customers. Also, our team delivered improved fully managed software build service for the robot that saves the client’s costs on build and deployment operations.
ConstructionThis is an ongoing project, involving Boston Dynamic’s Spot robots and Clearpath’s Huskies. Spot is a four-legged robot that can steadily walk around bumpy terrain, climb up the stairs or similar environments, and provide vision in hazardous environments. Husky is a ground vehicle platform with rugged construction and a high-torque drivetrain that can provide access to hard-to-reach environments. Both robots are unmanned and autonomous, making them a perfect inspection automation solution in such a place as a construction site.
The Waverley team of robotics and AI engineers is working on the monitoring and 3D modeling functionality for the construction site by making measurements and photos as well as providing additional useful features, such as connecting employees to video calls to help humans observe the construction process remotely.
R&DWaverley’s AI and robotics geeks are working on the development of a smart, legged robot advanced with computer vision technology. The four-legged robot is lightweight and equipped with an ML-powered high-resolution camera with depth vision and object detection capabilities. The simple and intuitive web interface for the robot system features robot controls for remote control, real-time video streaming with object detection, and the robot’s performance and hardware dashboard. It is designed for diverse automation applications, including industrial, commercial, and home.
This was an attempt at a general review of the current state of AI and Robotics fusion, its benefits for business, real-world applications, trends, and challenges. We can conclude that despite such challenges as ethical considerations, lack of standardization, and privacy concerns, smart robotic solutions have a multitude of useful applications at present and great potential for the future. Industries that benefit from AI in Robotics the most include logistics, manufacturing, welding, construction, transportation, and aerospace, with miltech, customer service, healthcare, and smart home gaining traction in this sphere.
It’s also important to mention here that AI-powered robotics development is a high-responsibility and costly process that requires a multi-faceted approach including the mastery of AI technologies, mechanical engineering, embedded engineering, security and privacy requirements, and industry-specific knowledge.
Waverley Software, with its decades of experience in software development, has the capacity to meet these rigid demands to help you integrate AI into your business with our robotics solutions. You can arrange a meeting with our consultants by using this contact page or the contact form below.
AI in robotics is the application of data science and machine learning algorithms to enable robots to perceive the environment and act in a human-like manner. This makes them autonomous and helpful for people. For example, the application of computer vision helps robots detect and classify objects which provides opportunities for using them in hazardous environments. Or, powered with reinforcement learning, robots provide assistance to people in completing physically demanding tasks, such as dealing with heavy loads, working in extreme conditions, or support for people with limited abilities.
The benefits of integrating AI into robotics include increased business efficiency, productivity, work accuracy, risk reduction, and cost efficiency. As the robots become autonomous, adaptable to the environment, and able to learn from past experience, they can substitute human workers in 24/7 operations, hazardous environments, and hard labor, or help them complete high-precision and heavy-load tasks. Social and customer-facing robots are designed to interact with people smoothly, building emotional connections and providing entertainment assistance in daily tasks. This way, businesses can increase quality, optimize the use of resources, provide better working conditions, and engage more customers.
AI technologies that are widely used in robotics include machine learning, deep learning, reinforcement learning, computer vision, generative AI, voice recognition, and speech synthesis. They make robotic systems autonomous and adaptable by enabling them to perceive their environment, process data collected from it in real time, make decisions independently and act accordingly without human supervision. Also, intelligent robots can learn from past experience, with or without human intervention, improving their performance and actions over time. Thus, AI increases robots’ efficiency and performance as compared to their less advanced counterparts.
In order to integrate AI into an existing robotic system, it is important to evaluate the robot’s hardware for computing capacity and compatibility with components with AI capabilities. Also, you need to understand your business needs and goals in order to identify the specific AI technologies, models, and data scope that will be required for your project. Your next step would be identifying the product features, scope of work, and optimal software tech stack to implement your vision. Waverley Software has the talent and competencies to guide you through the entire process of AI integration and development, from estimation and planning to implementation and support.
Interested in AI-enhanced robotics solutions?
Artificial Intelligence (AI) in robotics is one of the most groundbreaking technological advancements, revolutionizing how robots perform tasks. What was once a futuristic concept from space operas, the idea of “artificial intelligence robots” is now a reality, shaping industries globally. Unlike early robots, today’s AI-powered robots can retrieve data, learn from experiences, reason, and make decisions. These capabilities significantly enhance their effectiveness and versatility in sectors like manufacturing, healthcare, transportation, and domestic services.
AI in robotics is driving innovation, optimizing processes, and paving the way for future advancements. This article explores the potential of AI in robotics, its current applications, and how it is reshaping industries for a more efficient and automated future.
Robotics is a field that deals with the creation and designing of these mechanical humans. And robotics these days is not only restricted to the mechanical and electronics domain. Nowadays, the artificial intelligence robot is becoming ‘smarter’ and more efficient with the help of computer science.
Artificial Intelligence has played a very major role not only in increasing the comforts of humans but also by increasing industrial productivity, which includes quantitative as well as qualitative production and cost-efficiency. An artificial intelligence robot can significantly enhance these benefits by integrating advanced algorithms and machine learning capabilities. 
Robotics and artificial intelligence (AI) are closely related fields, and when combined, they give rise to a discipline known as robotic artificial intelligence or simply “robotics in artificial intelligence.”
The combination of robotics and AI opens up a wide range of applications, including autonomous vehicles, drones, industrial automation, healthcare robots, and more. The synergy between these fields continues to advance, leading to increasingly sophisticated and capable robotic systems.
AI plays a crucial role in modern robotics, bringing intelligence and adaptability to these fascinating machines. An Artificial Intelligence Robot is a perfect example of how AI enhances the capabilities of robots, enabling them to perform a wide range of tasks with increased autonomy and adaptability. There are several ways in which an Artificial Intelligence Robot utilizes AI in robotics:
AI algorithms process camera and sensor data to map surroundings, identify obstacles, and plan safe and efficient paths for robots to navigate.
The answer is simple. An artificial intelligence robot, or AI robot, gives robots a computer vision to navigate, sense, and calculate their reactions accordingly. Artificial intelligence robots learn to perform their tasks from humans through machine learning, which is a part of computer programming and AI. 
Since the time self-driving cars coined the term Artificial Intelligence in 1956, it has created a lot of sensation. This is because an artificial intelligence robot has the power to give life to robots and empower them to take their decisions on their own. Depending on the use and the tasks that the robot has to perform, different types of AI are used. They are as follows:
Weak AI, also known as Narrow AI is a type of AI is used to create a simulation of human thought and interaction. The robots have predefined commands and responses. However, the robots do not understand the commands they do only the work of retrieving the appropriate response when the suitable command is given. The most suitable example of this is Siri and Alexa.
The AI in these devices only executes the tasks as demanded by the owner.
Strong Artificial Intelligence is a type of AI is used in those robots who perform their tasks on their own. They do not need any kind of supervision once they are programmed to do the task correctly. This type of AI is widely used nowadays as many of the things are becoming automated and one of the most interesting examples is self-driving cars and internet cars
This type of AI is also used in humanoid robots, which can sense their environment quite well and interact with their surroundings. Also, robotic surgeons are becoming popular day by day as there is no human intervention required at all.
Specialized artificial intelligence is used when the robot needs to perform only specified special tasks. It is restricted only to limited tasks. This includes mainly industrial robots which perform specified and repetitive tasks like painting, tightening, etc.
Benefits of AI in Robotics
AI has already been adopted in robotics, establishing a new generation of intelligent robots that can go farther. These artificial intelligence robots provide flexibility in all sectors of industries, changing the way we interact with technology.
AI in robotics is transforming industries by enabling robots to autonomously perform tasks that were once reliant on human intervention. Below are some key applications of AI in robotics, with real-life examples of how this technology is being utilized.
In the intricate dance of AI and robotics, our world is witnessing transformative advancements. From manufacturing to healthcare, the marriage of artificial intelligence and robotic systems is reshaping industries, ushering in an era of unprecedented efficiency, adaptability, and autonomous capabilities. The synergy between these fields continues to redefine possibilities and elevate technological landscapes, with the artificial intelligence robot at the forefront of this evolution.
AI enhances robotics with learning and adaptability, enabling smarter, more autonomous robots for diverse applications.
They complement each other. AI provides intelligence, while robotics encompasses physical implementation. Together, they unlock powerful possibilities.
Expansive scope: designing intelligent machines, automating tasks, advancing healthcare, manufacturing, and shaping the future of technology.
AI mimics human intelligence, enabling machines to learn, reason, and adapt. It powers automation, decision-making, and smart systems.
Yes, AI is integral to the future of robotics, driving autonomy, adaptability, and expanding applications across industries.
Find out how robots equipped with artificial intelligence (AI) are helping businesses solve problems in new ways. 
Artificial intelligence can be integrated with all types of robots to help them accomplish a variety of tasks.
Machine and deep learning enable robots to become smarter, augmenting their capabilities so they can complete more-complex tasks.
Across industries, robots and artificial intelligence (AI) have enabled innovative solutions to the challenges faced by businesses of all sizes. Intel provides the technologies, tools, and partner relationships required to realize the full potential of robots and AI.
Across industries, robots and artificial intelligence (AI) have enabled innovative solutions to the challenges faced by businesses of all sizes. Intel provides the technologies, tools, and partner relationships required to realize the full potential of robots and AI.
Robots and Artificial Intelligence: Revolutionizing Business for the Better
The idea of robots powered by artificial intelligence has fascinated and ignited our imaginations for decades. Today, robotics ideas that were once science fiction are becoming reality for many businesses. 
Companies are using AI-powered robots to bring humans and technology closer together, solve problems, and transform their business models to meet changing demands.
For example, AI-enabled robots greet customers in stores and provide them with personalized information and directions. They harvest ripe vegetables in farm fields and serve made-to-order lattes in coffee shops. In industrial settings, AI-enabled robots keep workers safe by operating in shared spaces. They also perform complex tasks such as cutting, grinding, welding and inspection autonomously.
What Are AI-Powered Robots?
AI-powered robots are augmented with a variety of sensors (including vision devices such as 2D/3D cameras, vibration sensors, proximity sensors, accelerometers, and other environmental sensors,) that feed them with sensing data they can analyze and act upon in real-time.
To better understand what AI-enabled robots are, it’s important to understand what makes them intelligent.
Artificial intelligence refers to a broad class of systems that enable machines to mimic advanced human capabilities. There are several ways to achieve AI, as shown in the diagram below.
The idea of robots powered by artificial intelligence has fascinated and ignited our imaginations for decades. Today, robotics ideas that were once science fiction are becoming reality for many businesses. 
Companies are using AI-powered robots to bring humans and technology closer together, solve problems, and transform their business models to meet changing demands.
For example, AI-enabled robots greet customers in stores and provide them with personalized information and directions. They harvest ripe vegetables in farm fields and serve made-to-order lattes in coffee shops. In industrial settings, AI-enabled robots keep workers safe by operating in shared spaces. They also perform complex tasks such as cutting, grinding, welding and inspection autonomously.
AI-powered robots are augmented with a variety of sensors (including vision devices such as 2D/3D cameras, vibration sensors, proximity sensors, accelerometers, and other environmental sensors,) that feed them with sensing data they can analyze and act upon in real-time.
To better understand what AI-enabled robots are, it’s important to understand what makes them intelligent.
Artificial intelligence refers to a broad class of systems that enable machines to mimic advanced human capabilities. There are several ways to achieve AI, as shown in the diagram below.
When augmented with AI, robots can help businesses innovate and transform their operations. Today’s most common types of robots powered by AI include:
As AMRs move through their environments, AI enables them to:
Depending on the industry, the tasks and actions completed by AI-empowered AMRs vary widely. For example, when moving inventory from one point to another in a warehouse, AMRs can avoid collisions by navigating around human workers or fallen boxes while simultaneously determining the optimal path for task completion. Learn more about AMRs and how they are being used.
AI allows articulated robots to perform tasks faster and more accurately. AI technologies infer information from vision sensors, such as 2D/3D cameras, to segment and understand scenes as well as detect and classify objects. Learn more about articulated robots and robotic arms.
AI allows cobots to respond to and learn from human speech and gestures without worker-assisted training.
When augmented with AI, robots can help businesses innovate and transform their operations. Today’s most common types of robots powered by AI include:
As AMRs move through their environments, AI enables them to:
Depending on the industry, the tasks and actions completed by AI-empowered AMRs vary widely. For example, when moving inventory from one point to another in a warehouse, AMRs can avoid collisions by navigating around human workers or fallen boxes while simultaneously determining the optimal path for task completion. Learn more about AMRs and how they are being used.
AI allows articulated robots to perform tasks faster and more accurately. AI technologies infer information from vision sensors, such as 2D/3D cameras, to segment and understand scenes as well as detect and classify objects. Learn more about articulated robots and robotic arms.
AI allows cobots to respond to and learn from human speech and gestures without worker-assisted training.
Benefits of Integrating AI
While integrating artificial intelligence with an existing operation or business model appears overwhelming at first, the benefits realized typically far outweigh the challenges experienced. 
Companies today are juggling more demands than ever before. Customers want faster delivery. Stakeholders want higher productivity and increased efficiency. And workers want to contribute without fatigue or injury. AI robots are helping on all fronts. They perform repetitive or time-consuming tasks, such as checking inventory and alerting staff to out-of-stock or misplaced items in retail environments. This expedites product delivery, improves productivity, and frees human workers to take on higher-level, less physically taxing tasks, such as looking for ways to improve processes, troubleshooting AMR issues, or developing new ideas. 
AI robots can see and understand their environments, which enables them to complete complex tasks such as quality-control inspections on assembly lines. In industrial applications, AI robots can check the quality of goods inline, instead of delaying the task to the end of the process—saving time and money for the manufacturer. Read how Audi partnered with Intel and Nebbiolo Technologies to boost weld inspections and enhance quality-control processes with Intel-enabled robotic arms, machine learning, and predictive analytics.1
AI robots play a major role in improving workplace safety. Companies in the oil and gas sector often use them to perform data collection or safety inspection tasks in dangerous environments to reduce risk to humans. And because AI-enabled robots can learn from human gestures and speech, they’re able to continuously improve their ability to complete their tasks while safely working alongside employees.
While integrating artificial intelligence with an existing operation or business model appears overwhelming at first, the benefits realized typically far outweigh the challenges experienced. 
Companies today are juggling more demands than ever before. Customers want faster delivery. Stakeholders want higher productivity and increased efficiency. And workers want to contribute without fatigue or injury. AI robots are helping on all fronts. They perform repetitive or time-consuming tasks, such as checking inventory and alerting staff to out-of-stock or misplaced items in retail environments. This expedites product delivery, improves productivity, and frees human workers to take on higher-level, less physically taxing tasks, such as looking for ways to improve processes, troubleshooting AMR issues, or developing new ideas. 
AI robots can see and understand their environments, which enables them to complete complex tasks such as quality-control inspections on assembly lines. In industrial applications, AI robots can check the quality of goods inline, instead of delaying the task to the end of the process—saving time and money for the manufacturer. Read how Audi partnered with Intel and Nebbiolo Technologies to boost weld inspections and enhance quality-control processes with Intel-enabled robotic arms, machine learning, and predictive analytics.1
AI robots play a major role in improving workplace safety. Companies in the oil and gas sector often use them to perform data collection or safety inspection tasks in dangerous environments to reduce risk to humans. And because AI-enabled robots can learn from human gestures and speech, they’re able to continuously improve their ability to complete their tasks while safely working alongside employees.
AI Robot Capabilities
Robotics and Machine Learning
Machine learning is critical to AI robots’ ability to learn and progressively get better at task execution. Machine learning for robots enables the robots to use real-time data and contextual information acquired through their experiences to develop new learning pathways and capabilities. This allows the robots to solve new and unique problems as they encounter them in their environments.
Natural Language Processing (NLP)
Natural language processing (NLP) is a type of artificial intelligence that enables a robot to understand human language as it is spoken. AI robots with NLP typically complete tasks that involve:
NLP enables AI robots in retail, healthcare, and hospitality to directly interface with customers at touchless kiosks, serve as virtual assistants in banks to minimize human-to-human contact, or entertain residents in retirement communities.
Conversational AI
Conversational AI uses data, NLP, and machine learning to take an AI robot’s interaction capabilities with humans to the next level. The goal of using conversational AI with AMRs or humanoid robots is to offer more human-like interactions between people and computers. With every interaction, the robot will capture dialogue, process it, respond, and learn in anticipation of the next interaction. For example, Lee’s Famous Chicken Restaurants in Ohio faced an employee shortage and began using a conversational AI solution to greet drive-thru customers, answer questions about menu items, and take orders.
Machine learning is critical to AI robots’ ability to learn and progressively get better at task execution. Machine learning for robots enables the robots to use real-time data and contextual information acquired through their experiences to develop new learning pathways and capabilities. This allows the robots to solve new and unique problems as they encounter them in their environments.
Natural language processing (NLP) is a type of artificial intelligence that enables a robot to understand human language as it is spoken. AI robots with NLP typically complete tasks that involve:
NLP enables AI robots in retail, healthcare, and hospitality to directly interface with customers at touchless kiosks, serve as virtual assistants in banks to minimize human-to-human contact, or entertain residents in retirement communities.
Conversational AI uses data, NLP, and machine learning to take an AI robot’s interaction capabilities with humans to the next level. The goal of using conversational AI with AMRs or humanoid robots is to offer more human-like interactions between people and computers. With every interaction, the robot will capture dialogue, process it, respond, and learn in anticipation of the next interaction. For example, Lee’s Famous Chicken Restaurants in Ohio faced an employee shortage and began using a conversational AI solution to greet drive-thru customers, answer questions about menu items, and take orders.
Intel® AI Technologies
Intel’s interoperable technologies are key to equipping robots with AI so they can intelligently sense, plan, and act. 
With hardware built for IoT, AI software that’s purpose-built for mobile robot applications, and a global partner ecosystem, Intel provides the foundational building blocks for robot builders to create connected, intelligent, and reliable robotics solutions.
Our processors enhanced for IoT, AI accelerators, and VPUs provide the essential compute capabilities that all AI robots need for intelligent, autonomous operation. 
And the Intel® Distribution of OpenVINO™ toolkit gives developers the tools and prebuilt components to streamline development of comprehensive AI inference capabilities. Intel® oneAPI —our cross-industry, open, standards-based unified programming model—provides developers with one common development experience across accelerator architectures. This allows them to realize the full value of hardware application performance, enable more predictability, and deliver innovation. 
With Intel® AI technologies and Intel® Vision Products that are tuned for low-latency inference, businesses can bring AI to robots and other edge devices.
Intel’s interoperable technologies are key to equipping robots with AI so they can intelligently sense, plan, and act. 
With hardware built for IoT, AI software that’s purpose-built for mobile robot applications, and a global partner ecosystem, Intel provides the foundational building blocks for robot builders to create connected, intelligent, and reliable robotics solutions.
Our processors enhanced for IoT, AI accelerators, and VPUs provide the essential compute capabilities that all AI robots need for intelligent, autonomous operation. 
And the Intel® Distribution of OpenVINO™ toolkit gives developers the tools and prebuilt components to streamline development of comprehensive AI inference capabilities. Intel® oneAPI —our cross-industry, open, standards-based unified programming model—provides developers with one common development experience across accelerator architectures. This allows them to realize the full value of hardware application performance, enable more predictability, and deliver innovation. 
With Intel® AI technologies and Intel® Vision Products that are tuned for low-latency inference, businesses can bring AI to robots and other edge devices.
Intel® AI Technologies Enable the Next Era of Robotics
Innovative companies across the globe are using robotics with AI to not only solve some of the world’s biggest challenges but also address industry- and business-specific issues such as efficiency, productivity, and worker safety. With a robust portfolio of robotics and AI technologies, Intel is ready to help companies revolutionize their business.
Innovative companies across the globe are using robotics with AI to not only solve some of the world’s biggest challenges but also address industry- and business-specific issues such as efficiency, productivity, and worker safety. With a robust portfolio of robotics and AI technologies, Intel is ready to help companies revolutionize their business.
Robotics and artificial intelligence are two entirely different fields. Despite being separate areas, they do overlap in one area—AI robots. Artificial intelligence can be applied to robots to create AI robots.
One common misconception about robots augmented with AI is that they will begin to act freely or in a way that is beyond the scope of their original task. This is false. Robot intelligence is not the same as human intelligence and robots cannot create new abilities outside of the scope of what they were programmed to do. Another popular misconception is that AI-powered robots will replace humans in all jobs. It is more likely that robots augmented with AI will transform jobs. Robots are not currently designed to replace human workers. They are designed to assist humans in their work to improve efficiency, productivity, and safety.
Assembling small parts into larger units is a crucial part of the manufacturing process. Previously, the combination of human dexterity, vision, and intelligence was the only way such assembly could be done.  Recent advancements in technology have now made it possible for robots to do many of these tasks. Since many assembly processes require adhesives, robots that can dispense bonding agents are a related technology.
In warehouses and in factories, one of the most common tasks is transporting goods. Studies have shown that many industrial operatives spend most of their day walking, pushing a cart, or driving industrial vehicles like forklifts. These activities represent a low value-added, and therefore are a good candidate for automation.
As an intermediate step toward full automation, autonomous mobile robots (AMRs) can handle the transporting of the goods to a packing station after they’re picked from shelves by people.  Alternatively, in a scheme called “goods to person”, entire shelving units are picked up from below and carried by the AMRs to a person who is stationary, who then picks the items from the shelves to fulfill the orders.  Amazon has many videos on YouTube showing this type of robot-assisted order-picking process. 
Advances in artificial intelligence (AI) and computer vision, along with new kinds of grippers, are now making fully automated order-picking a reality. 
Milling Robots take the CNC automation to the next level, allowing for automated tool changing and unattended operation.  Using robotics to perform the milling can improve the precision and flexibility of the operation, reduce the number of defective parts, as well as improve safety for the workers.  Enhancing work conditions can help in employee retention. 
Laser welding lends itself well to automation because the width of the laser beam, the depth of penetration into the workpiece, and the path and speed of the beam can all be precisely controlled. 
Robotic automation of injection molding involves removing the piece from the mold, trimming off excess material, discarding the excess, and placing the finished workpiece into a bin or conveyor system.   As with die casting, the use of robots in the injection molding process improves productivity and increases safety.
As a result, painting and coating operations are well-suited for robotic automation.  The results are consistent, with high quality, and the machines can work continuously with no breaks, and no downtime except for periodic maintenance.  By using robotics, workers do not have to be exposed to harmful fumes or overspray, and safety is improved. 
Removing dust and debris from industrial facilities can be done automatically using industrial robot vacuums.  Some models offer an automatic discharge area, in which the robot empties the dirt it has collected into a receptacle or chute.  Reducing labor costs, and having the cleaning done thoroughly, consistently, and reliably, are a few of the advantages to using industrial robot vacuums. 
Robots that operate in a warehouse and distribution centers can automate a wide range of tasks, including order picking, packing, sorting, labeling, and transporting. The Warehouse Automation Market is estimated at USD 25.74 billion in 2024 and is expected to reach USD 54.53 billion by 2029, growing at a CAGR of 16.20% during the forecast period (2024-2029). This rapid growth indicates that automation is being swiftly adopted across the industry. Automated Guided Vehicles (AGVs) and Autonomous Mobile Robots (AMRs) are among the fastest-growing categories of robots for transporting goods within warehouses and distribution centers.
Palletizing robots can stack boxes and containers onto a pallet in an optimized way.  If there are a variety of different items in the boxes, artificial intelligence can be used so that the heavier containers are placed on the bottom.  The boxes can be oriented in such a way as to maximize the number of boxes that will fit onto the pallet. 
HowToRobot is a global platform connecting end-users with robot and automation suppliers worldwide. We have the world’s largest directory of robotics companies. Using our guide, you can find the type of robot you need, ideally suited for your application.
We can help you get started with robotics and automation.
Intel offers the computing hardware, AI technologies, and vision solutions that enable robots to sense and understand the world around them.
As robotics manufacturers continue to deliver innovations across capabilities, price, and form factor, robotics solutions are being implemented in an ever-increasing number of industries and applications. Advancements in processing power and AI capabilities mean that we can now use robots to fulfill critical purposes in a plethora of ways.
While many mobile humanoid robots may technically fall under the domain of an AMR, the term is used to identify robots that perform human-centric functions and often take human-like forms. They use many of the same technology components as AMRs to sense, plan, and act as they carry out tasks such as providing directions or offering concierge services.
As robotics manufacturers continue to deliver innovations across capabilities, price, and form factor, robotics solutions are being implemented in an ever-increasing number of industries and applications. Advancements in processing power and AI capabilities mean that we can now use robots to fulfill critical purposes in a plethora of ways.
While many mobile humanoid robots may technically fall under the domain of an AMR, the term is used to identify robots that perform human-centric functions and often take human-like forms. They use many of the same technology components as AMRs to sense, plan, and act as they carry out tasks such as providing directions or offering concierge services.
We also help power the larger technology ecosystem that robots operate in—from edge servers and devices to data centers. Our Intel® oneAPI programming model and the Intel® Distribution of OpenNESS help robotics manufacturers and software companies to more easily create and deploy the edge applications their solutions require.
With our Intel® RealSense™ cameras, we help enable the essential machine vision capabilities that allow robots to understand the world around them. And with the Intel® Distribution of OpenVINO™ toolkit, we’re empowering developers to more easily deploy AI capabilities on robotics solutions.
We also help power the larger technology ecosystem that robots operate in—from edge servers and devices to data centers. Our Intel® oneAPI programming model and the Intel® Distribution of OpenNESS help robotics manufacturers and software companies to more easily create and deploy the edge applications their solutions require.
With our Intel® RealSense™ cameras, we help enable the essential machine vision capabilities that allow robots to understand the world around them. And with the Intel® Distribution of OpenVINO™ toolkit, we’re empowering developers to more easily deploy AI capabilities on robotics solutions.
The advent of autonomous vehicles has heralded a transformative era in transportation, reshaping the landscape of mobility through cutting-edge technologies. Central to this evolution is the integration of artificial intelligence (AI), propelling vehicles into realms of unprecedented autonomy. Commencing with an overview of the current industry landscape with respect to Operational Design Domain (ODD), this paper delves into the fundamental role of AI in shaping the autonomous decision-making capabilities of vehicles. It elucidates the steps involved in the AI-powered development life cycle in vehicles, addressing various challenges such as safety, security, privacy, and ethical considerations in AI-driven software development for autonomous vehicles. The study presents statistical insights into the usage and types of AI algorithms over the years, showcasing the evolving research landscape within the automotive industry. Furthermore, the paper highlights the pivotal role of parameters in refining algorithms for both trucks and cars, facilitating vehicles to adapt, learn, and improve performance over time. It concludes by outlining different levels of autonomy, elucidating the nuanced usage of AI algorithms, and discussing the automation of key tasks and the software package size at each level. Overall, the paper provides a comprehensive analysis of the current industry landscape, focusing on several critical aspects.
Keywords: artificial intelligence (AI); Machine learning (ML); deep learning (DL); deep neural networks (DNNs); natural language processing (NLP); autonomous vehicles (AVs); safety; security; ethics; emerging trends; trucks vs. cars; autonomy levels; operational design domain (ODD); software-defined vehicles (SDVs); connected and automated vehicles (CAVs); in-vehicle AI assistant; internet of things (IoT); generative AI (GenAI)
AI is shaking things up in the creative world, and I get why a lot of artists feel anxious. Whenever new technology comes along — especially in industries like ours — it brings fear. Fear of losing control, fear of being replaced. That’s real. But there’s another side to this: AI can open doors we never thought possible.
In “Creativity in the Age of AI: Insights, Ethics & Opportunities,” a report I co-wrote with digital policy expert Natalia Domagala and technologist Angela Lungati — in collaboration with Mozilla and Skillshare — we explore both the anxieties and opportunities AI brings to creatives.
Together, we explore the future of creativity in this paper, touching on the ethical challenges and the immense possibilities AI brings.
If you’re curious about how AI is changing the creative world — whether you’re excited or skeptical — this paper is for you. We explore the risks, the rewards and what AI means for the future of creativity. It’s the start of a crucial conversation about creativity and control, with insights from the worlds of art, technology and policy — offering a glimpse into how AI is reshaping the future.
Manuel Sainsily is a TEDx speaker and an XR and AI instructor at McGill University and UMass Boston. Born in Guadeloupe and a Canadian citizen based in Montreal, where he completed his Master of Science in computer sciences, he is a trilingual public speaker, designer, and educator with over 15 years of experience who champions the responsible use and understanding of artificial intelligence. From delivering a masterclass on AI ethics and speaking at worldwide tech, film, and gaming conferences to being celebrated by NVIDIA, Mozilla Rise25, and Skillshare, and producing art exhibitions with Meta, OpenAI, and VIFFest, Manuel amplifies the conversation around cultural preservation and emerging technologies such as spatial computing, AI, real-time 3D, haptics, and BCI through powerful keynotes and curated events.
Deep learning is a method that trains computers to process information in a way that mimics human neural processes. Learn more about deep learning examples and applications in this article.
The field of artificial intelligence (AI) and machine learning (ML) is rapidly evolving, generating both fear and excitement. While many people have a general understanding of ML and AI, deep learning is a special type of machine learning that can be more challenging to describe.
You can learn more about deep learning systems and how to work with them in the following article, or start your journey with the popular course, Deep Learning Specialization from DeepLearning.AI.
Deep learning is a branch of machine learning thatÂ is made up of a neural network with three or more layers:
Input layer: Data enters through the input layer. 
Hidden layers: Hidden layers process and transport data to other layers. 
Neural networks attempt to model human learning by digesting and analyzing massive amounts of information, also known as training data. They perform a given task with that data repeatedly, improving in accuracy each time. It's similar to the way we study and practice to improve skills.Â 
Read more: Deep Learning vs. Machine Learning
Deep learning models are files that data scientists train to perform tasks with minimal human intervention. Deep learning models include predefined sets of steps (algorithms) that tell the file how to treat certain data. This training method enables deep learning models to recognize more complicated patterns in text, images, or sounds. 
AI, machine learning, and deep learning are sometimes used interchangeably, but they are each distinct terms. 
Artificial Intelligence (AI) is an umbrella term for computer software that mimics human cognition in order to perform complex tasks and learn from them.Â Â 
Machine learning (ML) is a subfield of AI that uses algorithms trained on data to produce adaptable models that can perform a variety of complex tasks.Â 
Deep learning is a subset of machine learning that uses several layers within neural networks to do some of the most complex ML tasks without any human intervention.Â 
Watch this video from DeepLearning.AI's course, Neural Networks and Deep Learning, to learn more about deep learning and neural networks:
Deep learning is a subset of machine learning that is made up of a neural network with three or more layers. A neural network attempts to model the human brain's behavior by learning from large data sets. Deep learning drives many AI applications that improve the way systems and tools deliver services, such as voice-enabled technology and credit card fraud detection.
Autonomous vehicles are already on our roadways. Deep learning algorithms help determine whether there are other cars, debris, or humans around and react accordingly.
Deep learning chatbots designed to mimic human intelligence (like Chat-GPT) have gained recent popularity due to their ability to respond to natural-language questions quickly and often accurately. The deeper the data pool from which deep learning occurs, the more rapidly deep learning can produce the desired results.
Facial recognition plays an essential role in everything from tagging people on social media to crucial security measures. Deep learning allows algorithms to function accurately despite cosmetic changes such as hairstyles, beards, or poor lighting.
The human genome consists of approximately three billion DNA base pairs of chromosomes. Machine learning is helping scientists and other medical professionals to create personalized medicines, and diagnose tumors, and is undergoing research and utilization for other pharmaceutical and medical purposes.
Similar to facial recognition, deep learning uses millions of audio clips to learn and recognize speech. It can then power algorithms to understand what someone said and differentiate different tones, as well as detect a specific person's voice. 
Whether your interest in deep learning is personal or professional, you can gain more expertise through online resources. If you're new to the field, consider taking a free online course like Introduction to Generative AI, offered by Google. Taking a free class from an industry leader in technology can help you build the foundational knowledge you need to start an independent project or decide whether or not you want to pursue a career in deep learning. Once you feel you have the basics down, you can begin experimenting with open-source deep learning platforms such as Caffe, Theano, and TensorFlow.
Becoming proficient in deep learning involves extensive technical expertise. The list below outlines some specific skills and systems you'll need to learn if you want to get into deep learning professionally.
Machine learning and AI programming languages
Natural language processing
Just like in machine learning and artificial intelligence, jobs in deep learning are experiencing rapid growth. Deep learning helps organizations and enterprises develop ways to automate tasks and do things better, faster, and cheaper.
There are a wide variety of career opportunities that utilize deep learning knowledge and skills. In addition to data, machine, and deep learning engineers, these include:
Data analysts
Data scientists
Natural language processing engineers
Deep learning is a subset of machine learning, so understanding the basics of machine learning is a good foundation to build on. Many deep learning engineers have Ph.D.s, but it is possible to enter the field with a bachelor's degree and relevant experience. Proficiency in coding and problem-solving are the base skills necessary to explore deep learning.
If you already have some of the skills mentioned above or you want to switch to a career in deep learning from a related field, you might consider a certificate program to improve your resume and focus your studies on job-ready skills. Here are a couple of career-focused certificate programs to get you started:
IBM AI Engineering Professional Certificate
DeepLearning.AI TensorFlow Developer Professional Certificate
After you've mastered some of the skills like those listed above, you might be ready to apply for jobs in data science and machine learning. Even an entry-level job as a developer or data analyst can provide exposure to machine learning algorithms and models, as well as those that involve deep learning.
If you have experience on the development side of computer science, you may be well-positioned to enter the field of deep learning. Experience in the intricacies of common languages such as Python is essential for a career in deep learning.
Honing software engineering skills such as data structures, Github, sorting, searching, optimizing algorithms, and a deep understanding of the software development life cycle is crucial to developing the sophisticated skills needed for a career in deep learning.
Led by AI expert Andrew Ng, this 100-percent self-paced, online Deep Learning Specialization includes the following courses for a strong overview of deep learning techniques and fundamentals:
Neural Networks and Deep Learning
Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization 
Structuring Machine Learning Projects
Convolutional Neural Networks
Sequence Models
Get Started with AI
Peter van der Made is the founder and CTO of BrainChip Ltd. BrainChip produces advanced AI processors in digital neuromorphic technologies.
The artificial intelligence (AI) revolution is upon us, and companies must prepare to adapt to this change. It is important to make an inventory of the current skills within the company to identify which additional skills the employees need to learn. The company does well in developing an AI strategy to outline the areas where AI is most effective, whether in a product or a service. Failing to act inevitably means falling behind. The training should include an introduction to AI, its capabilities, and its shortcomings (AI is only as good as its training data). This article gives a view of the current state of AI and what lies ahead.
Artificial intelligence found its purpose in 2012 when AlexNet won the ImageNet challenge with a 16.4% overall error rate, compared to over 26%. The ImageNet challenge is a collection of 1.4 million images in 1000 categories, such as dogs, cars, plants, etc. A neural network is the internal engine of all artificial intelligence technologies. The neural network is said to be based on the way the human brain functions; however, this is far from the truth. Brains are way more complicated and efficient than neural networks. Brains have awareness, imagination, inventiveness and creativity, all missing in neural networks. Brains are also dynamic, consisting of specialized cells called neurons.
Neural networks have grown from a few million to nearly 200 billion parameters. Each parameter must be computed, causing an increasingly great demand for high-performance computing resources and energy. Artificial intelligence programs have beaten humans at chess and in the more complicated game of Go. Programs such as ChatGPT can weave exciting stories and answer complex questions. Training a large network can take months on powerful servers with hundreds of thousands of processors.
The increase in computational resources has made new AI tools and neural networks possible. However, the neural networks responsible for all these impressive results are unaware of what they are doing. There is no awareness, just computation.
Machine learning is a subset of artificial intelligence. Training algorithms need vast data sets to create good-quality parameters that define the function and accuracy of a neural network. Machine learning continues to advance as more data becomes available and algorithms become more sophisticated. AI is used in many fields, including healthcare, finance, manufacturing and transportation.
The future of artificial intelligence appears bright with continued advancements in technology. Investment in artificial intelligence reached $93.5 billion in 2021, according to Statista. The current trend for neural networks to grow larger will likely continue into the near future as more functionality is required.
One of the most promising new technologies is neuromorphic processing. Neuromorphic means "like the brain." Dedicated circuits are used to mimic the way dynamic cells in the brain operate. They do not run any programs but are capable of learning, and just like actual brain cells, they all work simultaneously rather than sequentially. Neuromorphic cortical models of artificial intelligence are based on the structure and function of the neocortex, the brain's outer region responsible for complex cognitive processes and are small, faster and less power-hungry than computers.
Research into these and other brain structures is expected to lead to greater levels of intelligence and better cognitive performance than in previous types of artificial intelligence. With several million nodes, these artificial cortical networks are still far from simulating human intelligence.
Like the composition of the brain, which contains many different structures, it may be necessary to use different types of neural networks to perform specific functions. The neocortex is just one part of the brain responsible for cognition and intelligence. It has massive connections to the thalamus, the hippocampus and the cerebellum, all examples of brain regions important for different cognitive aspects.
Modeling these regions and the neocortex could lead to more advanced AI systems. The thalamus is the central hub that receives sensory information in the brain. Modeling the thalamus could improve the ability of AI to process sensory information, such as auditory, tactile and visual data.
The hippocampus is involved in spatial navigation and the creation of long-term memories. Modeling the hippocampus's functions could improve AI systems' ability to learn and selectively form long-term memory.
The cerebellum has massive connections to all regions of the neocortex. Modeling the cerebellum could lead to the simultaneous processing of incoming data while the AI is learning something new, like driving a car.
While the neuroscience understanding of these brain regions is still incomplete, sufficient information is available to build models that may answer open questions and fill in some of the blanks through experimentation. One day, cortical neuromorphic neural networks may displace the neural networks driving artificial intelligence today and have been responsible for its many successes.
One key difference is their training method. Current neural networks require millions of examples and an error feedback algorithm to adjust the parameters. These training sessions can take weeks using expensive, powerful computers costing millions.
Cortical neuromorphic neural networks learn from few examples and are thus cheaper to deploy. Neuromorphic processing eliminates the need for colossal computer resources. Continuous learning adds experience, creating more accurate outcomes.
Cortical neural networks are expected to be used in products that range from speech recognition to image processing, space exploration, healthcare, and robotics within the next five years. The development of cortical neural networks may lead to the emergence of artificial general intelligence (AGI), the holy grail of artificial intelligence. Humanity will benefit from the emergence of AGI in turbocharging the global economy in providing a multiplier for human ingenuity and safety. AGI is likely to benefit humankind much like previous economic revolutions. The internet and computers changed the way we do business. There will be a similar shift in how humans occupy their time in the future.
AI is a fast-moving field, and companies cannot afford to stand still. To enable personnel, it is imperative to take action now to enable employees to upgrade their skills to meet the challenges of the future. Seek out opportunities to train your employees on this new technology in order to fully embrace it across your organization.
Forbes Technology Council is an invitation-only community for world-class CIOs, CTOs and technology executives. Do I qualify?
This essay examines the state of Artificial Intelligence (AI) based technology applications in healthcare and the impact they have on the industry. This study comprised a detailed review of the literature and analyzed real-world examples of AI applications in healthcare. The findings show that major hospitals use AI-based technology to enhance knowledge and skills of their healthcare professionals for patient diagnosis and treatment. AI systems have also been shown to improve the efficiency and management of hospitals´ nursing and managerial functions. Healthcare providers are positively accepting AI in multiple arenas. However, its applications offer both the utopian (new opportunities) as well as the dystopian (challenges). Unlike pessimists, AI should not be seen a potential source of “Digital Dictatorship” in future of 22nd century. To provide a balanced view on the potential and challenges of AI in healthcare, we discuss these details. It is evident that AI and related technologies are rapidly evolving and will allow care providers to create new value for patients and improve their operational efficiency. Effective AI applications will require planning and strategies that transform both the care service and the operations in order to reap the benefits.
Keywords: Artificial intelligence, application, challenges, real-world, healthcare
Artificial Intelligence (AI), a technology prevalent for almost 60-year has made it possible to create applications that have a profound effect on our life today. It seeks to reproduce and modify human intelligence leading to development of intelligent machines [1]. Some researchers believe that AI can think and act rationally. Others disagree that AI is capable of acting and thinking like humans. Irrespective of what anyone believes, it appears for sure that in the year 2100, the health industry is expected to survive on AI-Human cooperation, not competition. Artificial intelligence, a broad-based tool, allow humans to rethink the way they integrate information, analyze data and use the insights to improve their decision-making. It is already transforming all walks of life [2].
AI is not something futuristic, but a technology that is already in use and integrated into many sectors. Examples include public healthcare and education, transport, telecommunications, data security management, finance, research, policymaking and the legal and judiciary system. AI technologies are now being increasingly applied to healthcare [3]. A combination of unstoppable forces drives healthcare demand. These include changing patient expectations, increasing population age, lifestyle shifts, and the never-ending circle of innovation. The Healthcare system must undergo significant structural and transformational changes to ensure its sustainability. AI has potential to transform healthcare and address some of these challenges [4,5].
AI has been welcomed by healthcare systems around the world, which struggle to fulfil the “quadruple objective” of improving the health and well-being of their patients, healthcare access, cost-effectiveness [6] and improving the lives of healthcare workers [7]. It is essential for healthcare providers to be well versed in the potential applications of AI technologies in different aspects of healthcare which may embark digital revolution in this sector [8]. This article will discuss numerous applications and issues of AI technology in the healthcare industry in the present times. The article also serves necessary recommendations which will help healthcare managers with strategic planning and execution of AI in healthcare.
UNESCO defines AI systems as “technological systems that can process information in a manner that resembles intelligent behavior” [9]. A simplified definition of AI for healthcare is the ability to use computer programs to perform tasks or reasoning in multiple areas of healthcare, including diagnosis and treatment. This is similar to the intelligence that we associate with intelligence in humans [10]. AI in healthcare also refers to the use of machine-learning algorithms or software to replicate human cognition in the analysis and presentation of complex medical and healthcare data [11].
The main categories of AI are based on the capabilities and functions of AI. The types of AI are explained in the diagram below (Figure 1).
types of artificial intelligence
i) Weak AI or Narrow AI: an AI that can perform a specific or a limited set of tasks without any thinking abilities. The Weak AI category covers almost all AI-based systems that have been developed to date such as Siri, Alexa Self-driving car, Alpha-Go, Sophia the humanoid and speech recognition agent [12,13]. ii) General AI or Strong AI - It can perform any intellectual task as efficiently as a human. Although there are no examples of Strong AI to date, we believe that it will soon become possible to build machines as smart and intelligent as humans [12,13]. iii) Super AI: this level of intelligence of systems is at which machines can surpass human intelligence and have cognitive properties. It is currently a fictional scenario [12,13].
i) Reactive machine AI: this category of AI includes machines that work solely from current data and take only current circumstances into consideration. It cannot draw inferences to predict their future actions. They can do a narrower variety of pre-defined functions. Examples include Google's Alpha Go and IBM's Deep Blue systems [12,13]. ii) Limited Memory AI: this has limited memory. It can make better decisions by looking at past data, can store past experiences in a short-term or temporary manner and then use that information to predict future actions. Example includes self-driving vehicles [12,13]. iii) The Theory of Mind AI: this AI should understand people, emotions, and beliefs of human beings, and can interact with them socially as humans. This type of AI machine is not yet developed [14,15]. iv) Self-aware AI: self-awareness AI is the future. This technology will build super-intelligent machines that will possess their own consciousness, feelings, and self-awareness. These machines will be more intelligent than the human brain. It´s only a fictional scenario at present [14,15].
Artificial intelligence does not refer to one technology. Many AI technologies can be applied immediately to healthcare. Some great AI technologies in healthcare are mentioned below:
Machine learning (ML): machine learning is the dominant approach to AI. It uses a predictive model for making predictions from predefined data. Machine learning is being used in many AI technologies, such as natural language processing (NLP) and voice technology [8]. Supervised learning, reinforcement learning (RL), deep learning and multi-instances learning are some of the most popular ML algorithms [14].
Supervised learning: this approach uses a set of data and known, defined outcomes as an outcome. Then, patterns are identified that correspond with the input to make predictions. The algorithm must know what conclusions it should draw from the given data set. Healthcare has witnessed a lot of supervised learning. This allows for data-driven clinical decisions to be made, e.g., use of imaging to diagnose tumours and determine their severity, and predictive analytics within continuous outputs e.g., use of EHR to predict the recurrences, prognosis and mortality of a particular disease [14,15].
Unsupervised learning: this approach can find the data structure and forecast based only on that input. It is better suited for uncertain outcomes or when data labelling is expensive. Unsupervised learning can be used in healthcare to predict individual disease risks and design personalized treatments that are based on genetic biomarkers and genomic variations [8,15].
Semi-supervised learning: unsupervised learning is able to learn by itself, without any human interventions for the outcome. Unsupervised learning, even without human instruction, can be more susceptible to errors as it may use minor features of the data for predictions. In practice, semi-supervised learning is often used. It uses a combination of large untagged and small tagged data for training [15].
Reinforcement learning: it is an autonomous algorithm that allows the user to act and interact according to the environment. It is one of the best learning models and very effective for tasks with clearly defined protocols. It relies on its own experience using feedback from mistakes and rewards to lead training. It does not require data or labelling. It is useful in healthcare such as optimizing treatment plans and robotic-assisted surgical procedures [15,16].
Deep learning: deep learning uses a backpropagation algorithm that operates on multiple levels of abstraction to uncover the complex structure of large datasets. This algorithm is designed for the solution of difficult practical world issues. Some examples are: computer vision, Go game, speech recognition, NLP, genomics and drug discovery [8, 16].
Natural language processing: this employs a computational approach to automatically interpret and represent human language, mainly in text form. These include machine translation, speech recognition, speech classification, question answering and sentiment analysis. Natural language processing tools can extract vital information about patients from large textual data like doctor´s prescriptions, daily patient notes, discharge summaries and various radiological / laboratory reports. This can help healthcare providers in speedy management of patients thus optimizing the health care delivery [8, 16].
Real-world applications: the meaningful and practical application of AI, provides healthcare providers with opportunities and confidence to boost their skills to new challenges in healthcare.
Precision medicine: one of the most important applications of AI in healthcare is precision medicine. Precision medicine aims to optimize the path for diagnosis, therapeutic intervention and prognosis. It uses large multidimensional biological data sets that capture individual variability in genes and other contributing factors like age, gender, and race, as well as medical treatment options such as immune profile, metabolism and vulnerability to the environment. This allows clinicians to tailor early interventions, whether preventative or treatment-oriented, to each patient. There are many precision medicine initiatives [17]. These can be divided into three categories: digital health apps and complex algorithms, as well as genomic-based tests [17]. A deep learning algorithm was developed in collaboration with Scripps Research Institute (CA, USA) and Intel. With a precision of 85%, it could identify 23 patients at high risk for cardiovascular disease. This cognitive assistant is equipped with clinical knowledge and reasoning [18].
Improved disease treatment: AI technologies are increasingly adding to the support of healthcare workers in various aspects of patient´s management. For instance, Onduo offers virtual coaching on mobile apps to control diabetes. It employs AI technology to detect food, and monitor glucose levels as well as physical activities, in order to make recommendations. DayTwo provides another solution for diabetes management. It provides an individualized meal suggestion, based on the user's gut microflora for adequate blood sugar levels. The recommended diet is chosen from its large index of over 100,000 foods [19]. ResApp Health, another example of AI used in chronic disease management, analyzes subjects' breathing by using their phone microphone. The AI algorithm then evaluates various respiratory conditions like chronic obstructive lung disease, pneumonia accurately [20].
Improved diagnostic error reduction and decision support: AI will be used to aid in diagnosing patients with certain diseases and reduce human errors. AI was used by the Mayo Clinic to screen for cervical cancer in order to detect pre-cancerous changes. To identify precancerous signs, the AI-based algorithm uses over 60,000 images of cervical cancer from the National Cancer Institute. The accuracy rate of the algorithm was 91% as compared to 69% by skilled human expert [21]. The focus of IBM's Watson for Oncology has been a focus of media, especially in oncology management. Watson uses combination machine learning and NLP capabilities [22]. Freenome, which uses molecular biology and machine learning to detect early-stage cancers, is another example. The model can be trained to identify which biomarker patterns indicate the stage, type and best treatment options for particular cancer. AI can be used to detect disease-associated patterns by decoding hidden patterns. Google health uses AI for breast cancer screening. It demonstrated that its AI system can outperform human experts in breast-cancer prediction [23]. A deep learning-based AI developed by Massachusetts Institute of Technology (MIT), can forecast the possibility of development of breast cancer up to five years ahead [23].
London´s Moorefield´s Eye Hospital, has declared an AI solution for identifying ocular disease. The AI-based algorithm used data from greater than 15,000 British patients to detect ocular diseases by optical coherence. The decision of referral made by the AI-based algorithm was 94% accurate [24]. Google's research team developed a deep learning algorithm that can interpret retinal images to identify signs of diabetic retinopathy. This could potentially help doctors screen more patients in areas with fewer resources [18]. There are between 6000 and 8000 rare diseases that affect approximately 400 million people around the globe. A rare disease diagnosis can take up to five years and is often time-consuming having a great impact on the finances of the patient and the system. 3Billion created an algorithm in 2019 to diagnose rare DNA-based conditions which can test for up to 7000 diseases simultaneously in suspected cases [25].
Patient data analytics: AI allows hospitals for clinical data analysis which can provide in-depth of patient´s health. It can also be used to predict prognosis, help in clinical audits, track patient prescription and refills, predict the advantages of specific drugs and identify patients´ at risk for substance abuse [26]. For example, the Paris public university hospital uses the Intel analytics platform for predicting the number of patients visiting the emergency department [27-29]. The potential volume of data is huge. According to estimates, personal lifestyle-based data amount to approximately 1100 terabytes in a lifetime. Genetics and medical data account for 6.4 terabytes. Omics technology, GWAS and EWAS, smartphone-based digital phenotyping, sensors and EHRs, and wearable devices can accurately monitor the lifestyle of a person along with climate and topographical data. This made it possible to implement strategies for the prevention and management of metabolic lifestyle disorders. This is why structured data collection and analysis are necessary for large, multidimensional studies which can be employed by integration ML/AI in healthcare system [29,30].
Medical robotics: medical robots have many uses. They can be used to assist in surgery, in rehabilitation for stroke patients (rehabilitation robotics), care for elderly persons (assist-living robotic companion) social interaction (humanoid robot) and so on. AI-assisted surgeon robots have found their way into operation theatres. They can perform surgeries without fatigue and very useful at places where human hands cannot operate due to space constraints [27,31]. The Da Vinci is a surgical robot that allows professionals to perform complex procedures with greater flexibility and control than traditional approaches. The Da Vinci is a surgical robot that can assist surgeons by translating their hand movements at the console and creating clear, magnified, 3D high-resolution images of the surgical site [32].
Real-time prioritization and triage: triage machine learning has been shown to be an efficient tool. John Hopkins University researchers found that ML-based e-triage improves patient risk assessment and categorization. Enlitic is patient triaging software that prioritizes cases according to their clinical data and directs them to suitable medical personnel [27]. Babylon health provides applicable health and triage information depending upon symptoms of the patient [33].
Personalized care or virtual assistance: the treatment plans based on patient data reduce cost and increase the effectiveness of care. Human-Machine Interfaces (HMIs) analyze and recognizes facial motions and helps person with disabilities to drive robotic vehicles and wheelchairs [34]. RUDO, an “ambient intelligent system”, can be used to help blind people live with sighted people and work in trained fields like computer science. Blind people can access the various functions of the virtual assistant through a single interface [35]. An AI-based smart assistant can advise pregnant mothers about various important antenatal matters. AI applications can help the elderly with routine medications and can predict and prevent falls. This can be of major help in patients with gait disorders like Parkinson´s disease [28]. Chatbots allow patients to self-diagnose or help physicians in making a diagnosis. They can help patients share their health information in a proactive way. This allows medical professionals to improve quality care with cost-effectiveness. It also helps to increase patient satisfaction [27]. GYANT is a chatbot for healthcare that helps patients understand their symptoms. Doctors then receive the data and can diagnose and prescribe medicines in real time. Woebot is another chatbot that focuses on mental health. It calls itself “the next generation of mental health” and it certainly seems that way. The chatbot uses Cognitive Behavioral Therapy or CBT, to listen and offer advice to anyone who seeks it out [36]. AI apps that monitor and assist patients´ compliance to prescribed medication and treatment have been proven to be effective. Sentrian uses AI to analyze the data collected from patients' sensors at home. The goal is to identify signs and conditions that could lead to deterioration early so that intervention can be taken to prevent hospital admissions [37].
Virtual assistants for nursing: AI virtual assistants are great in nursing because they can keep healthcare providers and patients connected all the time and thus decreases pressure on the already overburdened medical staff. Alexa robots are virtual nursing assistants employed by Cedars-Sinai Hospital in Los Angeles, California help nursing staff in their daily chores. [22]. Sensely, a virtual nurse, use Natural Language Processing, Machine Learning and wireless integration to medical devices, such as blood pressure monitors, to provide assistance to patients. Sensely can help you with self-care and clinical advice. It also helps you to schedule an appointment [38].
Administrative workflow assistance: one of the AI applications in healthcare is the automation of administrative workflow. AI systems are able to perform operations like the transcription of medical records, medical billing services, bed allotment, and insurance claim verifications apart from numerous other hospital administrative activities faster and much more accurately than humans.[22,38] faster and better than individuals. The AI robot Paul accompanies the medical personnel in their daily patient rounds, help in the analysis of patient medical records and can provide any information regarding patient including daily investigations in a fraction of a second. Maria, the robot's guide, provides directions to patients in the hospital lobby to their doctor's offices or specific medical departments within the hospital and schedules appointments by touching the robot with their medical ID card [39]. The official statement made by Johns Hopkins University Hospital regarding AI technology stated: “Emergency room patients are assigned beds 30% faster, transfer delays from operating rooms are reduced by 70%, ambulances can pick up patients from other hospitals 63 minutes earlier, and the ability to take patients with complex medical conditions from regional and national hospitals has improved to 60%” [40]. Microsoft´s AI digital Assistant Cortana employed advanced analytics and predictive technology to identify potential patients at-risk in ICU treatment and able to monitor “100 beds in 6 ICUs”. [40].
Improved operational efficiency and cost effectiveness: AI-based medical systems can perform numerous tasks involved in healthcare services in a simplified and cost-effective manner. Some of the tasks can be even done without human support. An AI-integrated pill-cam can substitute conventional upper endoscopy. Escalante et al. developed an AI-based method for diagnosis of acute leukemia by examining bone marrow structure characteristics non-invasively [41].
Improving biomedical research: AI acts as an “eDoctor” to diagnose, manage, and prognosis diseases. AI can be a great tool for the indexing of medical literature. It can be used to formulate a research question, search available literature within seconds and test scientific hypotheses. This can save a lot of time and allow the researchers to perform good studies with relevant conclusions in shortest possible time [28,42].
Drug discovery: deep learning has many promising applications in drug discovery. These include advanced image analysis, prediction of molecular structure, function and automated generation of unique chemical entities, de novo drug design, prediction of drug activity, prediction of drug-receptor interactions and prediction regarding drug reaction [43]. NuMedii, a Biopharma firm, developed an AIDD technology (Artificial Intelligence for Drug Discovery), that can identify rapid connections between drugs, diseases, and systems, if any [27]. Researchers created Eve, an AI “robot scientist” that is meant to speed up the process of drug discovery in a more economical way [44].
Some of the most significant challenges in the widespread use of AI include:
Data privacy and cyber security: privacy issues can arise when confidential patient data is collected and shared by AI-based systems/technologies on large datasets. Thus, it is important that AI technology must follow, medical ethics, and laws and should be governed by some laws [22]. The highly sensitive confidential data of patients can be accessed and manipulated by miscreants who may be detrimental to the patient´s social life. Also, there may be high chances of misdiagnosis because of wrong faked data by AI systems. One study showed that benign moles could be misdiagnosed as malignant simply by adding antagonistic noises or just rotation [45].
Reliability and safety: any error made by AI system, if not rectified early can lead to wrong results of the assigned tasks which may have serious consequences. For example, an AI app used for predicting the likelihood of patients developing complications after pneumonia wrongly advised doctors to send asthmatic patients home [46].
Accountability of technology use: if AI-based technology used by medical staff leads to the death of the patient, “who would be responsible for the outcome?” This will create multiple unanswered questions on many technical, managerial and ethical issues [22].
Potential loss of support system and autonomy: AI health apps may empower individuals to manage their own symptoms and take care of their own needs as and when required. This can have a potential impact on the employment of healthcare workers. This can also lead to less dependency on family members and can lead to isolation and behavioural issues [47]. AI agents could affect individual autonomy negatively by narrowing the treatment options and thus restricting patients to make informed consent about the procedure [45].
Challenges in generalization to new populations: AI systems are still far from being able to provide reliable generalizability or clinical application for most types of medical data [45].
Technological challenges: AI models are usually developed by non-medical professionals and thus end users (healthcare providers and patients) have no control in the derivation of the results. This lack of transparency is one of the major challenges in front of government policymakers. Another challenge is AI technology's limitations as they are designed by humans and any minute error in designing AI system can lead to wrong results. In addition, AI systems are not able to handle unstructured information such as medical imaging, which makes up a significant chunk of medical data in healthcare. Lastly, there is no standardization of data which is to be fed into databases and this can lead to different results in different locations [47].
Organizational and managerial challenges: there are various challenges in developing AI like exchange and possession of data along with the potential danger of losing skilled healthcare providers and ground-level workers [41].
Malicious use: although AI can be used to benefit humanity, it is also susceptible to being used maliciously. AI can be used to covertly monitor and analyze motor behaviours that can reveal the identity and secret information of the involved person [43].
Conclusion: in today´s digital age, innovation is essential. AI and related technologies can be very useful adjuncts to healthcare leaders in various aspects of healthcare management. They should not be viewed as a substitute for medical personnel but as a growing necessity that industries must embrace in order to have a competitive advantage. Artificial Intelligence and Human Stupidity run side by side to improve life of none other than stupid humans. AI over shine its master in two important aspects: connectivity and updatability. Because of its transformative nature in healthcare, the healthcare industry is particularly subjected to the potential of AI applications. AI applications have the potential to change not only the treatment and diagnosis processes but also the lifestyles of patients. In this study, we examined the impact AI technology on healthcare, as well as the types of new challenges and opportunities it has provided. We also recommend the establishment of a legal and ethical structure for AI, and drawing a social consensus between all stakeholders.
Cite this article: Shiv Kumar Mudgal et al. Real-world application, challenges and implication of artificial intelligence in healthcare: an essay. Pan African Medical Journal. 2022;43(3). 10.11604/pamj.2022.43.3.33384
Machine learning is a common type of artificial intelligence. Learn more about this exciting technology, how it works, and the major types powering the services and applications we rely on every day.
Machine learning is a subfield of artificial intelligence that uses algorithms trained on data sets to create models that enable machines to perform tasks that would otherwise only be possible for humans, such as categorizing images, analyzing data, or predicting price fluctuations.
Today, machine learning is one of the most common forms of artificial intelligence and often powers many of the digital goods and services we use every day.Â 
In this article, youâll learn more about what machine learning is, including how it works, different types of it, and how it's actually used in the real world. Weâll take a look at the benefits and dangers that machine learning poses, and in the end, youâll find some cost-effective, flexible courses that can help you learn even more about machine learning.Â 
Interested in learning more about machine learning but aren't sure where to start? Consider enrolling in one of these beginner-friendly machine learning courses on Coursera today: 
In Open.AI and Stanford's Machine Learning Specialization, you'll master fundamental AI concepts and develop practical machine-learning skills in as little as two months. 
The University of London's Machine Learning for All course will introduce you to the basics of how machine learning works and guide you through training a machine learning model with a data set on a non-programming-based platform. 
Machine learning is a subfield of artificial intelligence (AI) that uses algorithms trained on data sets to create self-learning models that are capable of predicting outcomes and classifying information without human intervention. Machine learning is used today for a wide range of commercial purposes, including suggesting products to consumers based on their past purchases, predicting stock market fluctuations, and translating text from one language to another.Â 
In common usage, the terms âmachine learningâ and âartificial intelligenceâ are often used interchangeably with one another due to the prevalence of machine learning for AI purposes in the world today. But, the two terms are meaningfully distinct. While AI refers to the general attempt to create machines capable of human-like cognitive abilities, machine learning specifically refers to the use of algorithms and data sets to do so.
Read more: Machine Learning vs. AI: Differences, Uses, and Benefits
Machine learning is typically the most mainstream type of AI technology in use around the world today. Some of the most common examples of machine learning that you may have interacted with in your day-to-day life include: 
Learn more about the real-world applications of machine learning in this lecture from Stanford and DeepLearning.AI's Machine Learning Specialization: 
Read more: 9 Real-Life Machine Learning Examples
Machine learning is both simple and complex.Â 
At its core, the method simply uses algorithms â essentially lists of rules â adjusted and refined using past data sets to make predictions and categorizations when confronted with new data. For example, a machine learning algorithm may be âtrainedâ on a data set consisting of thousands of images of flowers that are labeled with each of their different flower types so that it can then correctly identify a flower in a new photograph based on the differentiating characteristics it learned from other pictures.Â Â 
To ensure such algorithms work effectively, however, they must typically be refined many times until they accumulate a comprehensive list of instructions that allow them to function correctly. Algorithms that have been trained sufficiently eventually become âmachine learning models,â which are essentially algorithms that have been trained to perform specific tasks like sorting images, predicting housing prices, or making chess moves. In some cases, algorithms are layered on top of each other to create complex networks that allow them to do increasingly complex, nuanced tasks like generating text and powering chatbots via a method known as âdeep learning.â
As a result, although the general principles underlying machine learning are relatively straightforward, the models that are produced at the end of the process can be very elaborate and complex.Â Â 
As youâre exploring machine learning, youâll likely come across the term âdeep learning.â Although the two terms are interrelated, they're also distinct from one another.Â 
Machine learning refers to the general use of algorithms and data to create autonomous or semi-autonomous machines. Deep learning, meanwhile, is a subset of machine learning that layers algorithms into âneural networksâ that somewhat resemble the human brain so that machines can perform increasingly complex tasks.Â 
Read more: Deep Learning vs. Machine Learning: Beginnerâs Guide
Several different types of machine learning power the many different digital goods and services we use every day. While each of these different types attempts to accomplish similar goals â to create machines and applications that can act without human oversight â the precise methods they use differ somewhat.Â 
To help you get a better idea of how these types differ from one another, hereâs an overview of the four different types of machine learning primarily in use today.Â 
In supervised machine learning, algorithms are trained on labeled data sets that include tags describing each piece of data. In other words, the algorithms are fed data that includes an âanswer keyâ describing how the data should be interpreted. For example, an algorithm may be fed images of flowers that include tags for each flower type so that it will be able to identify the flower better again when fed a new photograph.Â 
Supervised machine learning is often used to create machine learning models used for prediction and classification purposes.Â 
Unsupervised machine learning uses unlabeled data sets to train algorithms. In this process, the algorithm is fed data that doesn't include tags, which requires it to uncover patterns on its own without any outside guidance. For instance, an algorithm may be fed a large amount of unlabeled user data culled from a social media site in order to identify behavioral trends on the platform.Â 
Unsupervised machine learning is often used by researchers and data scientists to identify patterns within large, unlabeled data sets quickly and efficiently.Â 
Semi-supervised machine learning uses both unlabeled and labeled data sets to train algorithms. Generally, during semi-supervised machine learning, algorithms are first fed a small amount of labeled data to help direct their development and then fed much larger quantities of unlabeled data to complete the model. For example, an algorithm may be fed a smaller quantity of labeled speech data and then trained on a much larger set of unlabeled speech data in order to create a machine learning model capable of speech recognition.Â 
Semi-supervised machine learning is often employed to train algorithms for classification and prediction purposes in the event that large volumes of labeled data is unavailable.Â 
Reinforcement learning uses trial and error to train algorithms and create models. During the training process, algorithms operate in specific environments and then are provided with feedback following each outcome. Much like how a child learns, the algorithm slowly begins to acquire an understanding of its environment and begins to optimize actions to achieve particular outcomes. For instance, an algorithm may be optimized by playing successive games of chess, which allows it to learn from its past successes and failures playing each game.Â 
Reinforcement learning is often used to create algorithms that must effectively make sequences of decisions or actions to achieve their aims, such as playing a game or summarizing an entire text.Â 
Read more: 3 Types of Machine Learning You Should Know
Machine learning is already transforming much of our world for the better. Today, the method is used to construct models capable of identifying cancer growths in medical scans, detecting fraudulent transactions, and even helping people learn languages. But, as with any new society-transforming technology, there are also potential dangers to know about.Â 
At a glance, here are some of the major benefits and potential drawbacks of machine learning:Â 
AI and machine learning are quickly changing how we live and work in the world today. As a result, whether youâre looking to pursue a career in artificial intelligence or are simply interested in learning more about the field, you may benefit from taking a flexible, cost-effective machine learning course on Coursera.Â 
In DeepLearning.AI and Stanfordâs Machine Learning Specialization, youâll master fundamental AI concepts and develop practical machine learning skills in the beginner-friendly, three-course program by AI visionary Andrew Ng.
In IBMâs Machine Learning Professional Certificate, youâll master the most up-to-date practical skills and knowledge machine learning experts use in their daily roles, including how to use supervised and unsupervised learning to build models for a wide range of real-world purposes.Â 
Get Started with AI
Artificial Intelligence (AI) in medical diagnosis is revolutionizing healthcare by significantly improving the accuracy and efficiency of diagnostic processes. 
The integration of AI not only streamlines diagnosis but also increases healthcare accessibility, underscoring the technology's critical role in advancing medical care and patient outcomes.
The journey of Artificial Intelligence (AI) in healthcare is marked by groundbreaking innovations and significant milestones that have fundamentally transformed medical diagnosis. The initial exploration of AI in healthcare began with simple models focused on pattern recognition—tools designed to mimic human decision-making processes in diagnostic tasks. 
One of the key developments in AI healthcare has been the enhancement of diagnostic accuracy and speed. Algorithms now routinely analyze medical data much faster than human practitioners, with a level of precision that often surpasses human capabilities. 
This progression from basic diagnostic aids to advanced, real-time decision-support systems represents a major leap forward in medical technology.
The impact of these AI developments in healthcare is profound. They not only improve patient outcomes but also optimize the allocation of healthcare resources, making treatments more cost-effective and accessible. 
The automation of routine tasks frees medical professionals to focus more on patient care rather than administrative duties, enhancing the overall efficiency of healthcare services.
As AI continues to evolve, its potential to further revolutionize medical diagnosis remains vast, promising even greater advancements in the accuracy, efficiency, and personalization of medical care.
Artificial Intelligence (AI) is dramatically reshaping the field of medical imaging, bringing about unprecedented improvements in the way medical images are captured, interpreted, and utilized. At the forefront of this revolution is AI’s ability to enhance the accuracy of imaging techniques, transforming them into more powerful diagnostic tools.
AI algorithms can analyze medical images with astonishing accuracy in just seconds. This rapid analysis significantly decreases the workload for radiologists, who traditionally spend extensive time detecting and characterizing abnormalities. Such efficiency is crucial, particularly in high-volume medical settings where time is often of the essence.
AI in diagnosis can analyze medical images, such as X-rays, MRIs, and CT scans, to identify abnormalities and assist healthcare professionals in making accurate diagnoses in mere seconds. AI algorithms can compare them to vast databases of similar cases and provide valuable insights.
The integration of AI in diagnostic imaging not only improves the accuracy of diagnosis but also increases efficiency exponentially. This enhancement allows healthcare facilities to manage their patient load more effectively, reducing wait times and potentially increasing the accuracy of diagnostic outcomes.
Highlighting the impact of AI in this field, the American Hospital Association notes that AI’s ability to process a vast amount of both structured and unstructured data has led to nearly 400 Food and Drug Administration (FDA) approvals of AI algorithms for the radiology field.
AI chatbots, employing sophisticated algorithms to simulate human conversation and decision-making, have become vital tools in the landscape of healthcare technology. 
These AI-driven systems are designed to interact with patients, gather medical data, and assist healthcare providers by offering preliminary diagnostic support and patient management.
AI chatbots function through natural language processing and machine learning, enabling them to understand and respond to human input with increasing accuracy. In healthcare settings, they:
A standout example in this field is the Docus AI Health Assistant. This AI chatbot enhances the patient experience by delivering personalized health assistance based on a detailed analysis of an individual’s medical history and current symptoms. Key features include:
AI chatbots in medical diagnosis bring numerous benefits but also pose certain challenges:
As AI technology continues to evolve, its implications for the future of medical diagnosis are both vast and promising. With ongoing advancements, AI is set to further revolutionize healthcare delivery, diagnosis, and patient management.
Emerging AI technologies in healthcare are focused on enhancing diagnostic precision and expanding the scope of AI applications. Innovations include:
The trajectory of AI in healthcare suggests significant shifts in how medical services will be delivered:
The successful integration of AI into medical diagnosis hinges on the collaboration between diverse fields:
Talk to Docus AI Doctor, generate health reports, get them validated by Top Doctors from the US and Europe.
Natural Language Processing (NLP) is one of the hottest areas of artificial intelligence (AI) thanks to applications like text generators that compose coherent essays, chatbots that fool people into thinking they’re sentient, and text-to-image programs that produce photorealistic images of anything you can describe. Recent years have brought a revolution in the ability of computers to understand human languages, programming languages, and even biological and chemical sequences, such as DNA and protein structures, that resemble language. The latest AI models are unlocking these areas to analyze the meanings of input text and generate meaningful, expressive output.
Natural language processing (NLP) is the discipline of building machines that can manipulate human language — or data that resembles human language — in the way that it is written, spoken, and organized. It evolved from computational linguistics, which uses computer science to understand the principles of language, but rather than developing theoretical frameworks, NLP is an engineering discipline that seeks to build technology to accomplish useful tasks. NLP can be divided into two overlapping subfields: natural language understanding (NLU), which focuses on semantic analysis or determining the intended meaning of text, and natural language generation (NLG), which focuses on text generation by a machine. NLP is separate from — but often used in conjunction with — speech recognition, which seeks to parse spoken language into words, turning sound into text and vice versa.
NLP is an integral part of everyday life and becoming more so as language technology is applied to diverse fields like retailing (for instance, in customer service chatbots) and medicine (interpreting or summarizing electronic health records). Conversational agents such as Amazon’s Alexa and Apple’s Siri utilize NLP to listen to user queries and find answers. The most sophisticated such agents — such as GPT-3, which was recently opened for commercial applications — can generate sophisticated prose on a wide variety of topics as well as power chatbots that are capable of holding coherent conversations. Google uses NLP to improve its search engine results, and social networks like Facebook use it to detect and filter hate speech. 
NLP is growing increasingly sophisticated, yet much work remains to be done. Current systems are prone to bias and incoherence, and occasionally behave erratically. Despite the challenges, machine learning engineers have many opportunities to apply NLP in ways that are ever more central to a functioning society.
NLP models work by finding relationships between the constituent parts of language — for example, the letters, words, and sentences found in a text dataset. NLP architectures use various methods for data preprocessing, feature extraction, and modeling. Some of these processes are: 
Deep learning is also used to create such language models. Deep-learning models take as input a word embedding and, at each time state, return the probability distribution of the next word as the probability for every word in the dictionary. Pre-trained language models learn the structure of a particular language by processing a large corpus, such as Wikipedia. They can then be fine-tuned for a particular task. For instance, BERT has been fine-tuned for tasks ranging from fact-checking to writing headlines. 
Most of the NLP tasks discussed above can be modeled by a dozen or so general techniques. It’s helpful to think of these techniques in two categories: Traditional machine learning methods and deep learning methods. 
Traditional Machine learning NLP techniques: 
Deep learning NLP Techniques: 
Over the years, many NLP models have made waves within the AI community, and some have even made headlines in the mainstream news. The most famous of these have been chatbots and language models. Here are some of them:
NLP has been at the center of a number of controversies. Some are centered directly on the models and their outputs, others on second-order concerns, such as who has access to these systems, and how training them impacts the natural world. 
“Nonsense on stilts”: Writer Gary Marcus has criticized deep learning-based NLP for generating sophisticated language that misleads users to believe that natural language algorithms understand what they are saying and mistakenly assume they are capable of more sophisticated reasoning than is currently possible.
If you want to learn more about NLP, try reading research papers. Work through the papers that introduced the models and techniques described in this article. Most are easy to find on arxiv.org. You might also take a look at these resources: 
We highly recommend learning to implement basic algorithms (linear and logistic regression, Naive Bayes, decision trees, and vanilla neural networks) in Python. The next step is to take an open-source implementation and adapt it to a new dataset or task. 
NLP is one of the fast-growing research domains in AI, with applications that involve tasks including translation, summarization, text generation, and sentiment analysis. Businesses use NLP to power a growing number of applications, both internal — like detecting insurance fraud, determining customer sentiment, and optimizing aircraft maintenance — and customer-facing, like Google Translate. 
Aspiring NLP practitioners can begin by familiarizing themselves with foundational AI skills: performing basic mathematics, coding in Python, and using algorithms like decision trees, Naive Bayes, and logistic regression. Online courses can help you build your foundation. They can also help as you proceed into specialized topics. Specializing in NLP requires a working knowledge of things like neural networks, frameworks like PyTorch and TensorFlow, and various data preprocessing techniques. The transformer architecture, which has revolutionized the field since it was introduced in 2017, is an especially important architecture.
NLP is an exciting and rewarding discipline, and has potential to profoundly impact the world in many positive ways. Unfortunately, NLP is also the focus of several controversies, and understanding them is also part of being a responsible practitioner. For instance, researchers have found that models will parrot biased language found in their training data, whether they’re counterfactual, racist, or hateful. Moreover, sophisticated language models can be used to generate disinformation. A broader concern is that training large models produces substantial greenhouse gas emissions.
This page is only a brief overview of what NLP is all about. If you have an appetite for more, DeepLearning.AI offers courses for everyone in their NLP journey, from AI beginners and those who are ready to specialize. No matter your current level of expertise or aspirations, remember to keep learning!
Because of this, a subfield of artificial intelligence and machine learning called natural language processing, or NLP has emerged as one of data science’s most popular subjects.
Just imagine how much information we may get from the speech and text data we come across on a daily basis. In order to understand the potential of natural language processing and how it affects our lives, we must first look at its applications. As a result, in this blog post, we will go over the Top 10 Applications of Natural Language Processing.
Natural language processing (NLP) is how machines understand and translate human language.
Businesses rely on natural language processing to make sense of enormous volumes of unstructured text, such as email, social media interactions, online chats, survey replies, voice calls, and many other types of data.
Today’s machines can examine a large amount of data reliably and without weariness. Finally, it comes down to teaching a computer to converse with humans and perform a variety of language-related activities.
To create powerful NLP models, you must first collect high-quality data.
By incorporating the example of NLP in daily life applications into the workplace, businesses may leverage its significant time-saving capabilities to return time to their data teams. They may now focus on analyzing data to uncover what’s useful in the midst of the turmoil, gaining vital insights that will help them make the correct business decisions.
Here are the top 10 applications of AI in natural language processing:
Understanding natural language can be challenging for machines, especially when dealing with human opinions, often expressed through sarcasm and irony. However, sentiment analysis has the capability to discern subtle emotional nuances and opinions, determining their positivity or negativity. Real-time sentiment analysis enables the monitoring of social media mentions, allowing for the proactive management of negative comments before they escalate. It also provides insights into customer reactions to ongoing marketing campaigns or recent product launches, offering an overall understanding of the public sentiment toward your company.
Periodic sentiment analysis is one of the applications of NLP in artificial intelligence that allows for a deeper comprehension of customer preferences and concerns related to specific aspects of your business. For instance, it can reveal that customers appreciate a new feature but are dissatisfied with customer service. These insights serve as valuable inputs for making informed decisions and identifying areas for improvement in your business.
Text classification, a facet of text analysis that encompasses sentiment analysis, entails the automated comprehension, processing, and categorization of unstructured text.
Imagine having to analyze numerous open-ended responses from your recent NPS survey manually – a time-consuming and potentially costly endeavor. However, what if you could train a natural language processing model to swiftly categorize your data within seconds, using predefined categories and applying your own criteria?
For instance, you could employ a topic classifier tailored for NPS survey responses. This classifier would automatically tag your data based on topics such as Customer Support, Features, Ease of Use, and Pricing. This streamlined approach enhances efficiency and facilitates the extraction of valuable insights from your data.
While traditional question-answering systems adhere to predefined rules, AI-powered chatbots and virtual assistants possess the ability to learn from each interaction, adapting their responses accordingly. Notably, these intelligent systems continuously improve over time through learning from their interactions.
Text extraction, also referred to as information extraction, involves the automatic identification of specific details within a text, encompassing names, companies, locations, and more, commonly known as named entity recognition. Additionally, it includes extracting keywords and predefined features like product serial numbers and models.
One practical application of text extraction is in managing incoming support tickets, where specific data such as company names, order numbers, and email addresses can be identified without the need to manually open and read each ticket. Another use case for text extraction is in data entry. For example, individuals and organizations can use NLP-based data extraction tools to quickly extract data from images, documents, invoices, bank statements, etc. Extracted information can be seamlessly integrated into a database through automated triggers, streamlining the process.
The application of NLP in machine learning text extraction becomes evident. Combining keyword extraction with sentiment analysis offers an enhanced understanding of customer sentiments. This synergy allows you to identify the most frequently used words by customers to express negativity toward your product or service, providing valuable insights for machine learning applications.
Machine translation (MT) stands out as one of the earliest applications of natural language processing. Despite the declaration of Facebook’s translations as superhuman, the challenge for machine translation lies in grasping context.
Nevertheless, for those who have been consistent users of Google Translate over the years, the significant progress it has made is evident, thanks to substantial advancements in neural networks and the increased availability of extensive datasets.
The application of natural language processing, especially in the context of automated translation, proves invaluable in business settings. It streamlines communication, enables companies to connect with broader audiences, and swiftly and cost-effectively comprehends foreign documentation.
Leveraging Natural Language Processing (NLP) can be a game-changer for marketers seeking deeper insights into their customers, ultimately enhancing their ability to craft more impactful strategies.
By delving into unstructured data and analyzing elements such as topics, sentiment, keywords, and intent, marketers can significantly augment their market research efforts. This approach not only illuminates current trends but also unveils potential business opportunities. Moreover, the ability to discern customer pain points and monitor competitor activities through data analysis adds another layer of strategic advantage.
Harnessing the power of natural language processing, speech recognition technology converts spoken language into a machine-readable format.
Speech recognition systems are integral to virtual assistants like Siri, Alexa, and Google Assistant. Beyond consumer applications, the business landscape is witnessing an increasing adoption of speech recognition, highlighting diverse applications and the broader context of the application of AI in natural language processing. For instance, integrating speech-to-text capabilities into business software enables companies to automate call transcriptions, streamline email communications, and even facilitate language translation.
The synergy between artificial intelligence (AI) and natural language processing in speech recognition applications underscores the evolution of technology, enabling more seamless and efficient communication. This not only enhances the user experience in virtual assistants but also presents businesses with innovative ways to boost productivity and streamline communication workflows in the broader framework of the application of AI in natural language processing.
The Human Resource department holds a crucial role in every organization, tasked with the pivotal responsibility of selecting the most suitable employees. In today’s highly competitive environment, recruiters often face the daunting task of reviewing numerous resumes, sometimes numbering in the hundreds or thousands, for a single position. This process of filtering resumes and shortlisting candidates can be time-consuming. However, there’s a solution – automation through natural language processing (NLP).
By leveraging NLP, recruiters can streamline the process of identifying the right candidates. It is one of the important applications of NLP in AI. This means they no longer have to manually sift through each resume to filter potential candidates. Techniques like information extraction, coupled with named entity recognition, enable the extraction of essential details such as skills, names, locations, and education from resumes. These extracted features can then be used to represent candidates in a feature space, allowing for classification into categories such as fit or not fit for a specific role. Alternatively, candidates could be recommended for different roles based on the content of their resumes.
Among the various types of email filters, the spam filter stands out as a widely recognized example. Spam accounts for approximately 85% of global email traffic, underscoring the vital role that email filters play. How can the applications of natural language processing (NLP) contribute to the effectiveness of these filters? Over the years, you’ve likely observed the evolution of email filters aimed at helping users maintain an organized inbox. A prime illustration is Gmail, which provides distinct categories like primary, promotions, updates, and social for email organization.
At the heart of these email filters lies natural language processing, serving as a fundamental element. As emails land in your inbox, NLP techniques, including keyword extraction and text classification, play a crucial role in automatically scanning and categorizing the emails. This showcases the impactful example of NLP in daily life applications in enhancing the efficiency and organization of email filters.
Moreover, these automated systems contribute valuable data for future interactions and enhancements. Don’t be astonished if, in the near future, these answering machines start responding with a more human-like voice, offering a personalized touch to address your inquiries. The evolution of customer support mechanisms continues to embrace technological advancements, aiming to provide seamless and enhanced assistance to customers.
In conclusion, the applications of Natural Language Processing (NLP) showcased in this blog underscore its transformative role across diverse fields. From deciphering sentiment and classifying text to powering chatbots, and virtual assistants, and even revolutionizing the hiring process, NLP has become an indispensable tool for businesses seeking efficiency, automation, and improved decision-making. Its impact extends to market intelligence, language translation, and customer support, demonstrating the versatility and growing significance of NLP in shaping our technological landscape.
For those eager to harness the potential of NLP and delve into the realm of Artificial Intelligence, SoluLab stands as a leading AI application development company. With a proven track record in delivering innovative AI solutions, SoluLab offers expertise in developing and implementing cutting-edge NLP applications. Whether it’s enhancing customer interactions, automating processes, or extracting valuable insights from data, SoluLab’s AI development services provide tailored solutions to meet the evolving needs of businesses across various industries. As pioneers in the field, SoluLab’s AI developers bring a wealth of experience and proficiency to propel organizations into a future where the seamless integration of NLP transforms the way we interact with and derive value from technology.
NLP is a branch of artificial intelligence that focuses on the interaction between computers and human languages. It is crucial as it enables machines to understand, interpret, and generate human-like language, opening avenues for automation, efficiency, and improved decision-making.
NLP plays a vital role in market intelligence by analyzing topics, sentiment, and keywords in unstructured data. This allows businesses to gain insights into trends, customer sentiments, and potential business opportunities, facilitating informed decision-making.
In customer support, NLP automates responses to queries, providing efficient and personalized assistance. It also contributes valuable data for future improvements, enhancing the overall customer experience.
SoluLab, a renowned AI development company, offers expertise in developing and implementing NLP applications. Our AI development services cater to businesses looking to leverage the power of NLP for improved communication, automation, and data extraction, ensuring tailored solutions to meet diverse industry needs.
Learn how AI is transforming free slot games with personalized gameplay, enhanced security, and real-time adjustments for a unique player experience.
Natural Language Processing (NLP) is a revolutionary field of artificial intelligence that focuses on bridging the gap between human language and computer understanding. Over the years, NLP has witnessed significant advancements. For example, it unlocks the potential to interpret, generate, and translate human language. As a result, this blog post will explore some critical advances in NLP. This will include sentiment analysis, text generation, language translation, and applying NLP across various industries and domains.
Sentiment analysis, also known as opinion mining, is a powerful NLP technique that enables computers to determine the sentiment or emotional tone behind a text. For example, whether it’s customer reviews, social media posts, or survey responses, sentiment analysis can extract valuable insights from vast textual data.
Advancements in sentiment analysis techniques have improved accuracy in identifying sentiments such as positive, negative, neutral, or even more nuanced emotions like joy, sadness, anger, and fear. Furthermore, businesses can leverage sentiment analysis to understand customer feedback. This will allow them to measure brand perception and make data-driven decisions to improve their products and services.
Text generation is another groundbreaking application of NLP, wherein machines can generate human-like text based on patterns learned from vast corpora of written data. Chatbots and virtual assistants are prime examples of text generation systems. They can understand and respond to natural language queries, enabling more intuitive and interactive user experiences.
Furthermore, NLP-powered text generation models have shown impressive capabilities in creative writing, such as generating poetry, stories, and even code snippets. These models can assist writers, copywriters, and content creators, providing suggestions or automating certain parts of the writing process.
Language translation has been a long-standing challenge in NLP. However, significant advancements have been made in recent years. For example, neural machine translation models have proven highly effective in translating text between different languages with remarkable accuracy.
These NLP models have not only improved the quality of translation but also reduced the time and effort required for human translators. That has opened up possibilities for cross-border communication, global collaboration, and enhanced accessibility to information for non-native speakers.
In the healthcare industry, NLP transforms how medical data is processed and analyzed. NLP-powered systems can extract valuable information from medical records, research papers, and clinical notes. Hence, this aids diagnosis, treatment recommendations, and medical research. NLP also plays a crucial role in improving patient outcomes through better healthcare monitoring and personalized treatment plans.
Natural Language Processing revolutionizes customer service and support by enabling intelligent chatbots and virtual assistants. These conversational agents can understand and respond to customer queries, resolving issues promptly and efficiently. As a result, that enhances customer satisfaction and reduces the workload on support teams, allowing them to focus on more complex tasks.
In the e-commerce and marketing domains, NLP is used for sentiment analysis of customer reviews and social media posts to understand consumer preferences and sentiments toward products and brands. Companies can leverage that information to improve product offerings, optimize marketing strategies, and enhance customer engagement.
NLP is making significant inroads into the financial sector, helping analyze vast amounts of financial data, news articles, and market sentiment to make informed investment decisions. Furthermore, these financial institutions can apply sentiment analysis to gauge public perception and predict market trends, benefiting traders and investors.
Natural Language Processing has come a long way, empowering machines to comprehend, generate, and translate human language with remarkable accuracy and sophistication. Advancements in sentiment analysis, text generation, and language translation have opened up exciting possibilities across various industries and domains.
As NLP continues to evolve, we can expect further breakthroughs that will revolutionize communication, data analysis, and decision-making processes. Embracing NLP in diverse fields will lead to more efficient and effective interactions between humans and machines, paving the way for a future where language is no longer a barrier but a bridge to innovative solutions and enhanced experiences.
Ever wondered how Siri knows what you’re saying? Or why Google Maps can lead you to where you want to go? The answer is Natural Language Processing (NLP). It’s a cool part of artificial intelligence (AI) that lets machines understand and talk like people do. This has changed how we use technology in big ways.
The perks of using NLP tech are huge. It helps with analyzing data better, saving money, and making customers happier. NLP can look at feelings in public and brand talks, which gives useful info to companies. Chatbots, for example, can talk to customers really well. A study in 2019 found that 65% of people who deal with customer service think chatbots are good at understanding what customers need.
Natural language processing or NLP is a key part of artificial intelligence. It helps computers understand spoken and written human language. This is making it more and more important in many sectors.
NLP is a mix of computational linguistics and machine learning. It teaches machines to catch onto human language details. This comes in handy in areas like “sentiment analysis”. Here, phrases like “error” or “not worth the price” are seen as negative signs. They help understand if customers are happy.
The tech behind NLP has grown a lot. It started with simple rule-based methods but now uses complex machine and deep learning. A good example is Google Search. It uses NLP to guess what users will type next. This helps by suggesting search terms, making it very useful.
NLP uses various basic methods. These include content sorting and machine translation. Sorting helps arrange text data. This is great for news and online stores. On the other hand, better translations have improved how we work with different written materials. This includes tech and legal papers.
Another technique is Named Entity Recognition or NER. It finds and sorts named things like people, places, and companies in text data. This is very good for pulling out important details.
Stuff like sentiment analysis and chatbots are now key in fields like customer service and healthcare. They save time and effort by automating certain tasks. Chatbots, for example, are really smart and are good at grasping what people need. This has shown how useful NLP is in the real world.
Sentiment analysis is a tool in the world of tech that figures out if text sounds happy, sad, or just okay. It’s great for lots of tasks, like checking what people think, seeing how they feel on social media, and looking at general opinions. For companies, this tech is a goldmine. It helps them see what their customers like and don’t like, so they can make things better.
This method uses smart models and language techniques to break down text. It all begins with preparing the text, like cutting it into parts and removing words that don’t add much. Then, machines are trained to spot different feelings in the text, thanks to tons of examples.
Businesses use sentiment analysis to keep an eye on how people feel about their brand. This info is super helpful for making ads that people really connect with and for improving what they offer. For scientists and others studying public ideas, it’s a fast way to understand what many people think.
There’s plenty of software out there made just for sentiment analysis. Tools like SpaCy and Gensim are top picks for digging through what customers say. With these, companies can stay up-to-date on opinions and make smart moves based on what people are talking about.
Amazon’s Alexa and Apple’s Siri are leading the pack in voice AI. They can understand language well enough to set reminders, check the weather, or even suggest music. Amazon’s Alexa devices are everywhere now, showing how much people enjoy talking to these assistants.
The world of machine translation has grown a lot since the 1950s. Then, Georgetown and IBM started working on it. Now, with natural language processing, tools for translating have become really important all over the world.
Today’s machine translation can handle both text and voice in many languages. Because of NLP projects and machine learning, tools like Google Translate and Microsoft Translator give good, relevant translations. This helps with business communication and traveling. Now, we can talk to people globally without trouble.
Email management AI has changed how companies deal with emails. It’s estimated that 85% of global email traffic is spam. So, there’s a big need for systems that can spot spam. Using Natural Language Processing (NLP), these systems not only block spam but also sort emails into useful categories. This helps businesses stay focused on important messages and improve their work.
Tools such as MonkeyLearn offer powerful AI for email management. Gmail is a good example – it’s able to spot different email types automatically. This is essential for keeping work moving smoothly. NLP is also used by companies like Levity to fine-tune sorting for specific business needs.
NLP-driven search engines have changed how we use the web. They use natural language processing to figure out what we want online. Then, they give us search results that match our needs well.
Tools like predictive text and autocomplete are also big on NLP. They guess what we’re going to type next as we start searching. This tech is behind helpful tools like Grammarly and Smart Compose in Gmail, which make writing easier.
NLP in customer service has changed how businesses interact with customers. Now, they can use AI to handle support. This way, their systems work better to meet customer wants, using things like chatbots.
Social listening and survey analytics are changing how businesses understand customers. They use NLP tools to make sense of long responses quickly. Before, doing this much analysis by hand was just too slow.
Today, companies can analyze customer feedback much faster. They do this with AI and NLP, like in MonkeyLearn. This method is faster and more accurate, making decisions easier.
NLP software is changing how many industries work, thanks to its AI language skills. Take eCommerce, for example. It now uses semantic search to help people find what they need. This has lowered cart abandonment rates from 40% to 2%, showing NLP’s power to boost sales and user satisfaction.
Then there are smart assistants like Siri, Alexa, and Google Assistant. They’re changing how we interact with technology. They understand complex commands and can assist in tasks like shopping, pushing the boundaries of NLP in our daily lives.
A great read to understand NLP better is “Real-World Natural Language Processing” by Masato Hagiwara. This book is for Python programmers and covers key NLP topics without expecting you to be a machine learning expert. Thanks to Manning Publications, you can access this book through different subscriptions and dive deep into NLP.
Overall, NLP is making a big difference in places like eCommerce and customer service. The examples shared here show NLP’s real impact, fueled by sophisticated AI language features.
Natural Language Processing (NLP) is a key tech driving change in many fields. It helps with sentiment analysis and better machine translations. NLP powers voice assistants like Siri and Alexa, making our daily digital life easier. It’s also key in sorting news and products for sites.
With more AI and NLP together, new tools like Actioner for Slack are making work smoother. NLP isn’t just changing customer relations. It makes information more open, breaking down language barriers. This tech is leading us towards more personalized and instant interactions, revolutionizing how we go about daily life and business.
Explore how AI in Transportation revolutionizes the way we move, enhancing everything from Autonomous Vehicles to Smart Logistics.
				Read More AI in Transportation: From Autonomous Vehicles to Smart LogisticsContinue
Discover how AI in Marketing revolutionizes engagement and personalization, tailoring unique experiences for every customer.
				Read More AI in Marketing: Enhancing Customer Engagement and PersonalizationContinue
Explore the intersection of AI advancements and ethical practices, ensuring responsible innovation and societal well-being.
				Read More The Ethics of AI: Balancing Innovation and ResponsibilityContinue
Discover the top AI tools for business that boost productivity and efficiency. Harness cutting-edge artificial intelligence for smarter operations.
				Read More Top AI Tools for Business: Enhancing Productivity and EfficiencyContinue
Explore the evolving relationship between AI vs. Human Intelligence: Complementary or Competitive? Unpack the synergy and rivalry.
				Read More AI vs. Human Intelligence: Complementary or Competitive?Continue
Explore the future of tech with AI Trends to Watch in 2027: What’s Next for Artificial Intelligence? Discover upcoming innovations & challenges.
				Read More AI Trends to Watch in 2024: What’s Next for Artificial Intelligence?Continue
While natural language processing isn’t a new science, the technology is rapidly advancing thanks to an increased interest in human-to-machine communications, plus an availability of big data, powerful computing and enhanced algorithms.
Indeed, programmers used punch cards to communicate with the first computers 70 years ago. This manual and arduous process was understood by a relatively small number of people. Now you can say, “Alexa, I like this song,” and a device playing music in your home will lower the volume and reply, “OK. Rating saved,” in a humanlike voice. Then it adapts its algorithm to play that song – and others like it – the next time you listen to that music station.
Let’s take a closer look at that interaction. Your device activated when it heard you speak, understood the unspoken intent in the comment, executed an action and provided feedback in a well-formed English sentence, all in the space of about five seconds. The complete interaction was made possible by NLP, along with other AI elements such as machine learning and deep learning.
Discover how machines can learn to understand and interpret the nuances of human language; how AI, natural language processing and human expertise work together to help humans and machines communicate and find meaning in data; and how NLP is being used in multiple industries.
Kia Motors America regularly collects feedback from vehicle owner questionnaires to uncover quality issues and improve products. But understanding and categorizing customer responses can be difficult. With natural language processing from SAS, KIA can make sense of the feedback. An NLP model automatically categorizes and extracts the complaint type in each response, so quality issues can be addressed in the design and manufacturing process for existing and future vehicles.
Natural language processing helps computers communicate with humans in their own language and scales other language-related tasks. For example, NLP makes it possible for computers to read text, hear speech, interpret it, measure sentiment and determine which parts are important. 
Today’s machines can analyse more language-based data than humans, without fatigue and in a consistent, unbiased way. Considering the staggering amount of unstructured data that’s generated every day, from medical records to social media, automation will be critical to fully analyse text and speech data efficiently.
While supervised and unsupervised learning, and specifically deep learning, are now widely used for modelling human language, there’s also a need for syntactic and semantic understanding and domain expertise that are not necessarily present in these machine learning approaches. NLP is important because it helps resolve ambiguity in language and adds useful numeric structure to the data for many downstream applications, such as speech recognition or text analytics.
Learn how natural language processing is used across industries
How are organisations around the world using artificial intelligence and NLP? What are the adoption rates and future plans for these technologies? What are the budgets and deployment plans? And what business problems are being solved with NLP algorithms? Find out in this report from TDWI.
Government agencies are bombarded with text-based data, including digital and paper documents. Using technologies like NLP, text analytics and machine learning, agencies can reduce cumbersome, manual processes while addressing citizen demands for transparency and responsiveness, solving workforce challenges and unleashing new insights from data.
Text analytics is a type of natural language processing that turns text into data for analysis. Learn how organisations in banking, health care and life sciences, manufacturing and government are using text analytics to drive better customer experiences, reduce fraud and improve society.
Natural language processing includes many different techniques for interpreting human language, ranging from statistical and machine learning methods to rules-based and algorithmic approaches. We need a broad array of approaches because the text- and voice-based data varies widely, as do the practical applications. 
How can you find answers in large volumes of textual data? By combining machine learning with natural language processing and text analytics. Find out how your unstructured data can be analysed to identify issues, evaluate sentiment, detect emerging trends and spot hidden opportunities.
Natural language processing goes hand in hand with text analytics, which counts, groups and categorises words to extract structure and meaning from large volumes of content. Text analytics is used to explore textual content and derive new variables from raw text that may be visualised, filtered, or used as inputs to predictive models or other statistical methods.
A subfield of NLP called natural language understanding (NLU) has begun to rise in popularity because of its potential in cognitive and AI applications. NLU goes beyond the structural understanding of language to interpret intent, resolve context and word ambiguity, and even generate well-formed human language on its own. NLU algorithms must tackle the extremely complex problem of semantic interpretation – that is, understanding the intended meaning of spoken or written language, with all the subtleties, context and inferences that we humans are able to comprehend.
The evolution of NLP toward NLU has a lot of important implications for businesses and consumers alike. Imagine the power of an algorithm that can understand the meaning and nuance of human language in many contexts, from medicine to law to the classroom. As the volumes of unstructured information continue to grow exponentially, we will benefit from computers’ tireless ability to help us make sense of it all.
Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence. It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics. Typically data is collected in text corpora, using either rule-based, statistical or neural-based approaches in machine learning and deep learning.
Major tasks in natural language processing are speech recognition, text classification, natural-language understanding, and natural-language generation.
Natural language processing has its roots in the 1950s.[1] Already in 1950, Alan Turing published an article titled "Computing Machinery and Intelligence" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.
The premise of symbolic NLP is well-summarized by John Searle's Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.
Up until the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[8]
In 2003, word n-gram model, at the time the best statistical algorithm, was outperformed by a multi-layer perceptron (with a single hidden layer and context length of several words trained on up to 14 million of words with a CPU cluster in language modelling) by Yoshua Bengio with co-authors.[9]
In 2010, Tomáš Mikolov (then a PhD student at Brno University of Technology) with co-authors applied a simple recurrent neural network with a single hidden layer to language modelling,[10] and in the following years he went on to develop Word2vec. In the 2010s, representation learning and deep neural network-style (featuring many hidden layers) machine learning methods became widespread in natural language processing. That popularity was due partly to a flurry of results showing that such techniques[11][12] can achieve state-of-the-art results in many natural language tasks, e.g., in language modeling[13] and parsing.[14][15] This is increasingly important in medicine and healthcare, where NLP helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care[16] or protect patient privacy.[17]
Symbolic approach, i.e., the hand-coding of a set of rules for manipulating symbols, coupled with a dictionary lookup, was historically the first approach used both by AI in general and by NLP in particular:[18][19] such as by writing grammars or devising heuristic rules for stemming.
Machine learning approaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach: 
In the late 1980s and mid-1990s, the statistical approach ended a period of AI winter, which was caused by the inefficiencies of the rule-based approaches.[20][21]
Only the introduction of hidden Markov models, applied to part-of-speech tagging, announced the end of the old rule-based approach.
A major drawback of statistical methods is that they require elaborate feature engineering. Since 2015,[22] the statistical approach has been replaced by the neural networks approach, using semantic networks[23] and word embeddings to capture semantic properties of words.  
The following is a list of some of the most commonly researched tasks in natural language processing. Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.
Though natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. A coarse division is given below.
As an example, George Lakoff offers a methodology to build natural language processing (NLP) algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics,[50] with two defining aspects:
Ties with cognitive linguistics are part of the historical heritage of NLP, but they have been less frequently addressed since the statistical turn during the 1990s. Nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar,[53] functional grammar,[54] construction grammar,[55] computational psycholinguistics and cognitive neuroscience (e.g., ACT-R), however, with limited uptake in mainstream NLP (as measured by presence on major conferences[56] of the ACL). More recently, ideas of cognitive NLP have been revived as an approach to achieve explainability, e.g., under the notion of "cognitive AI".[57] Likewise, ideas of cognitive NLP are inherent to neural models multimodal NLP (although rarely made explicit)[58] and developments in artificial intelligence, specifically tools and technologies using large language model approaches[59] and new directions in artificial general intelligence based on the free energy principle[60] by British neuroscientist and theoretician at University College London Karl J. Friston.
In the contemporary landscape where human-computer interaction holds increasing significance, Natural Language Processing (NLP) emerges as a pivotal force, facilitating a seamless connection between humans and machines. The enchantment lies in envisioning a computer not only comprehending spoken words but also responding meaningfully — a feat made possible by the magic of NLP.
At the heart of NLP techniques lies tokenization, a central process in the NLP pipeline. This process involves disassembling a given text into its smallest units, known as tokens, encompassing punctuation marks, words, and even numbers. The significance of tokenization becomes apparent in its ability to analyze word frequency within the entire text, forming the basis for creating models based on these frequencies. It also facilitates labeling tokens based on their word type, a concept crucial for Part of Speech Tagging.
Stemming, a technique in the NLP toolkit, trims prefixes and suffixes from words, revealing their base form. This process proves invaluable for tasks such as text classification or sentiment analysis, simplifying and standardizing text data by focusing on core meanings.
Contrasting with stemming, lemmatization considers the contextual and meaningful aspects of words, producing valid words from the language’s lexicon. It retains words in their base form, considering grammatical context and meaning. Both stemming and lemmatization are fundamental techniques, contributing to the effective analysis of textual data in various NLP applications.
This process is a crucial step in natural language processing, as it enables computers to understand the syntactic and semantic structure of text, facilitating various language analysis tasks.
Understanding these fundamental parts of speech is essential for analyzing and interpreting language, both for humans and in natural language processing applications.
As we conclude our journey through the enchanting realms of Tokenization, POS Tagging, and Named Entity Recognition (NER), we recognize these techniques as more than mere tools. They are the keys unlocking the language-machine connection, empowering us to navigate the evolving world of NLP. By mastering these techniques, we harness the full potential of language and technology, ensuring smoother and more intuitive communication with machines. We extend our gratitude for joining us on this insightful journey through the intricate landscape of NLP techniques.
Tokenization enables us to analyze the frequency of words within the entire text by segmenting it into these tokens. This, in turn, forms the basis for creating models based on these word frequencies. Additionally, tokenization allows us to label tokens according to their word type, a concept we will dig into further when discussing Part of Speech Tagging.
We can use stemming to prepare text data for various NLP tasks, such as text classification or sentiment analysis, by reducing the complexity of the words used. It’s a fundamental technique that plays a role in simplifying and standardizing text data.
This process is a crucial step in natural language processing, as it enables computers to understand the syntactic and semantic structure of text, facilitating various language analysis tasks.
Understanding these fundamental parts of speech is essential for analyzing and interpreting language, both for humans and in natural language processing applications.
These techniques aren’t just tools; they’re the keys to understanding the language-machine connection. In the ever-evolving world of NLP, mastering these techniques empowers us to unlock the full potential of language and technology, making our communication with machines smoother and more intuitive.
Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data of any language.
In this article, we will try to study Natural language Processing with libraries like Spacy and NLTK.
You may treat the above concepts as basic building blocks of Natural Language Processing and this understanding and implementing these concepts get a better start for NLP.
Learn More – Natural Language Processing- Business use cases – Byteridge
Natural Language Processing (NLP) has experienced some of the most impactful breakthroughs in recent years, primarily due to the the transformer architecture. These breakthroughs have not only enhanced the capabilities of machines to understand and generate human language but have also redefined the landscape of numerous applications, from search engines to conversational AI.
As the field progressed, the focus shifted toward understanding sequences of text, which was crucial for tasks like machine translation, text summarization, and sentiment analysis. Recurrent Neural Networks (RNNs) became the cornerstone for these applications due to their ability to handle sequential data by maintaining a form of memory.
The landscape of NLP underwent a dramatic transformation with the introduction of the transformer model in the landmark paper “Attention is All You Need” by Vaswani et al. in 2017. The transformer architecture departs from the sequential processing of RNNs and LSTMs and instead utilizes a mechanism called ‘self-attention' to weigh the influence of different parts of the input data.
The core idea of the transformer is that it can process the entire input data at once, rather than sequentially. This allows for much more parallelization and, as a result, significant increases in training speed. The self-attention mechanism enables the model to focus on different parts of the text as it processes it, which is crucial for understanding the context and the relationships between words, no matter their position in the text.
Following the initial success of the transformer model, there was an explosion of new models built on its architecture, each with its own innovations and optimizations for different tasks:
GPT (Generative Pre-trained Transformer): Developed by OpenAI, the GPT line of models started with GPT-1 and reached GPT-4 by 2023. These models are pre-trained using unsupervised learning on vast amounts of text data and fine-tuned for various tasks. Their ability to generate coherent and contextually relevant text has made them highly influential in both academic and commercial AI applications.
Here's a more in-depth comparison of the T5, BERT, and GPT models across various dimensions:
Transformers have revolutionized the field of NLP by enabling models to process sequences of data in parallel, which dramatically increased the speed and efficiency of training large neural networks. They introduced the self-attention mechanism, allowing models to weigh the significance of each part of the input data, regardless of distance within the sequence. This led to unprecedented improvements in a wide array of NLP tasks, including but not limited to translation, question answering, and text summarization.
Research continues to push the boundaries of what transformer-based models can achieve. GPT-4 and its contemporaries are not just larger in scale but also more efficient and capable due to advances in architecture and training methods. Techniques like few-shot learning, where models perform tasks with minimal examples, and methods for more effective transfer learning are at the forefront of current research.
The language models like those based on transformers learn from data which can contain biases. Researchers and practitioners are actively working to identify, understand, and mitigate these biases. Techniques range from curated training datasets to post-training adjustments aimed at fairness and neutrality.
Humane’s AI Pin is a Step Forward in Wearable Tech, But With Drawbacks
Custom GPTs Are Here and Will Impact Everything AI
I have spent the past five years immersing myself in the fascinating world of Machine Learning and Deep Learning. My passion and expertise have led me to contribute to over 50 diverse software engineering projects, with a particular focus on AI/ML. My ongoing curiosity has also drawn me toward Natural Language Processing, a field I am eager to explore further.
Optimizing LLM Deployment: vLLM PagedAttention and the Future of Efficient AI Serving
Decoder-Based Large Language Models: A Complete Guide
You know that expression When you have a hammer, everything looks like a nail? Well, in machine learning, it seems like we really have discovered a magical hammer for which everything is, in fact, a nail, and they’re called Transformers. Transformers are models that can be designed to translate text, write poems and op eds, and even generate computer code. In fact, lots of the amazing research I write about on daleonai.com is built on Transformers, like AlphaFold 2, the model that predicts the structures of proteins from their genetic sequences, as well as powerful natural language processing (NLP) models like GPT-3, BERT, T5, Switch, Meena, and others. You might say they’re more than meets the… ugh, forget it.
If you want to stay hip in machine learning and especially NLP, you have to know at least a bit about Transformers. So in this post, we’ll talk about what they are, how they work, and why they’ve been so impactful.
A Transformer is a type of neural network architecture. To recap, neural nets are a very effective type of model for analyzing complex data types like images, videos, audio, and text. But there are different types of neural networks optimized for different types of data. For example, for analyzing images, we’ll typically use convolutional neural networks or “CNNs.” Vaguely, they mimic the way the human brain processes visual information.
Before Transformers were introduced in 2017, the way we used deep learning to understand text was with a type of model called a Recurrent Neural Network or RNN that looked something like this:
So any model that’s going to understand language must capture word order, and recurrent neural networks did this by processing one word at a time, in a sequence.
Worse, RNNs were hard to train. They were notoriously susceptible to what’s called the vanishing/exploding gradient problem (sometimes you simply had to restart training and cross your fingers). Even more problematic, because they processed words sequentially, RNNs were hard to parallelize. This meant you couldn’t just speed up training by throwing more GPUs at the them, which meant, in turn, you couldn’t train them on all that much data.
This is where Transformers changed everything. They were developed in 2017 by researchers at Google and the University of Toronto, initially designed to do translation. But unlike recurrent neural networks, Transformers could be very efficiently parallelized. And that meant, with the right hardware, you could train some really big models.
GPT-3, the especially impressive text-generation model that writes almost as well as a human was trained on some 45 TB of text data, including almost all of the public web.
Conceptually, you can think of this as moving the burden of understanding word order from the structure of the neural network to the data itself.
At first, before the Transformer has been trained on any data, it doesn’t know how to interpret these positional encodings. But as the model sees more and more examples of sentences and their encodings, it learns how to use them effectively.
I’ve done a bit of over-simplification here–the original authors used sine functions to come up with positional encodings, not the simple integers 1, 2, 3, 4–but the point is the same. Store word order as data, not structure, and your neural network becomes easier to train.
Attention is a neural network structure that you’ll hear about all over the place in machine learning these days. In fact, the title of the 2017 paper that introduced Transformers wasn’t called, We Present You the Transformer. Instead it was called Attention is All You Need.
And how does the model know which words it should be “attending” to at each time step? It’s something that’s learned from training data. By seeing thousands of examples of French and English sentences, the model learns what types of words are interdependent. It learns how to respect gender, plurality, and other rules of grammar.
The attention mechanism has been an extremely useful tool for natural language processing since its discovery in 2015, but in its original form, it was used alongside recurrent neural networks. So, the innovation of the 2017 Transformers paper was, in part, to ditch RNNs entirely. That’s why the 2017 paper was called “Attention is all you need.”
In general, what makes neural networks powerful and exciting and cool is that they often automatically build up meaningful internal representations of the data they’re trained on. When you inspect the layers of a vision neural network, for example, you’ll find sets of neurons that “recognize” edges, shapes, and even high-level structures like eyes and mouths. A model trained on text data might automatically learn parts of speech, rules of grammar, and whether words are synonymous.
Self-attention help neural networks disambiguate words, do part-of-speech tagging, entity resolution, learn semantic roles and a lot more.
One of the most popular Transformer-based models is called BERT, short for “Bidirectional Encoder Representations from Transformers.” It was introduced by researchers at Google around the time I joined the company, in 2018, and soon made its way into almost every NLP project–including Google Search.
- classification
BERT proved that you could build very good language models trained on unlabeled data, like text scraped from Wikipedia and Reddit, and that these large “base” models could then be adapted with domain-specific data to lots of different use cases.
You can download common Transformer-based models like BERT from TensorFlow Hub. For a code tutorial, check out this one I wrote on building apps powered by semantic language.
But if you want to be really trendy and you write Python, I’d highly recommend the popular “Transformers” library maintained by the company HuggingFace. The platform allow you to train and use most of today’s popular NLP models, like BERT, Roberta, T5, GPT-2, in a very developer-friendly way.
Are you curious about the incredible advancements in Natural Language Processing (NLP) and how they are shaping our digital experiences? Look no further! In this blog post, we will dive headfirst into the fascinating world of Deep Learning in NLP. From analyzing sentiments to creating interactive chatbots, discover how these breakthrough technologies are revolutionizing communication and transforming the way we interact with machines. Join us on this exciting journey as we unravel the applications of Deep Learning in NLP and uncover its potential to reshape our digital landscape.
Natural Language Processing (NLP) and Deep Learning are two rapidly growing fields that have gained immense popularity in recent years. NLP is a branch of artificial intelligence (AI) that deals with the interaction between computers and human languages, while deep learning is a subset of machine learning that uses neural networks to process complex data. Together, they have revolutionized the way machines understand and analyze human language.
Traditionally, computers were only able to understand structured data such as numbers or symbols. However, with advancements in technology, NLP has made it possible for machines to comprehend and analyze unstructured data like text, speech, and images. This has opened up a wide range of possibilities for applications in various industries such as healthcare, finance, customer service, marketing, and more.
Deep learning techniques have further enhanced NLP by allowing machines to learn from vast amounts of data without being explicitly programmed for each task. This makes them suitable for handling natural language tasks that involve large datasets and complex patterns. By using multiple layers of artificial neural networks, deep learning models can perform tasks like language translation, summarization, question answering systems, sentiment analysis, chatbots,and more with remarkable accuracy.
One of the most significant advantages of combining NLP with deep learning is its ability to handle language variations such as slang words or typos. Traditional rule-based systems often struggle with these variations as they rely on specific keywords or grammatical rules to interpret text.
Sentiment analysis, also known as opinion mining, is the process of using natural language processing (NLP) techniques to identify and extract subjective information from text. It involves analyzing written or spoken words to determine the overall sentiment or attitude expressed towards a particular topic, product, or service. In recent years, sentiment analysis has gained significant attention due to its relevance in various industries such as marketing, customer service, and social media.
The Importance of Sentiment Analysis in NLP:
1. Understanding Customer Sentiments: In today’s digital age, online reviews and feedback have become a crucial source of information for businesses. By using sentiment analysis techniques on these reviews and comments, businesses can gain valuable insights into how their customers feel about their products or services. This information can help them make data-driven decisions to improve their offerings and enhance customer satisfaction.
2. Brand Reputation Management: Sentiment analysis can also be used for brand reputation management by monitoring social media platforms and other online channels for mentions of a company or its products. By tracking sentiment towards their brand, companies can quickly identify any negative sentiments that may harm their reputation and take necessary actions to address them.
3. Market Research: Traditional market research methods such as surveys and focus groups often tend to be time-consuming and expensive. With sentiment analysis, companies can gather large amounts of data from social media platforms in real-time at a fraction of the cost. This data can then be analyzed to understand consumer preferences better and make informed business decisions.
Deep learning has revolutionized the field of natural language processing (NLP) and has paved the way for more advanced applications such as sentiment analysis. Sentiment analysis is a technique used to identify and extract emotions, opinions, attitudes, and feelings expressed in text data. It has gained significant attention in recent years due to its wide range of applications in various industries such as marketing, customer service, and social media monitoring.
One of the main reasons behind the success of deep learning in sentiment analysis is its ability to process large amounts of unstructured data with high accuracy. Unlike traditional machine learning techniques that require handcrafted features, deep learning models can learn feature representations directly from raw text data. This allows them to capture complex patterns and relationships between words and phrases, making them ideal for sentiment analysis tasks.
The first step in any sentiment analysis task is pre-processing the text data by removing noise and irrelevant information. Deep learning models excel at this task by using techniques such as tokenization, stemming/lemmatization, stop word removal, and part-of-speech tagging. These techniques help to create a cleaner representation of the text data which can then be fed into the deep learning model for further processing.
One popular type of deep learning model used in sentiment analysis is recurrent neural networks (RNNs). RNNs are designed to handle sequential data such as natural language by taking into account previous inputs when processing current inputs.
Sentiment analysis is a powerful tool in Natural Language Processing (NLP) that allows us to understand and interpret the emotions and sentiments expressed in text data. With the advancements in deep learning techniques, sentiment analysis has become even more accurate and efficient, leading to its adoption in various real-life applications.
1. Customer feedback analysis:In today’s competitive market, understanding customer sentiments is crucial for businesses to improve their products and services. Sentiment analysis using deep learning algorithms can help companies analyze large volumes of customer feedback from various sources such as social media reviews, surveys, and customer support interactions. This enables businesses to gain insights into customer satisfaction levels, identify areas for improvement, and make data-driven decisions.
2. Brand monitoring:With the rise of social media platforms, brands need to be aware of how their customers perceive them online. Sentiment analysis using deep learning techniques can help brands monitor their reputation by analyzing mentions on social media platforms, news articles or blog posts related to their brand. This allows companies to stay informed about any negative sentiment towards their brand and take necessary actions.
3. Stock market prediction:Sentiment analysis has found its use in predicting stock market trends by analyzing financial news articles or social media conversations related to stocks. Deep learning models can analyze textual data from multiple sources and classify it as positive or negative sentiment towards specific stocks or the overall market trend. This information can be used by investors for making informed decisions about buying or selling stocks.
The rise of artificial intelligence (AI) has paved the way for many advancements in the field of natural language processing (NLP). One of the most exciting developments in this area is the development and use of chatbots. Chatbots are computer programs designed to simulate conversation with human users, using natural language processing techniques.
At its core, a chatbot is an AI-based system that interacts with users through text or voice conversations. These interactions can take place on messaging platforms like Facebook Messenger, WhatsApp, or through dedicated chatbot applications. They can also be integrated into websites or mobile apps as a virtual assistant.
But how do chatbots achieve this level of sophistication? The answer lies in deep learning — a subset of AI that involves training neural networks on large datasets to recognize patterns and make predictions based on new information.
In particular, recurrent neural networks (RNNs) have been widely used for developing chatbot models. RNNs are specialized neural networks for processing sequential data such as text or speech.
Chatbots, also known as virtual assistants, have become an integral part of our daily lives. From customer service to personal assistance, chatbots are being used in various industries to improve efficiency and enhance user experience. In recent years, there has been a significant advancement in natural language processing (NLP) thanks to deep learning techniques. These techniques have revolutionized the way chatbots are built and function.
In this section, we will explore the process of implementing chatbots using deep learning techniques. We will dive into the different steps involved in building a chatbot and how deep learning is utilized at each stage.
1. Understanding Natural Language Processing (NLP)Before delving into the world of deep learning for chatbots, it is crucial to understand NLP — the branch of artificial intelligence that deals with human language processing. NLP enables computers to understand human languages by breaking down text into smaller components such as words and phrases and analyzing their meanings.
Next comes creating a database or knowledge base for your chatbot. This includes gathering data from reliable sources such as FAQs or product manuals that can be used to train the bot’s responses.
3. Pre-processing Text DataOnce you have gathered all the necessary data for your chatbot,
Chatbots have become increasingly popular in recent years as a way for businesses to interact with their customers. These virtual assistants use natural language processing (NLP) techniques to understand and respond to human queries and are becoming more sophisticated thanks to advancements in deep learning.
Deep learning is a subset of machine learning that uses artificial neural networks to process large amounts of data and make predictions or decisions. This technology has revolutionized the field of NLP, allowing chatbots to handle complex conversations and deliver more accurate responses.
Advantages of Using Deep Learning for NLP:
1. Ability to Handle Large Amounts of Data: Deep learning models have the capability to process and analyze vast amounts of data, making them suitable for natural language processing tasks which require large datasets. This allows for a more comprehensive understanding and representation of language patterns and nuances.
2. Feature Extraction: Unlike traditional machine learning algorithms, deep learning models can automatically extract features from raw data without the need for manual feature engineering. This not only saves time but also improves the accuracy and performance of NLP tasks.
3. Complex Representation: Deep learning models are able to create complex representations of language by capturing hierarchical relationships between words, phrases, and sentences. This allows for a more nuanced understanding of language structure and context.
4. Continual Learning: With continual training, deep learning models can adapt and improve over time as they encounter new data or scenarios. This makes them well-suited for NLP tasks that require continuous learning such as sentiment analysis or chatbot conversations.
5. Multilingual Capabilities: Due to their ability to handle large amounts of data, deep learning models can be trained on multilingual datasets, making them adept at processing multiple languages simultaneously. This is especially useful in today’s globalized world where businesses need to cater to diverse audiences.
Limitations of Using Deep Learning for NLP:
1. Data Dependency: One major limitation of using deep learning models for NLP is their heavy reliance on large datasets for training purposes. Without sufficient data, these models may not perform as well and may even produce inaccurate results.
2. Computationally Intensive: Deep learning algorithms are computationally intensive, meaning they require a significant amount of computing power to train and run. This can be time-consuming and expensive, making it difficult for smaller organizations or individuals to use deep learning for NLP tasks.
3. Lack of Interpretability: Deep learning models are often referred to as “black boxes” because it can be challenging to understand how they arrive at their decisions or predictions. This lack of interpretability can be a drawback in some NLP applications where explainability is crucial.
4. Overfitting: Deep learning models have a high risk of overfitting, which occurs when the model becomes too specialized on the training data and performs poorly on new data. This can be mitigated by using techniques such as regularization, but it is still a potential limitation to consider.
5. Domain Specificity: Deep learning models are trained on specific datasets, which means they may struggle with out-of-domain data that differs significantly from what they were trained on. This makes it important to carefully select or fine-tune models for specific NLP tasks and domains.
The field of natural language processing (NLP) has been revolutionized by the emergence of deep learning techniques. These methods, inspired by the way our brains process information, have shown remarkable success in applications such as sentiment analysis and chatbots. As we continue to make advancements in deep learning, it is important to explore its future potential in NLP and identify potential areas for growth.
One of the most promising areas for growth in deep learning for NLP is language translation. Traditionally, machine translation required extensive linguistic knowledge and hand-crafted rules. However, with the use of recurrent neural networks (RNNs) and long short-term memory (LSTM) models, which are adept at capturing sequential data, we have seen significant improvements in automated translation systems. With further advancements in these models and the incorporation of attention mechanisms, we can expect even more accurate and fluent translations.
Another area that is poised for growth is dialogue management. Deep learning approaches have been used to develop conversational agents or chatbots that can engage in natural conversations with users. However, there is still much room for improvement in terms of creating more human-like interactions. This could be achieved through better understanding of context and emotion recognition using deep learning techniques.
Additionally, text summarization is another area where deep learning has great potential. Summarizing large amounts of text while retaining essential information requires a thorough understanding of the meaning behind words and sentences. This task can be tackled using deep learning methods such as sequence-to-sequence models with attention, which have already shown promising results in abstractive text summarization.
Furthermore, deep learning can be applied to improve the accuracy and efficiency of information extraction, which involves automatically extracting structured data from unstructured text. By leveraging neural networks and reinforcement learning techniques, we can expect to see advancements in this area that will enable us to extract more complex and diverse information from texts.
In the healthcare industry, deep learning has the potential to improve medical document analysis for tasks such as automated coding and clinical decision support. With more advanced deep learning models capable of handling medical terminologies and specific language used in patient records, we can streamline processes and reduce human error in medical data analysis.
Finally, ethical considerations are crucial for the future growth of deep learning in NLP. As these models become more advanced and are used for sensitive tasks such as automated decision making or content moderation, it is important to ensure they are fair and unbiased. This requires ongoing research on how to mitigate bias in training data and create transparent decision-making processes.
In conclusion, the future of deep learning in NLP looks promising with potential applications in language translation, dialogue management, text summarization, information extraction, healthcare document analysis, and more.
Cybercriminals are weaponizing Artificial Intelligence (AI) to launch more sophisticated, scaled and advanced targeted cyberattacks. AI has empowered attackers and enabled them to create malware that transforms to evade detection, highly compelling phishing exploits, and automate advanced attacks.
Deep Instinct’s fourth edition report states that 75% of security professionals have witnessed an increase in cyberattacks this year and 85% were powered by generative AI. Traditional defense controls like rule-based intrusion detection and prevention systems, signature-based antivirus software and firewalls have proved ineffective in preventing evolving AI-driven cyberattacks. There is a great demand for more adaptive and advanced tools and strategies to protect the fast-transforming threat landscape and to defend against these automated dynamic exploits.
AI has enabled cybercriminals to launch automated cyberattacks with unprecedented accuracy, speed and at scales that were difficult to achieve just by human hackers. Malicious users are taking advantage of AI technology in several ways. Below are some of the cyber exploits where attackers incorporate generative AI:
Overall, generative AI technology has enabled cybercriminals to create more sophisticated and automated exploits that are much more scalable and less time-consuming. Organizations are struggling to keep in phase in detecting and preventing these advanced exploits.
Traditional security measures and tools like intrusion detection and prevention systems, SIEMs, firewalls and antivirus software have proven ineffective in protecting the fast-evolving threat landscape and preventing AI-powered cyberattacks. Below are some of their limitations (Figure 1):
Ironically, generative AI technology itself can be used to protect against AI-powered cyberthreats. The cybersecurity industry has started to rely on AI-powered security tools in conjunction with traditional security measures like identity and access management, intrusion detection, risk assessment, fraud detection, data loss prevention, incident response and other core security domains. Surprisingly, recent research revealed that the global market for AI-powered cybersecurity tools and products was US$15 billion in 2021 and is projected to surge to roughly $135 billion by 2030. There are several advantages to using AI-powered security tools in combating today’s advanced cyber threats (Figure 2). Some of them are:
Figure 2: AI-powered cybersecurity
Generative AI-powered tools can improve themselves through machine learning capabilities by analyzing previous security incidents and training themselves to identify suspicious behaviors, predict threats and undertake preventive measures to stop cyberattacks. Also, this helps in filling the gaps in not having enough human resources with cybersecurity skills to fill 3.5 million security jobs. Using AI has freed security analysts from mundane initial event monitoring and analysis and allowed them to apply their skills in more advanced, strategic decision-making tasks. By combining both traditional and AI security tools, organizations are experiencing more productivity, effectiveness and reduction in security threats. 
Organizations need to keep up to date and stay informed about the latest research and developments in the space of AI-powered security attacks and ways to prevent/remediate the exploits. Perform regular security audits to detect security vulnerabilities and make sure your infrastructure is compliant and secure. Proactively take measures to prevent these advanced security exploits. Invest in generative AI-powered security tools to take advantage of the benefits they offer in combatting the fast-evolving cyber threats. Provide adequate training to your teams and create awareness about AI security risks and ways to take advantage of them securely.
Build AI skills at any level. Access articles, whitepapers, and publications. Explore new training courses and discover how to harness AI's power for success.
Far too many users are starstruck by AI capabilities and are putting enterprises at substantial risk. 
The introduction of OpenAI’s ChatGPT was a tipping point in the field of artificial intelligence (AI) and, perhaps, a watershed moment in history.
Both generative AI and precision AI hold promise in helping organizations defend against ever more sophisticated cyberattacks.