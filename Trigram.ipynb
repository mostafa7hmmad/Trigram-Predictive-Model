{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a88d79fc-1382-47ce-94d2-173b4f83a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffff9d7-4c68-4901-bbf2-ca350caf8a9c",
   "metadata": {},
   "source": [
    "# tokenize text and prepare trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf39bb7c-a934-4752-aed4-f77f0d9def41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Trigrams:\n",
      "('artificial', 'intelligence', 'techniques')\n",
      "('intelligence', 'techniques', 'in')\n",
      "('techniques', 'in', 'financial')\n",
      "('in', 'financial', 'trading:')\n",
      "('financial', 'trading:', 'a')\n",
      "('trading:', 'a', 'systematic')\n",
      "('a', 'systematic', 'artificial')\n",
      "('systematic', 'artificial', 'intelligence')\n",
      "('artificial', 'intelligence', 'financial')\n",
      "('intelligence', 'financial', 'technology')\n",
      "('financial', 'technology', 'artificial')\n",
      "('technology', 'artificial', 'intelligence')\n",
      "('artificial', 'intelligence', '(ai)')\n",
      "('intelligence', '(ai)', 'approaches')\n",
      "('(ai)', 'approaches', 'have')\n",
      "('approaches', 'have', 'been')\n",
      "('have', 'been', 'increasingly')\n",
      "('been', 'increasingly', 'used')\n",
      "('increasingly', 'used', 'in')\n",
      "('used', 'in', 'financial')\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\mostafa\\AI&ML\\assiment-nlp\\AI-work.txt\"\n",
    "\n",
    "def collect_and_tokenize_corpus(file_path):\n",
    "    # Read file contents\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read().lower()  \n",
    "    \n",
    "    tokens = text.split()\n",
    "    \n",
    "    trigram_model = [(tokens[i], tokens[i+1], tokens[i+2]) for i in range(len(tokens) - 2)]\n",
    "    \n",
    "    return tokens, trigram_model\n",
    "def extract_trigrams(file_path, num_samples=10):\n",
    "    _, trigram_model = collect_and_tokenize_corpus(file_path)\n",
    "    return trigram_model[:num_samples]\n",
    "\n",
    "trigram_sample = extract_trigrams(file_path, num_samples=20)\n",
    "\n",
    "print(\"Sample Trigrams:\")\n",
    "for trigram in trigram_sample:\n",
    "    print(trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f8944c-350f-4df6-9cda-8561ac6c2014",
   "metadata": {},
   "source": [
    "## build trigram frequency model with Laplace Smoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "722b3d55-51bb-4203-aead-64f0dfbeed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trigram_model(trigram_model, tokens, alpha=1):\n",
    "    trigram_counts = Counter(trigram_model) #how many times each trigram appears\n",
    "    total_trigrams = sum(trigram_counts.values())\n",
    "    vocabulary_size = len(set(tokens)) #removes any duplicates\n",
    "    \n",
    "    smoothed_probs = defaultdict(lambda: alpha / (total_trigrams + alpha * vocabulary_size)) # default probability for any trigram\n",
    "    \n",
    "    for trigram, count in trigram_counts.items():\n",
    "        smoothed_probs[trigram] = (count + alpha) / (total_trigrams + alpha * vocabulary_size) #probability to each trigram\n",
    "    \n",
    "    return trigram_counts, smoothed_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9df9ba1-560e-424b-97d3-92eed554e517",
   "metadata": {},
   "source": [
    "# Autocomplete function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86303d05-b54f-4051-8a15-b615754600f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocomplete(input_text, smoothed_probs):\n",
    "    input_tokens = input_text.lower().split()\n",
    "    if len(input_tokens) < 2:\n",
    "        return [\"Please type at least two words.\"]\n",
    "    \n",
    "    last_bigram = tuple(input_tokens[-2:])\n",
    "    suggestions = {\n",
    "        trigram[-1]: prob for trigram, prob in smoothed_probs.items() if trigram[:2] == last_bigram\n",
    "    }\n",
    "    \n",
    "    if not suggestions:\n",
    "        return [\"No suggestions available.\"]\n",
    "    \n",
    "    sorted_suggestions = sorted(suggestions.items(), key=lambda x: -x[1])[:5] \n",
    "    return [word for word, _ in sorted_suggestions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5026dd2c-93e0-4b82-9991-8d5b9b08d8aa",
   "metadata": {},
   "source": [
    "# Function to calculate perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fc8b7c4-8d33-45c7-9aa7-e688683e45ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(smoothed_probs, test_trigrams):\n",
    "    N = len(test_trigrams)\n",
    "    log_prob_sum = 0\n",
    "    for trigram in test_trigrams:\n",
    "        prob = smoothed_probs[trigram]\n",
    "        log_prob_sum += math.log(prob, 2)  # log(P1×P2×P3)=log(P1)+log(P2)+log(P3)\n",
    "    perplexity = 2 ** (-log_prob_sum / N)\n",
    "    return perplexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aedd71-4fb1-4ab8-a7e7-89ebd8df3e6f",
   "metadata": {},
   "source": [
    "# Load and prepare the corpus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "226f5d60-0e90-439a-87e2-1580b8224a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "tokens, trigram_model = collect_and_tokenize_corpus(file_path)\n",
    "trigram_counts, smoothed_probs = build_trigram_model(trigram_model, tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96b983a-8c58-4a91-a5a0-ecc3349d3108",
   "metadata": {},
   "source": [
    "# Streamlit Interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "679335fd-1fd9-4e13-945c-fa4e85d7a724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 09:26:23.494 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.title(\"Trigram Model Autocomplete and Perplexity Calculator\")\n",
    "\n",
    "st.write(f\"Total Words in Corpus: {len(tokens)}\")\n",
    "st.write(f\"Total Trigrams in Corpus: {len(trigram_model)}\")\n",
    "st.write(f\"Vocabulary Size: {len(set(tokens))}\")\n",
    "\n",
    "# Autocomplete Section\n",
    "st.header(\"Autocomplete Suggestions\")\n",
    "user_input = st.text_input(\"Type your text here:\")\n",
    "\n",
    "if user_input:\n",
    "    suggestions = autocomplete(user_input, smoothed_probs)\n",
    "    st.write(\"Suggestions:\")\n",
    "    for suggestion in suggestions:\n",
    "        st.write(suggestion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
